<?xml version="1.0" encoding="utf-8" ?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:wfw="http://wellformedweb.org/CommentAPI/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/"><channel><title>Adventures in JavaScript</title><atom:link href="http://rmurphey.com/feed/" rel="self" type="application/rss+xml"></atom:link><link>http://rmurphey.com</link><description></description><lastBuildDate>Wed, 25 Nov 2015 14:00:00 +0000</lastBuildDate><language>en-US</language><sy:updatePeriod>hourly</sy:updatePeriod><sy:updateFrequency>1</sy:updateFrequency><item><title>Building for HTTP/2</title><guid isPermaLink="false">building-for-http2</guid><link>http://rmurphey.com/2015/11/25/building-for-http2</link><pubDate>Wed, 25 Nov 2015 14:00:00 +0000</pubDate><description><![CDATA[Earlier this year, I got the chance to speak with Google&#39;s Ilya Grigorik about HTTP/2 for the 1.10 episode of the TTL Podcast. It was a great primer for me on how HTTP/2 works and what it means for how we build the web, but it wasn&#39;t until more recently that I started to think about what it means for how we build the web — that is, how we generate and deploy the HTML, CSS, and JS that power web applications.
If you&#39;re not familiar with HTTP/2, the basics are simultaneously simple and mind-boggling. Whereas its predecessors allowed each connection to a server to serve only one request at a time, HTTP/2 allows a connection to serve multiple requests simultaneously. A connection can also be used for a server to push a resource to a client — a protocol-level replacement for the technique we currently call “inlining.”
This is everything-you-thought-you-knew-is-wrong kind of stuff. In an HTTP/2 world, there are few benefits to concatenating a bunch of JS files together, and in many cases the practice will be actively harmful. Domain sharding becomes an anti-pattern. Throwing a bunch of &lt;script&gt; tags in your HTML is suddenly not a laughably terrible idea. Inlining of resources is a thing of the past. Browser caching — and cache busting — can occur on a per-module basis.
What does this mean for how we build and deploy applications? Let&#39;s start by looking at the state of the art in client-side application deployment prior to HTTP/2.
Deploying JavaScript Applications (2013)In March of 2013, Alex Sexton wrote Deploying JavaScript Applications, and it&#39;s what I consider to be the canonical post on the topic for sites and apps that include more than about 50K of client-side code.
In his post, Alex describes a deployment that uses a &quot;scout&quot; approach: a small bit of code, included directly in the HTML or loaded via &lt;script&gt; tag.
The scout file exists to balance the desire for application resources to be highly cacheable vs. the need for changes to those resources to take effect quickly.
To meet that goal, the scout needs a short cache time when it&#39;s a file; if the scout is in the HTML, then the HTML itself needs a short cache time. The scout contains information about the location of the file(s) that provide the current version of the application, and the code necessary to load those files.
Files loaded by the scout can have extremely long cache times because the scout loads resources from versioned URLs: when a resource is updated, it is hosted at a new URL, and the scout is updated to load the resource from that new URL.
Why a scout approach rather than just loading the versioned files using &lt;script&gt; tags directly from the HTML? The scout technique lets you deploy changes to your JavaScript application without requiring a re-deploy of the server-side application. (In an ideal world this might not seem valuable, but in the real world, it often is.) When the scout is served separately from the HTML, it also allows for a different caching strategy for the HTML.
In this system, it&#39;s typical that the scout would load one or two JavaScript files that were generated by combining the modules needed for the initial state of the application. More code might be loaded later to support additional application behavior; again, that code would typically comprise a set of modules shipped in a single file.
There are a few shortcomings inherent to this approach, which are difficult to overcome without upsetting the balance between cacheability and changeability:

Shipping the application as a large file with a long cache time works great for repeat visitors, but not so well for first-timers who have to wait for the large file to load.
All users have to download the whole large file again whenever something changes — even something small.
Even when nothing changes, a short cache time means repeat visitors may end up re-downloading the scout frequently.

Adding HTTP/2 to the mix — that is, flipping the switch that gets your server to start speaking HTTP/2 to browsers that understand it — has a nominal positive impact the performance of an app crafted for maximum performance on HTTP/1. Indeed, the applications most likely to see big improvements without big changes are applications whose deployments were poorly designed in the first place.
To see performance gains in a well-engineered deployment, we&#39;ll have to re-engineer the deployment itself.
Splitting it upOne of the most obvious opportunities is presented by HTTP/2&#39;s ability to handle multiple requests over the same connection. Rather than shipping a single large application file over the wire, what if we tell the scout to load the individual modules that make up the application? We would no longer have to invalidate the cache for the whole application every time we make a change.
A few reasons come to mind why this might be a bad idea.
The first is the concern that compression might suffer if shipping modules individually. As it turns out, though, combining multiple modules into a single file results in only slightly better compression than if the modules are compressed individually. For example, compressing a file containing minified versions of jQuery, Underscore, and Backbone results in 42,186-byte file; compressing each minified file individually results in a combined size of 42,975 bytes. The difference is 789 bytes -- barely meaningful.
Other second concern may be more legitimate: our server or CDN may be unhappy about serving one request per module; and it may be unduly complex to ship a single module per file, especially since any given request might fail for whatever reason. For the sake of discussion, we&#39;ll assume that it&#39;s reasonable to do some grouping of modules into individual files.
How to group those modules is up for debate. One strategy could be to group files according to their likelihood of changing, recognizing that library and framework modules don&#39;t change often, while application modules do. Another strategy would be to group files associated with a unit of useful functionality, though this leaves us needing a way to deliver code that&#39;s shared across units of functionality.
At Bazaarvoice, we solve this concern via a lightweight require/define system that ships in the scout file, allowing us to share vendor files such as jQuery and Backbone across applications. An application can express a dependency on a vendor file using NAMESPACE.require(), and vendor files declare themselves using NAMESPACE.define(). Once a vendor file has been defined, other modules on the page have access to it immediately via NAMESPACE.require().
VersioningFor HTTP/1.1-friendly builds, we always increment the version of the built application file, and embed a URL pointing to that new version in the scout file. We do this because it is essentially guaranteed that the contents of the application file have changed whenever we do a new build -- otherwise there would be no reason for the build.
For HTTP/2-friendly builds, we’re generating many smaller files; we only want to increment their version when something has changed.
For example, imagine a build that generates vendor-v1.js and application-v1.js; it also generates a scout that loads these two files. We then make a change to an application file, and we do another build, creating vendor-v2.js and application-v2.js. However, no vendor files have changed; our scout should now load to application-v2.js but still load vendor-v1.js. If our scout points to vendor-v2.js, we lose the benefit of being able to cache smaller pieces of our code.
This can be solved by using hashes of the file contents rather than version numbers: vendor-d41d8cd98f.js. If a file has not changed, its hash will remain the same. (Notably, inconsequential changes will change the hash -- for example, a new copyright comment that is inserted post-minification.) Plenty of build strategies already use content hashes for versioning; however, many still use integers, dates, or commit hashes, which change even when the contents of a file have not.
Given files whose names include a hash, our scout can include a manifest that prescribes the file to load for a given resource. The manifest would be generated by the build after all of the resources were generated.
module.exports = {
  baseUrl : &#39;https://mysite.com/static/&#39;,
  resources : {
    vendor : &#39;vendor-d41d8cd98f.js&#39;,
    application : &#39;application-a32e3ec23d.js&#39;
  }
};

Push: Because you downloaded scout.js, you might also like ...Another exciting opportunity in an HTTP/2 world is the ability to push a cascade of resources.
The first push opportunity is the scout itself: for sites and applications that currently ship the scout inlined in the initial HTML payload, server push affords an opportunity to send the scout as a separate resource when the initial HTML is requested.
There’s an interesting dilemma here: If the browser already has the resource cached, and the cache is still valid, it doesn’t need the server to push the resource. Currently, though, there’s no way for the browser to communicate its cache contents to the server. A browser can decline a push, but the server may have already started to send it. We’ve basically introduced a new tradeoff: server push can get the resource to the browser quickly, but we waste bandwidth if the browser doesn’t need it.
As discussed at the link above, a smart server could use session information to determine when to push -- for example, if the page is reloaded within a resource’s cache time, there is no need to re-push that resource to the same session -- but this makes push state-dependent, a frightening prospect if we hope to use CDNs to ensure efficient asset delivery.
Assuming we&#39;ve generated a manifest as described above, we have the option of going a step further: we can separate the manifest and the scout, allowing the scout to have a far longer cache time than in a pre-HTTP/2 world. This is possible because the thing that typically changes about the scout is the version of the resources it loads, and it makes the most sense on a site where there are different payloads for different pages or users. For applications that previously included the scout in HTML, we can push the scout and the manifest, and have the scout request the manifest; for applications that loaded the scout as its own JS file, we can push the manifest when the scout file is loaded and, again, have the scout request the manifest.
This approach also makes a further case for a standardized scout: application-specific configuration can be shipped in the manifest, and a standardized scout can be shared across applications. This scout could be a file loaded via a script tag, where the script tag itself provides information about the application manifest to use:
&lt;script src=&quot;/static/shared/js/scout.js&quot;
  data-manifest=&quot;/static/apps/myapp/manifest.js&quot;&gt;&lt;/script&gt;

The manifest contains information about the other resources that the scout will request, and can even be used by the server to determine what to push alongside the HTML.
A manifest could provide these instructions:
module.exports = {
  baseUrl : &#39;https://mysite.com/static/&#39;,
  resources : {
    vendor : {
      version : &#39;vendor-d41d8cd98f.js&#39;,
      pushWith : [ &#39;scout&#39; ]
    },
    application : {
      version : &#39;application-a32e3ec23d.js&#39;,
      pushWith : [ &#39;scout&#39; ]
    },
    secondary : {
      version : &#39;secondary-e43b8ad12f.js&#39;,
      pushWith : [ ]
    }
  }
};

Processing this manifest would require intelligence on the part of the CDN; it may be necessary to replace s3 storage with an actual server that is capable of making these decisions, fronted by a CDN that can intelligently relay responses that include server push.
The elephants in the roomThere are two notable challenges to the rapid transition to an HTTP/2 world: the continued existence of legacy browsers, especially on mobile; and the requirement that HTTP/2 connections be conducted over TLS. Thankfully, the latter provides a reasonable opportunity to address the former. Let&#39;s, then, talk about the TLS requirement first.
HTTP/2 is a new protocol, and as such, it is greatly confusing to a large segment of the existing internet: proxies, antivirus software, and the like. During the development of HTTP/2 and SPDY before it, engineers observed that traffic that was transported on an insecure connection would frequently fail. The reason? The proxies, the antivirus software, and all the rest had certain expectations of HTTP traffic; HTTP/2 violated those expectations, and so HTTP/2 traffic was considered unsafe. The software that thwarted insecure HTTP/2 traffic didn&#39;t have the ability to inspect secure traffic, and so HTTP/2 traffic over a secure connection passed through just fine. Thus was born the requirement — which is a browser implementation detail, and not part of the HTTP/2 spec — that HTTP/2 web communication be conducted using TLS.
The Let&#39;s Encrypt project aims to eliminate the high cost of obtaining the certificate that enables secure HTTP communication; there will still be technical hurdles to using that certificate, but those should be surmountable for anyone who cares enough to engineer a performant HTTP/2 deployment.
In order for a browser and a server to communicate using HTTP/2, the browser and the server must first agree that they can. The TLS handshake that enables secure communication turns out to be the ideal time to negotiate the communication protocol, as well: no additional round trip is required for the negotiation.
When a server is handling a request, it knows whether the browser understands HTTP/2; we can use this information to shape our payload. We can send a legacy browser an HTML file that includes an inlined scout file, and that inlined scout file can include the manifest. The manifest can provide information about how to support legacy browsers:
module.exports = {
  baseUrl : &#39;https://mysite.com/static/&#39;,
  resources : {
    // ...
  },
  legacyResources : {
    legacyMain : {
      initialLoad : true,
      version : &#39;legacy-main-c312efa43e.js&#39;
    },
    legacySecondary : {
      version : &#39;legacy-secondary-a22cf1e2af.js&#39;
    }
  }
};

For Consideration: HTTP/2-friendly deployments with HTTP/1.1 supportPutting the pieces together, we arrive at a deployment process that does the following:

Generates files that contain one or more modules, grouped by likelihood of changing, functionality, or another strategy. The file grouping strategy must persist across builds; new groupings would need a new, unique name that had not been used by earlier builds.
Generates legacy files, where those files contain modules that are grouped according to their likelihood to change, and according to whether they are required for initial load.
Names all files with a content hash.
Generates a manifest for the build, where the manifest includes:
a baseUrl property whose value is a string that should be used as the base for generating a full URL to a resource, using the pattern &lt;baseUrl&gt;/&lt;resource.version&gt;
a resources property whose value is an object that, for each file, provides:
the most recent changed version
a list of individual files which, when any of the files is requested, should trigger a push of the bundle


a legacyResources property whose value is an object that, for each legacy bundle, provices:
the most recent changed version
an optional initialLoad property whose value is true if the resource should be loaded immediately by the scout




Generates an HTTP/2 scout file* that provides the ability to load resources, and that loads a manifest.
Generates an HTTP/1 scout file* that provides the ability to load resources, and that includes the manifest.
Uploads the static resources.
Updates a delivery mechanism (such as a server or a CDN) based on the data in the new manifest.

The versioning and caching of the resources would be as follows:

manifest Unversioned. Short cache time, e.g. 10 minutes, to allow for the rapid uptake of new resources for HTTP/2 browsers.
scout Unversioned. Medium cache time, e.g. one day, assuming the contents of this file are considered relatively stable.
legacy-scout Unversioned. Short cache time, e.g. 10 minutes, to allow for the rapid uptake of new resources for legacy browsers.
application and vendor files Versioned. Long cache time, e.g. one year, given that new versions will be picked up when a new manifest is loaded.

* In applications that a) control the initial HTML payload, and b) only use the scout to load other resources, it may not make sense to have a separate scout; it might be sufficient to just load those resources via &lt;script&gt; and &lt;link&gt; tags in the HTML itself. This approach isn&#39;t viable for applications that do not control the initial HTML payload, such as third-party applications.
Reality checkIn several places so far, I’ve talked about the need for a server to make decisions about which resources it delivers, and when and how it delivers them. As I alluded to earlier, this could be profoundly challenging for CDNs, which traditionally simply receive a request and return a single resource in response. It also suggests the need for close collaboration between client and server development teams, and an increased knowledge of server-side technology for client-side developers.
CDN support of HTTP/2 in general is rather disappointing, with some major vendors providing nothing more than vague timelines for non-specific support.
As of this writing, I&#39;m unaware of CDNs that support any notion of server push, but I&#39;d be happy to find I am ill-informed. Ideally, CDNs need to provide applications with the ability to express how static assets relate to each other -- a task complicated by the fact that those relationships may be situational, such as in the case where an application doesn&#39;t want to push an asset that was just pushed to the same client 10 seconds before. One-size-fits-all push could be accomplished by setting a header on a file, indicating that other files should be pushed alongside it, but that doesn&#39;t allow for expressing more nuanced rules.
Even for applications that just want to split their payload into smaller files to take advantage of HTTP/2, and that don&#39;t intend to use server push, there is still a gap when it comes to providing a positive experience for HTTP/1.1 clients. CDNs need to surface the ability to change a response not just based on the URL that is requested, but the protocol of the request. Without this ability, we&#39;ll be stuck having to choose which protocol to support.
There is also work to be done on tooling, especially if we want to support HTTP/2 without significantly degrading the experience for legacy browsers. Ideally, our build tooling would figure out the optimal combination of files for us, with a knowledge of how the application was bundled previously so as not to squander past caching.
The developer story for HTTP/2 also leaves a lot to be desired as of this writing. Front-end developers are among the most likely in an organization to advocate for this new technology, but my experiences over a few weeks of learning about HTTP/2 suggest that the effort required to set up even a local environment will stretch the comfort zone for many. With a working local environment in hand, the tools to understand the differences between HTTP/2 and HTTP/1 behavior are limited and often confusing. Chrome presents information in its network tab that seems to conflict with the wall of text in its net-internals tool, especially when it comes to server push . Charles Proxy doesn&#39;t yet speak HTTP/2. Firefox shows pushed resources as an entry in the network tab, but they appear as though they were never received. nghttp2 provides great insight into how an HTTP/2 server is behaving, but it doesn&#39;t speak HTTP/1.1, so you can&#39;t use it to do comparisons. Measuring performance using a tool like WebPagetest requires a real certificate, which you may not have handy if you&#39;re just trying to experiment.
Alex wrote his 2013 post to document the product of years of experience in creating performant HTTP/1.1 deployments. HTTP/2 means we need to rethink everything we know about shipping applications to the web, and while the building blocks are there, there&#39;s still much to figure out about how we&#39;ll use them; the &quot;right&quot; answers are, in many cases, still TBD while we wait for vendors to act.
Further ReadingI&#39;ve been bookmarking useful HTTP/2 resources as I come across them.
ThanksThanks to the many folks who have talked to me about the ideas in this post, but especially to Lon Ingram, Jake Archibald, and Andy Davies.]]></description><content:encoded><![CDATA[<p>Earlier this year, I got the chance to speak with Google&#39;s Ilya Grigorik about HTTP/2 for the <a href="http://ttlpodcast.com/episodes/ilya-grigorik.html">1.10 episode of the TTL Podcast</a>. It was a great primer for me on how HTTP/2 works and what it means for how we build the web, but it wasn&#39;t until more recently that I started to think about what it means for how we <em>build</em> the web — that is, how we generate and deploy the HTML, CSS, and JS that power web applications.</p>
<p>If you&#39;re not familiar with <a href="https://httpwg.github.io/specs/rfc7540.html">HTTP/2</a>, the basics are simultaneously simple and mind-boggling. Whereas its predecessors allowed each connection to a server to serve only one request at a time, HTTP/2 allows a connection to serve multiple requests simultaneously. A connection can also be used for a server to <em>push</em> a resource to a client — a protocol-level replacement for the technique we currently call “inlining.”</p>
<p>This is everything-you-thought-you-knew-is-wrong kind of stuff. In an HTTP/2 world, there are few benefits to concatenating a bunch of JS files together, and in many cases the practice will be actively harmful. <a href="http://www.stevesouders.com/blog/2013/09/05/domain-sharding-revisited/">Domain sharding</a> becomes an anti-pattern. Throwing a bunch of <code>&lt;script&gt;</code> tags in your HTML is suddenly not a laughably terrible idea. Inlining of resources is a thing of the past. Browser caching — and cache busting — can occur on a per-module basis.</p>
<p>What does this mean for how we build and deploy applications? Let&#39;s start by looking at the state of the art in client-side application deployment prior to HTTP/2.</p>
<h2>Deploying JavaScript Applications (2013)</h2><p>In March of 2013, Alex Sexton wrote <a href="https://alexsexton.com/blog/2013/03/deploying-javascript-applications/">Deploying JavaScript Applications</a>, and it&#39;s what I consider to be the canonical post on the topic for sites and apps that include more than about 50K of client-side code.</p>
<p>In his post, Alex describes a deployment that uses a &quot;scout&quot; approach: a small bit of code, included directly in the HTML or loaded via <code>&lt;script&gt;</code> tag.</p>
<p>The scout file exists to balance the desire for application resources to be highly cacheable vs. the need for changes to those resources to take effect quickly.</p>
<p>To meet that goal, the scout needs a short cache time when it&#39;s a file; if the scout is in the HTML, then the HTML itself needs a short cache time. The scout contains information about the location of the file(s) that provide the current version of the application, and the code necessary to load those files.</p>
<p>Files loaded by the scout can have extremely long cache times because the scout loads resources from versioned URLs: when a resource is updated, it is hosted at a new URL, and the scout is updated to load the resource from that new URL.</p>
<p>Why a scout approach rather than just loading the versioned files using <code>&lt;script&gt;</code> tags directly from the HTML? The scout technique lets you deploy changes to your JavaScript application without requiring a re-deploy of the server-side application. (In an ideal world this might not seem valuable, but in the real world, it often is.) When the scout is served separately from the HTML, it also allows for a different caching strategy for the HTML.</p>
<p>In this system, it&#39;s typical that the scout would load one or two JavaScript files that were generated by combining the modules needed for the initial state of the application. More code might be loaded later to support additional application behavior; again, that code would typically comprise a set of modules shipped in a single file.</p>
<p>There are a few shortcomings inherent to this approach, which are difficult to overcome without upsetting the balance between cacheability and changeability:</p>
<ul>
<li>Shipping the application as a large file with a long cache time works great for repeat visitors, but not so well for first-timers who have to wait for the large file to load.</li>
<li>All users have to download the whole large file again whenever something changes — even something small.</li>
<li>Even when <em>nothing</em> changes, a short cache time means repeat visitors may end up re-downloading the scout frequently.</li>
</ul>
<p>Adding HTTP/2 to the mix — that is, flipping the switch that gets your server to start speaking HTTP/2 to browsers that understand it — has a nominal positive impact the performance of an app crafted for maximum performance on HTTP/1. Indeed, the applications most likely to see big improvements without big changes are applications whose deployments were poorly designed in the first place.</p>
<p>To see performance gains in a well-engineered deployment, we&#39;ll have to re-engineer the deployment itself.</p>
<h2>Splitting it up</h2><p>One of the most obvious opportunities is presented by HTTP/2&#39;s ability to handle multiple requests over the same connection. Rather than shipping a single large application file over the wire, what if we tell the scout to load the individual modules that make up the application? We would no longer have to invalidate the cache for the whole application every time we make a change.</p>
<p>A few reasons come to mind why this might be a bad idea.</p>
<p>The first is the concern that compression might suffer if shipping modules individually. As it turns out, though, combining multiple modules into a single file results in only slightly better compression than if the modules are compressed individually. For example, compressing a file containing minified versions of jQuery, Underscore, and Backbone results in 42,186-byte file; compressing each minified file individually results in a combined size of 42,975 bytes. The difference is 789 bytes -- barely meaningful.</p>
<p>Other second concern may be more legitimate: our server or CDN may be unhappy about serving one request per module; and it may be unduly complex to ship a single module per file, especially since any given request might fail for whatever reason. For the sake of discussion, we&#39;ll assume that it&#39;s reasonable to do <em>some</em> grouping of modules into individual files.</p>
<p>How to group those modules is up for debate. One strategy could be to group files according to their likelihood of changing, recognizing that library and framework modules don&#39;t change often, while application modules do. Another strategy would be to group files associated with a unit of useful functionality, though this leaves us needing a way to deliver code that&#39;s shared across units of functionality.</p>
<p>At Bazaarvoice, we solve this concern via a lightweight require/define system that ships in the scout file, allowing us to share vendor files such as jQuery and Backbone across applications. An application can express a dependency on a vendor file using <code>NAMESPACE.require()</code>, and vendor files declare themselves using <code>NAMESPACE.define()</code>. Once a vendor file has been defined, other modules on the page have access to it immediately via <code>NAMESPACE.require()</code>.</p>
<h2>Versioning</h2><p>For HTTP/1.1-friendly builds, we always increment the version of the built application file, and embed a URL pointing to that new version in the scout file. We do this because it is essentially guaranteed that the contents of the application file have changed whenever we do a new build -- otherwise there would be no reason for the build.</p>
<p>For HTTP/2-friendly builds, we’re generating many smaller files; we only want to increment their version when something has changed.</p>
<p>For example, imagine a build that generates vendor-v1.js and application-v1.js; it also generates a scout that loads these two files. We then make a change to an application file, and we do another build, creating vendor-v2.js and application-v2.js. However, no vendor files have changed; our scout should now load to application-v2.js but still load vendor-v1.js. If our scout points to vendor-v2.js, we lose the benefit of being able to cache smaller pieces of our code.</p>
<p>This can be solved by using hashes of the file contents rather than version numbers: vendor-d41d8cd98f.js. If a file has not changed, its hash will remain the same. (Notably, inconsequential changes <em>will</em> change the hash -- for example, a new copyright comment that is inserted post-minification.) Plenty of build strategies already use content hashes for versioning; however, many still use integers, dates, or commit hashes, which change even when the contents of a file have not.</p>
<p>Given files whose names include a hash, our scout can include a manifest that prescribes the file to load for a given resource. The manifest would be generated by the build after all of the resources were generated.</p>
<pre><code class="language-js">module.exports = {
  baseUrl : &#39;https://mysite.com/static/&#39;,
  resources : {
    vendor : &#39;vendor-d41d8cd98f.js&#39;,
    application : &#39;application-a32e3ec23d.js&#39;
  }
};
</code></pre>
<h2>Push: Because you downloaded scout.js, you might also like ...</h2><p>Another exciting opportunity in an HTTP/2 world is the ability to push a cascade of resources.</p>
<p>The first push opportunity is the scout itself: for sites and applications that currently ship the scout inlined in the initial HTML payload, server push affords an opportunity to send the scout as a separate resource when the initial HTML is requested.</p>
<p>There’s an interesting dilemma here: If the browser already has the resource cached, and the cache is still valid, it doesn’t need the server to push the resource. Currently, though, there’s no way for the browser to communicate its cache contents to the server. A browser can decline a push, but <a href="https://github.com/h2o/h2o/issues/355#issuecomment-109979111">the server may have already started to send it</a>. We’ve basically introduced a new tradeoff: server push can get the resource to the browser quickly, but we waste bandwidth if the browser doesn’t need it.</p>
<p>As discussed at the link above, a smart server could use session information to determine when to push -- for example, if the page is reloaded within a resource’s cache time, there is no need to re-push that resource to the same session -- but this makes push state-dependent, a frightening prospect if we hope to use CDNs to ensure efficient asset delivery.</p>
<p>Assuming we&#39;ve generated a manifest as described above, we have the option of going a step further: we can separate the manifest and the scout, allowing the scout to have a far longer cache time than in a pre-HTTP/2 world. This is possible because the thing that typically <em>changes</em> about the scout is the version of the resources it loads, and it makes the most sense on a site where there are different payloads for different pages or users. For applications that previously included the scout in HTML, we can push the scout and the manifest, and have the scout request the manifest; for applications that loaded the scout as its own JS file, we can push the manifest when the scout file is loaded and, again, have the scout request the manifest.</p>
<p>This approach also makes a further case for a <a href="https://github.com/bazaarvoice/scoutfile">standardized scout</a>: application-specific configuration can be shipped in the manifest, and a standardized scout can be shared across applications. This scout could be a file loaded via a script tag, where the script tag itself provides information about the application manifest to use:</p>
<pre><code class="language-html">&lt;script src=&quot;/static/shared/js/scout.js&quot;
  data-manifest=&quot;/static/apps/myapp/manifest.js&quot;&gt;&lt;/script&gt;
</code></pre>
<p>The manifest contains information about the other resources that the scout will request, and can even be used by the server to determine what to push alongside the HTML.</p>
<p>A manifest could provide these instructions:</p>
<pre><code class="language-js">module.exports = {
  baseUrl : &#39;https://mysite.com/static/&#39;,
  resources : {
    vendor : {
      version : &#39;vendor-d41d8cd98f.js&#39;,
      pushWith : [ &#39;scout&#39; ]
    },
    application : {
      version : &#39;application-a32e3ec23d.js&#39;,
      pushWith : [ &#39;scout&#39; ]
    },
    secondary : {
      version : &#39;secondary-e43b8ad12f.js&#39;,
      pushWith : [ ]
    }
  }
};
</code></pre>
<p>Processing this manifest would require intelligence on the part of the CDN; it may be necessary to replace s3 storage with an actual server that is capable of making these decisions, fronted by a CDN that can intelligently relay responses that include server push.</p>
<h2>The elephants in the room</h2><p>There are two notable challenges to the rapid transition to an HTTP/2 world: the continued existence of legacy browsers, especially on mobile; and the requirement that HTTP/2 connections be conducted over TLS. Thankfully, the latter provides a reasonable opportunity to address the former. Let&#39;s, then, talk about the TLS requirement first.</p>
<p>HTTP/2 is a new protocol, and as such, it is greatly confusing to a large segment of the existing internet: proxies, antivirus software, and the like. During the development of HTTP/2 and <a href="https://en.wikipedia.org/wiki/SPDY">SPDY</a> before it, engineers observed that traffic that was transported on an insecure connection would frequently fail. The reason? The proxies, the antivirus software, and all the rest had certain expectations of HTTP traffic; HTTP/2 violated those expectations, and so HTTP/2 traffic was considered unsafe. The software that thwarted insecure HTTP/2 traffic didn&#39;t have the ability to inspect secure traffic, and so HTTP/2 traffic over a secure connection passed through just fine. Thus was born the requirement — which is a browser implementation detail, and not part of the HTTP/2 spec — that HTTP/2 web communication be conducted using TLS.</p>
<p>The <a href="https://letsencrypt.org/">Let&#39;s Encrypt</a> project aims to eliminate the high cost of obtaining the certificate that enables secure HTTP communication; there will still be technical hurdles to using that certificate, but those should be surmountable for anyone who cares enough to engineer a performant HTTP/2 deployment.</p>
<p>In order for a browser and a server to communicate using HTTP/2, the browser and the server must first agree that they <em>can</em>. The TLS handshake that enables secure communication turns out to be the ideal time to negotiate the communication protocol, as well: no additional round trip is required for the negotiation.</p>
<p>When a server is handling a request, it knows whether the browser understands HTTP/2; we can use this information to shape our payload. We can send a legacy browser an HTML file that includes an inlined scout file, and that inlined scout file can include the manifest. The manifest can provide information about how to support legacy browsers:</p>
<pre><code class="language-js">module.exports = {
  baseUrl : &#39;https://mysite.com/static/&#39;,
  resources : {
    // ...
  },
  legacyResources : {
    legacyMain : {
      initialLoad : true,
      version : &#39;legacy-main-c312efa43e.js&#39;
    },
    legacySecondary : {
      version : &#39;legacy-secondary-a22cf1e2af.js&#39;
    }
  }
};
</code></pre>
<h2>For Consideration: HTTP/2-friendly deployments with HTTP/1.1 support</h2><p>Putting the pieces together, we arrive at a deployment process that does the following:</p>
<ul>
<li>Generates files that contain one or more modules, grouped by likelihood of changing, functionality, or another strategy. The file grouping strategy must persist across builds; new groupings would need a new, unique name that had not been used by earlier builds.</li>
<li>Generates <strong>legacy files</strong>, where those files contain modules that are grouped according to their likelihood to change, and according to whether they are required for initial load.</li>
<li>Names all files with a content hash.</li>
<li>Generates a manifest for the build, where the manifest includes:<ul>
<li>a <code>baseUrl</code> property whose value is a string that should be used as the base for generating a full URL to a resource, using the pattern <code>&lt;baseUrl&gt;/&lt;resource.version&gt;</code></li>
<li>a <code>resources</code> property whose value is an object that, for each file, provides:<ul>
<li>the most recent <em>changed</em> version</li>
<li>a list of individual files which, when any of the files is requested, should trigger a push of the bundle</li>
</ul>
</li>
<li>a <code>legacyResources</code> property whose value is an object that, for each legacy bundle, provices:<ul>
<li>the most recent <em>changed</em> version</li>
<li>an optional <code>initialLoad</code> property whose value is <code>true</code> if the resource should be loaded immediately by the scout</li>
</ul>
</li>
</ul>
</li>
<li>Generates an HTTP/2 scout file* that provides the ability to load resources, and that loads a manifest.</li>
<li>Generates an HTTP/1 scout file* that provides the ability to load resources, and that <em>includes</em> the manifest.</li>
<li>Uploads the static resources.</li>
<li>Updates a delivery mechanism (such as a server or a CDN) based on the data in the new manifest.</li>
</ul>
<p>The versioning and caching of the resources would be as follows:</p>
<ul>
<li><strong>manifest</strong> Unversioned. Short cache time, e.g. 10 minutes, to allow for the rapid uptake of new resources for HTTP/2 browsers.</li>
<li><strong>scout</strong> Unversioned. Medium cache time, e.g. one day, assuming the contents of this file are considered relatively stable.</li>
<li><strong>legacy-scout</strong> Unversioned. Short cache time, e.g. 10 minutes, to allow for the rapid uptake of new resources for legacy browsers.</li>
<li><strong>application and vendor files</strong> Versioned. Long cache time, e.g. one year, given that new versions will be picked up when a new manifest is loaded.</li>
</ul>
<p><small>* In applications that a) control the initial HTML payload, and b) only use the scout to load other resources, it may not make sense to have a separate scout; it might be sufficient to just load those resources via <code>&lt;script&gt;</code> and <code>&lt;link&gt;</code> tags in the HTML itself. This approach isn&#39;t viable for applications that do not control the initial HTML payload, such as third-party applications.</small></p>
<h2>Reality check</h2><p>In several places so far, I’ve talked about the need for a server to make decisions about which resources it delivers, and when and how it delivers them. As I alluded to earlier, this could be profoundly challenging for CDNs, which traditionally simply receive a request and return a single resource in response. It also suggests the need for close collaboration between client and server development teams, and an increased knowledge of server-side technology for client-side developers.</p>
<p>CDN support of HTTP/2 in general is rather disappointing, with some major vendors providing nothing more than vague timelines for non-specific support.</p>
<p>As of this writing, I&#39;m unaware of CDNs that support any notion of server push, but I&#39;d be happy to find I am ill-informed. Ideally, CDNs need to provide applications with the ability to express how static assets relate to each other -- a task complicated by the fact that those relationships may be situational, such as in the case where an application doesn&#39;t want to push an asset that was just pushed to the same client 10 seconds before. One-size-fits-all push could be accomplished by setting a header on a file, indicating that other files should be pushed alongside it, but that doesn&#39;t allow for expressing more nuanced rules.</p>
<p>Even for applications that just want to split their payload into smaller files to take advantage of HTTP/2, and that don&#39;t intend to use server push, there is still a gap when it comes to providing a positive experience for HTTP/1.1 clients. CDNs need to surface the ability to change a response not just based on the URL that is requested, but the protocol of the request. Without this ability, we&#39;ll be stuck having to choose which protocol to support.</p>
<p>There is also work to be done on tooling, especially if we want to support HTTP/2 without significantly degrading the experience for legacy browsers. Ideally, our build tooling would figure out the optimal combination of files for us, with a knowledge of how the application was bundled previously so as not to squander past caching.</p>
<p>The developer story for HTTP/2 also leaves a lot to be desired as of this writing. Front-end developers are among the most likely in an organization to advocate for this new technology, but my experiences over a few weeks of learning about HTTP/2 suggest that the effort required to set up even a local environment will stretch the comfort zone for many. With a working local environment in hand, the tools to understand the differences between HTTP/2 and HTTP/1 behavior are limited and often confusing. Chrome presents information in its network tab that seems to conflict with the wall of text in its net-internals tool, especially when it comes to server push . Charles Proxy doesn&#39;t yet speak HTTP/2. Firefox shows pushed resources as an entry in the network tab, but they appear as though they were never received. <a href="https://nghttp2.org/">nghttp2</a> provides great insight into how an HTTP/2 server is behaving, but it doesn&#39;t speak HTTP/1.1, so you can&#39;t use it to do comparisons. Measuring performance using a tool like WebPagetest requires a real certificate, which you may not have handy if you&#39;re just trying to experiment.</p>
<p>Alex wrote his 2013 post to document the product of years of experience in creating performant HTTP/1.1 deployments. HTTP/2 means we need to rethink everything we know about shipping applications to the web, and while the building blocks are there, there&#39;s still much to figure out about how we&#39;ll use them; the &quot;right&quot; answers are, in many cases, still TBD while we wait for vendors to act.</p>
<h2>Further Reading</h2><p>I&#39;ve been bookmarking useful <a href="https://pinboard.in/u:rmurphey/t:http2/">HTTP/2 resources</a> as I come across them.</p>
<h2>Thanks</h2><p>Thanks to the many folks who have talked to me about the ideas in this post, but especially to Lon Ingram, Jake Archibald, and Andy Davies.</p>
]]></content:encoded></item><item><title>Five Questions</title><guid isPermaLink="false">five-questions</guid><link>http://rmurphey.com/2015/10/08/five-questions</link><pubDate>Thu, 08 Oct 2015 22:00:00 +0000</pubDate><description><![CDATA[I recently started in a new role: I&#39;m the dev lead of a project that was
already in the hands of a group of skilled developers before I showed up, a
project whose scope and technologies extend far beyond the experiences I&#39;ve had
up until now.
As you might imagine, there have been a lot of challenges, but one that&#39;s been
particularly interesting has been figuring out how to meaningfully contribute
to decisions about systems I don&#39;t intimately understand. It&#39;s easy to be
inclined to sit those conversations out: I really don&#39;t yet know enough to
participate, and the &quot;who am I to have a say?&quot; instinct is strong.
The problem: that attitude will ensure that I never know enough to
participate, and though I am definitely out of my comfort zone, my job -- the
job I asked to do, and the job I have been asked to do -- is to participate,
to learn, and to change the definition of my comfort zone.
While I may not have the project-specific experience to lean on, I&#39;m finding
that there are a few questions that help me understand, discuss, and -- ultimately -- consent or object to a technical plan. They&#39;re questions that
seem to work well across a spectrum of discussions; they work whether we&#39;re
talking about a wholly new system, a migration from an old system, or a
solution to a particularly prickly problem.
These questions don&#39;t just help me gain a better understanding of a topic, or
help me make better decisions; they&#39;ve also helped me reframe my understanding
of my role as a lead.
Question 1: What are we doing and why?When I hear the answer, I&#39;m listening for whether the developer is clearly
articulating the problem and the solution. Do we clearly understand the
problem? Is the solution magical, or can we explain why it works? Are we
solving more than the problem, and thereby incurring unnecessary risk? Does the
developer agree that the work is necessary?
Question 2: How could it go wrong?A developer who says nothing can go wrong probably hasn&#39;t been a developer
for very long. I want to hear far-fetched scenarios, and an explanation for
why they&#39;re far-fetched. I want to hear worst-case scenarios; good developers
have already thought about these plenty, they&#39;ve worked to avoid them, and
yet they acknowledge their existence. The goal of this question isn&#39;t to plan
for everything; rather, the answers provide context for poking at assumptions.
Question 3: How will we know if it&#39;s going wrong?This is probably my favorite question. If we&#39;re talking about developing a new
system or project, it&#39;s a question of how we&#39;ll know we&#39;re off track, which
leads to clear milestones and check-in points. If it&#39;s a migration to a new
system, or a solution to a bad bug, it&#39;s a question of how we&#39;ll know that
the new state is less good than we thought it would be. If the answer is
&quot;customers will tell us,&quot; we&#39;re in dangerous territory. For services, I hope to hear answers about automated monitoring, but manual checks will suffice. For
new projects, I hope to hear near-term goals that will help us gauge progress.
Question 4: What will we do if it goes wrong?The answer to this may not always be knowable -- obviously we won&#39;t always know
the ways things will go wrong -- but it&#39;s a useful exercise nonetheless. The
answer may be &quot;we&#39;ll have to revert back to the old system and that will be
very hard,&quot; but that at least helps me understand the stakes of the decision.
For new projects, this is a great way to identify the point of no return --
that is, the point in the project where starting over or changing course
becomes prohibitive.
Question 5: Is there an &quot;undo&quot; button?Sometimes, the worst happens. Do we have an escape hatch? How hard will it be
to add one later vs. adding one now? Again, it may be OK if we don&#39;t have a
rollback plan, but knowing that answer should help guide the decision
about whether to proceed.

I&#39;m learning that a lot of what makes me kind of OK (I hope!) at this dev lead
thing isn&#39;t a deep knowledge of the specific technologies that are the
underpinning of the project (though it&#39;s certainly important that I be able to
find my way around). Rather, it&#39;s my ability to ask these questions, and to
hear and understand the answers, and interpret them into action. I&#39;m thankful
to the team that is giving me the chance.]]></description><content:encoded><![CDATA[<p>I recently started in a new role: I&#39;m the dev lead of a project that was
already in the hands of a group of skilled developers before I showed up, a
project whose scope and technologies extend far beyond the experiences I&#39;ve had
up until now.</p>
<p>As you might imagine, there have been a lot of challenges, but one that&#39;s been
particularly interesting has been figuring out how to meaningfully contribute
to decisions about systems I don&#39;t intimately understand. It&#39;s easy to be
inclined to sit those conversations out: I really don&#39;t yet know enough to
participate, and the &quot;who am I to have a say?&quot; instinct is strong.</p>
<p>The problem: that attitude will ensure that I <em>never</em> know enough to
participate, and though I am definitely out of my comfort zone, my job -- the
job I asked to do, and the job I have been asked to do -- is to participate,
to learn, and to change the definition of my comfort zone.</p>
<p>While I may not have the project-specific experience to lean on, I&#39;m finding
that there are a few questions that help me understand, discuss, and -- ultimately -- consent or object to a technical plan. They&#39;re questions that
seem to work well across a spectrum of discussions; they work whether we&#39;re
talking about a wholly new system, a migration from an old system, or a
solution to a particularly prickly problem.</p>
<p>These questions don&#39;t just help me gain a better understanding of a topic, or
help me make better decisions; they&#39;ve also helped me reframe my understanding
of my role as a lead.</p>
<h2>Question 1: What are we doing and why?</h2><p>When I hear the answer, I&#39;m listening for whether the developer is clearly
articulating the problem and the solution. Do we clearly understand the
problem? Is the solution magical, or can we explain why it works? Are we
solving more than the problem, and thereby incurring unnecessary risk? Does the
developer agree that the work is necessary?</p>
<h2>Question 2: How could it go wrong?</h2><p>A developer who says nothing can go wrong probably hasn&#39;t been a developer
for very long. I want to hear far-fetched scenarios, and an explanation for
why they&#39;re far-fetched. I want to hear worst-case scenarios; good developers
have already thought about these plenty, they&#39;ve worked to avoid them, and
yet they acknowledge their existence. The goal of this question isn&#39;t to plan
for everything; rather, the answers provide context for poking at assumptions.</p>
<h2>Question 3: How will we know if it&#39;s going wrong?</h2><p>This is probably my favorite question. If we&#39;re talking about developing a new
system or project, it&#39;s a question of how we&#39;ll know we&#39;re off track, which
leads to clear milestones and check-in points. If it&#39;s a migration to a new
system, or a solution to a bad bug, it&#39;s a question of how we&#39;ll know that
the new state is less good than we thought it would be. If the answer is
&quot;customers will tell us,&quot; we&#39;re in dangerous territory. For services, I hope to hear answers about automated monitoring, but manual checks will suffice. For
new projects, I hope to hear near-term goals that will help us gauge progress.</p>
<h2>Question 4: What will we do if it goes wrong?</h2><p>The answer to this may not always be knowable -- obviously we won&#39;t always know
the ways things will go wrong -- but it&#39;s a useful exercise nonetheless. The
answer may be &quot;we&#39;ll have to revert back to the old system and that will be
very hard,&quot; but that at least helps me understand the stakes of the decision.
For new projects, this is a great way to identify the point of no return --
that is, the point in the project where starting over or changing course
becomes prohibitive.</p>
<h2>Question 5: Is there an &quot;undo&quot; button?</h2><p>Sometimes, the worst happens. Do we have an escape hatch? How hard will it be
to add one later vs. adding one now? Again, it may be OK if we don&#39;t have a
rollback plan, but knowing that answer should help guide the decision
about whether to proceed.</p>
<hr>
<p>I&#39;m learning that a lot of what makes me kind of OK (I hope!) at this dev lead
thing isn&#39;t a deep knowledge of the specific technologies that are the
underpinning of the project (though it&#39;s certainly important that I be able to
find my way around). Rather, it&#39;s my ability to ask these questions, and to
hear and understand the answers, and interpret them into action. I&#39;m thankful
to the team that is giving me the chance.</p>
]]></content:encoded></item><item><title>Pausing Office Hours</title><guid isPermaLink="false">pausing-office-hours</guid><link>http://rmurphey.com/2015/08/04/pausing-office-hours</link><pubDate>Tue, 04 Aug 2015 20:00:00 +0000</pubDate><description><![CDATA[I started doing office hours at the beginning of the year; it&#39;s been tremendous fun, super eye-opening, and just generally quite rewarding. I won&#39;t lie: it&#39;s also been a lot of time, especially the first few weeks when I terribly underestimated how many people would sign up.
I was out for dinner with a friend tonight and she asked me how it was going, and I had to pause for a second when I realized that we might not be sitting there, right then, if she hadn&#39;t signed up for a slot. Things like that -- and getting to see, on stage, speakers who trusted me with their talk idea months ago -- make me super-glad that I let (mostly) strangers put 30 minutes on my calendar a couple-few dozen times these last few months. Hopefully I helped a few people along the way too.
In the last couple of weeks I&#39;ve started a new role at Bazaarvoice: after a few months of working on some fairly independent projects, I&#39;m back to leading a team. I used to get a kick out of being the female lead of an otherwise-all-male team; now I&#39;m honored and humbled to get to work with a team where I am one of five women. The ratio isn&#39;t quite 50-50, but it&#39;s closer than any team I&#39;ve worked on before. It&#39;s also the first lead role I&#39;ve had where my responsibilities span beyond the front end, a prospect both exciting and daunting.
Which is to say: My hands seem a bit fuller than they did back when I started office hours, so for now, it&#39;s time to hit the pause button while I focus on my new team. If you&#39;re interested in picking up where I left off, hit me up and I&#39;m happy to spread the word.]]></description><content:encoded><![CDATA[<p>I started doing <a href="http://rmurphey.com/blog/2015/01/11/office-hours/">office hours</a> at the beginning of the year; it&#39;s been tremendous fun, super eye-opening, and just generally quite rewarding. I won&#39;t lie: it&#39;s also been a lot of time, especially the first few weeks when I terribly underestimated how many people would sign up.</p>
<p>I was out for dinner with a friend tonight and she asked me how it was going, and I had to pause for a second when I realized that we might not be sitting there, right then, if she hadn&#39;t signed up for a slot. Things like that -- and getting to see, on stage, speakers who trusted me with their talk idea months ago -- make me super-glad that I let (mostly) strangers put 30 minutes on my calendar a couple-few dozen times these last few months. Hopefully I helped a few people along the way too.</p>
<p>In the last couple of weeks I&#39;ve started a new role at Bazaarvoice: after a few months of working on some fairly independent projects, I&#39;m back to leading a team. I used to get a kick out of being the female lead of an otherwise-all-male team; now I&#39;m honored and humbled to get to work with a team where I am one of <em>five</em> women. The ratio isn&#39;t quite 50-50, but it&#39;s closer than any team I&#39;ve worked on before. It&#39;s also the first lead role I&#39;ve had where my responsibilities span beyond the front end, a prospect both exciting and daunting.</p>
<p>Which is to say: My hands seem a bit fuller than they did back when I started office hours, so for now, it&#39;s time to hit the pause button while I focus on my new team. If you&#39;re interested in picking up where I left off, hit me up and I&#39;m happy to spread the word.</p>
]]></content:encoded></item><item><title>So You're Going on a Podcast</title><guid isPermaLink="false">tech-podcast-recording-tips</guid><link>http://rmurphey.com/2015/07/27/tech-podcast-recording-tips</link><pubDate>Mon, 27 Jul 2015 20:00:00 +0000</pubDate><description><![CDATA[I got a fair bit of experience recording a podcast back in the yayQuery days; when I decided to start another one, the technical side of it felt pretty familiar, minus the part where yayQuery was crazy enough to also record video. Back then, we mostly were talking to each other, so it was easy for us to all be on the same page about the technical requirements: headphones always, typing never (at least when you&#39;re also talking), and buy a good microphone. We also had 20-some episodes to get good at working with each other.
I&#39;ve been recording the TTL Podcast for a few months now; it&#39;s a show with a different guest every week, so the tech challenges are different, and each show is completely different from the last. It has been great fun, and I can&#39;t believe how lucky I am to get to ask all of these people to talk to me and they keep saying yes.
I&#39;ve learned a few things about how to be a good podcast guest along the way, but I haven&#39;t always been good at sharing them ahead of time with guests. This, then, is really just an attempt to write them down in a single place, with the added benefit that maybe they will be useful to others. This is mostly focused on being a guest of a show; I have lots to say about being a host, but I feel like that&#39;s a lot more complicated than this.
Technical
Wear headphones, preferably the best ones you own. The iPhone headphones aren&#39;t nice, and actually leak noise like crazy. I alternate between using Klipsch and Shure (sorry, not sure of the model, so no link) in-ear headphones, both of which have a nice silicone seal to keep the sound I&#39;m hearing in my ears and out of my microphone.
Use the best microphone you can. A MacBook&#39;s built-in microphone is decent enough in a pinch, but it&#39;s probably worth springing for an external microphone. I used the AT2020 for most of the yayQuery episodes, but I stepped up to a Shure SM7B to record TTL at the suggest of Alex Sexton. The USB mic is just fine and very reasonably priced; the Shure sounds absolutely lovely but is a bit more of an investment. If you don&#39;t want to spring for a mic, see if someone in your office has one you can borrow. If you have questions about audio gear, I am mostly clueless beyond what I&#39;ve written above.
If you&#39;re a guest, always plan to record your side of the conversation. (If you&#39;re a host, always plan to record all sides of the conversation; I&#39;ve lost an episode by failing to do this.) On a Mac, Quicktime has a simple audio recording feature. There&#39;s also plenty of other software that will do the same.

Preparation
Listen to at least one episode of the show before you go on (and possibly before you even agree to go on).
Ask the host what they want to talk to you about, and try to have a decent sense of the outline of the conversation before you start. If the host doesn&#39;t have great guidance -- she&#39;s almost certainly less familiar with your work than you are -- it&#39;s generally very welcome for you to propose an outline yourself.
If you have access to a soundproofed room, consider using it. Avoid large, echo-y rooms, or rooms that will be subject to a lot of hallway or construction noise.

The Show
Consider your biological needs before you start recording :) Except for a live show, you&#39;re always welcome to pause if you need to step away, but you may find yourself distracted in the meantime. Make sure you have water nearby!
Silence phone notifications (no vibrating phones; silence means silent); on your computer, close Twitter, your mail client, etc.; option-click the Notification Center icon in your Mac toolbar to put it in do-not-disturb mode (thanks Ralph Holzmann for that tip).
Unless it&#39;s a live show, feel free to pause and try again if you make a mistake or say something wrong. It&#39;s important that you announce that you&#39;re starting over, then pause, then start over -- that way it&#39;s easy to fix in post-production.
Remember that a podcast is a conversation, not a presentation. Unlike a presentation, you&#39;re conversing with a host who knows the audience and can ask you the questions that will help that audience connect with you. Use a video chat so you can watch the host for visual cues that she might want to interject.

That&#39;s my list, though undoubtedly I&#39;ve left things out. If you have stuff to add, please share in the comments —]]></description><content:encoded><![CDATA[<p>I got a fair bit of experience recording a podcast back in the <a href="http://yayquery.com">yayQuery</a> days; when I decided to start another one, the technical side of it felt pretty familiar, minus the part where yayQuery was crazy enough to also record video. Back then, we mostly were talking to each other, so it was easy for us to all be on the same page about the technical requirements: headphones always, typing never (at least when you&#39;re also talking), and buy a good microphone. We also had 20-some episodes to get good at working with each other.</p>
<p>I&#39;ve been recording the <a href="http://ttlpodcast.com">TTL Podcast</a> for a few months now; it&#39;s a show with a different guest every week, so the tech challenges are different, and each show is completely different from the last. It has been great fun, and I can&#39;t believe how lucky I am to get to ask all of these people to talk to me and they keep saying yes.</p>
<p>I&#39;ve learned a few things about how to be a good podcast guest along the way, but I haven&#39;t always been good at sharing them ahead of time with guests. This, then, is really just an attempt to write them down in a single place, with the added benefit that maybe they will be useful to others. This is mostly focused on being a guest of a show; I have lots to say about being a host, but I feel like that&#39;s a lot more complicated than this.</p>
<h2>Technical</h2><ul>
<li>Wear headphones, preferably the best ones you own. The iPhone headphones aren&#39;t nice, and actually leak noise like crazy. I alternate between using <a href="http://www.klipsch.com/R6i">Klipsch</a> and Shure (sorry, not sure of the model, so no link) in-ear headphones, both of which have a nice silicone seal to keep the sound I&#39;m hearing in my ears and out of my microphone.</li>
<li>Use the best microphone you can. A MacBook&#39;s built-in microphone is decent enough in a pinch, but it&#39;s probably worth springing for an external microphone. I used the <a href="http://www.audio-technica.com/cms/wired_mics/a0933a662b5ed0e2/">AT2020</a> for most of the yayQuery episodes, but I stepped up to a <a href="http://www.shure.com/americas/products/microphones/sm/sm7b-vocal-microphone">Shure SM7B</a> to record TTL at the suggest of Alex Sexton. The USB mic is just fine and very reasonably priced; the Shure sounds absolutely lovely but is a bit more of an investment. If you don&#39;t want to spring for a mic, see if someone in your office has one you can borrow. If you have questions about audio gear, I am mostly clueless beyond what I&#39;ve written above.</li>
<li>If you&#39;re a guest, always plan to record your side of the conversation. (If you&#39;re a host, always plan to record <em>all</em> sides of the conversation; I&#39;ve lost an episode by failing to do this.) On a Mac, Quicktime has a simple audio recording feature. There&#39;s also plenty of other software that will do the same.</li>
</ul>
<h2>Preparation</h2><ul>
<li>Listen to at least one episode of the show before you go on (and possibly before you even agree to go on).</li>
<li>Ask the host what they want to talk to you about, and try to have a decent sense of the outline of the conversation before you start. If the host doesn&#39;t have great guidance -- she&#39;s almost certainly less familiar with your work than you are -- it&#39;s generally very welcome for you to propose an outline yourself.</li>
<li>If you have access to a soundproofed room, consider using it. Avoid large, echo-y rooms, or rooms that will be subject to a lot of hallway or construction noise.</li>
</ul>
<h2>The Show</h2><ul>
<li>Consider your biological needs before you start recording :) Except for a live show, you&#39;re always welcome to pause if you need to step away, but you may find yourself distracted in the meantime. Make sure you have water nearby!</li>
<li>Silence phone notifications (no vibrating phones; silence means <em>silent</em>); on your computer, close Twitter, your mail client, etc.; option-click the Notification Center icon in your Mac toolbar to put it in do-not-disturb mode (thanks Ralph Holzmann for that tip).</li>
<li>Unless it&#39;s a live show, feel free to pause and try again if you make a mistake or say something wrong. It&#39;s important that you announce that you&#39;re starting over, then pause, then start over -- that way it&#39;s easy to fix in post-production.</li>
<li>Remember that a podcast is a conversation, not a presentation. Unlike a presentation, you&#39;re conversing with a host who knows the audience and can ask you the questions that will help that audience connect with you. Use a video chat so you can watch the host for visual cues that she might want to interject.</li>
</ul>
<p>That&#39;s my list, though undoubtedly I&#39;ve left things out. If you have stuff to add, please share in the comments —</p>
]]></content:encoded></item><item><title>Browser Testing and Code Coverage with Karma, Tape, and Webpack</title><guid isPermaLink="false">karma-webpack-tape-code-coverage</guid><link>http://rmurphey.com/2015/07/20/karma-webpack-tape-code-coverage</link><pubDate>Mon, 20 Jul 2015 13:00:00 +0000</pubDate><description><![CDATA[We recently set up a new project at Bazaarvoice for centralizing common UI modules. We started by using node-tap for unit tests, but given that these are UI modules, we quickly switched to using tape, because it has a fairly easy browser testing story with the help of Karma.
One thing that node-tap provided that tape did not provide out of the box was the ability to measure the code coverage of unit tests. Karma does provide this, but getting it hooked up while using Webpack -- which is our build tool of choice these days -- wasn&#39;t quite as clear as I would have liked. If you&#39;re looking to use Karma, tape, and Webpack, then hopefully this post will help you spend a bit less time than I did.
What You&#39;ll NeedBy the time it was all said and done, I needed to npm install the following modules:

karma
karma-phantomjs-launcher
karma-chrome-launcher
karma-tap
karma-webpack
karma-coverage
istanbul-instrumenter-loader
tape

The directory structure was simple:

a root directory, containing karma.conf.js and package.json
a lib subdirectory, containing module files
a test/unit subdirectory, containing the unit tests

An example application file at lib/global/index.js looked like this:
/**
 *  @fileOverview Provides a reference to the global object
 *
 *  Functions created via the Function constructor in strict mode are sloppy
 *  unless the function body contains a strict mode pragma. This is a reliable
 *  way to obtain a reference to the global object in any ES3+ environment.
 *  see http://stackoverflow.com/a/3277192/46867
 */
&#39;use strict&#39;;

module.exports = (new Function(&#39;return this;&#39;))();

An example test in test/unit/global/index.js looked like this:
var test = require(&#39;tape&#39;);
var global = require(&#39;../../../lib/global&#39;);

test(&#39;Exports window&#39;, function (t) {
  t.equal(global, window);
  t.end();
});

Testing CommonJS Modules in the BrowserThe applications that consume these UI modules use Webpack, so we author the modules (and their tests) as CommonJS modules. Of course, browsers can&#39;t consume CommonJS directly, so we need to generate files that browsers can consume. There are several tools we can choose for this task, but since we&#39;ve otherwise standardized on Webpack, we wanted to use Webpack here as well.
Since our goal is to load the tests in the browser, we use the test file as the &quot;entry&quot; file. Webpack processes the dependencies of an entry file to generate a new file that contains the entry file&#39;s contents as well as the contents of its dependencies. This new file is the one that Karma will load into the browser to run the tests.
Getting this to happen is pretty straightforward with the karma-webpack plugin to Karma. The only catch was the need to tell Webpack how to deal with the fs dependency in tape. Here&#39;s the initial Karma configuration that got the tests running:
var webpack = require(&#39;webpack&#39;);

module.exports = function(config) {
  config.set({
    plugins: [
      require(&#39;karma-webpack&#39;),
      require(&#39;karma-tap&#39;),
      require(&#39;karma-chrome-launcher&#39;),
      require(&#39;karma-phantomjs-launcher&#39;)
    ],

    basePath: &#39;&#39;,
    frameworks: [ &#39;tap&#39; ],
    files: [ &#39;test/**/*.js&#39; ],

    preprocessors: {
      &#39;test/**/*.js&#39;: [ &#39;webpack&#39; ]
    },

    webpack: {
      node : {
        fs: &#39;empty&#39;
      }
    },

    webpackMiddleware: {
      noInfo: true
    },

    reporters: [ &#39;dots&#39; ],
    port: 9876,
    colors: true,
    logLevel: config.LOG_INFO,
    autoWatch: true,
    browsers: [&#39;Chrome&#39;],
    singleRun: false
  })
};

However, as I mentioned above, I wanted to get code coverage information. Karma offers the karma-coverage plugin, but that alone was insufficient in Webpack land: it would end up instrumenting the whole Webpack output -- including the test code itself! -- and thus reporting highly inaccurate coverage numbers.
I ended up reading a karma-webpack issue that told me someone else had already solved this exact problem by creating a Webpack loader to instrument modules at build time. By adjusting our Webpack configuration to only apply this loader to application modules -- not to test code or vendor code -- the Webpack output ends up properly instrumented for the karma-coverage plugin to work with it. Our final Karma config ends up looking like this:
var webpack = require(&#39;webpack&#39;);

module.exports = function(config) {
  config.set({
    plugins: [
      require(&#39;karma-webpack&#39;),
      require(&#39;karma-tap&#39;),
      require(&#39;karma-chrome-launcher&#39;),
      require(&#39;karma-phantomjs-launcher&#39;),
      require(&#39;karma-coverage&#39;)
    ],

    basePath: &#39;&#39;,
    frameworks: [ &#39;tap&#39; ],
    files: [ &#39;test/**/*.js&#39; ],

    preprocessors: {
      &#39;test/**/*.js&#39;: [ &#39;webpack&#39; ]
    },

    webpack: {
      node : {
        fs: &#39;empty&#39;
      },

      // Instrument code that isn&#39;t test or vendor code.
      module: {
        postLoaders: [{
          test: /\.js$/,
          exclude: /(test|node_modules)\//,
          loader: &#39;istanbul-instrumenter&#39;
        }]
      }
    },

    webpackMiddleware: {
      noInfo: true
    },

    reporters: [
      &#39;dots&#39;,
      &#39;coverage&#39;
    ],

    coverageReporter: {
      type: &#39;text&#39;,
      dir: &#39;coverage/&#39;
    },

    port: 9876,
    colors: true,
    logLevel: config.LOG_INFO,
    autoWatch: true,
    browsers: [&#39;Chrome&#39;],
    singleRun: false
  })
};

Even with the coverage hiccup, the speed with which I was able to get Karma set up the way I wanted -- and working with TravisCI -- was nothing short of breathtaking. I&#39;m late to the Karma party, but I had no idea it could be this easy. If you haven&#39;t checked it out yet, you should.]]></description><content:encoded><![CDATA[<p>We recently set up a new project at Bazaarvoice for centralizing common UI modules. We started by using <a href="https://github.com/isaacs/node-tap">node-tap</a> for unit tests, but given that these are <em>UI</em> modules, we quickly switched to using <a href="https://github.com/substack/tape">tape</a>, because it has a fairly easy browser testing story with the help of <a href="http://karma-runner.github.io/0.13/index.html">Karma</a>.</p>
<p>One thing that node-tap provided that tape did not provide out of the box was the ability to measure the code coverage of unit tests. Karma <em>does</em> provide this, but getting it hooked up while using <a href="http://webpack.github.io/">Webpack</a> -- which is our build tool of choice these days -- wasn&#39;t quite as clear as I would have liked. If you&#39;re looking to use Karma, tape, and Webpack, then hopefully this post will help you spend a bit less time than I did.</p>
<h2>What You&#39;ll Need</h2><p>By the time it was all said and done, I needed to <code>npm install</code> the following modules:</p>
<ul>
<li>karma</li>
<li>karma-phantomjs-launcher</li>
<li>karma-chrome-launcher</li>
<li>karma-tap</li>
<li>karma-webpack</li>
<li>karma-coverage</li>
<li>istanbul-instrumenter-loader</li>
<li>tape</li>
</ul>
<p>The directory structure was simple:</p>
<ul>
<li>a root directory, containing karma.conf.js and package.json</li>
<li>a lib subdirectory, containing module files</li>
<li>a test/unit subdirectory, containing the unit tests</li>
</ul>
<p>An example application file at lib/global/index.js looked like this:</p>
<pre><code class="language-js">/**
 *  @fileOverview Provides a reference to the global object
 *
 *  Functions created via the Function constructor in strict mode are sloppy
 *  unless the function body contains a strict mode pragma. This is a reliable
 *  way to obtain a reference to the global object in any ES3+ environment.
 *  see http://stackoverflow.com/a/3277192/46867
 */
&#39;use strict&#39;;

module.exports = (new Function(&#39;return this;&#39;))();
</code></pre>
<p>An example test in test/unit/global/index.js looked like this:</p>
<pre><code class="language-js">var test = require(&#39;tape&#39;);
var global = require(&#39;../../../lib/global&#39;);

test(&#39;Exports window&#39;, function (t) {
  t.equal(global, window);
  t.end();
});
</code></pre>
<h2>Testing CommonJS Modules in the Browser</h2><p>The applications that consume these UI modules use Webpack, so we author the modules (and their tests) as CommonJS modules. Of course, browsers can&#39;t consume CommonJS directly, so we need to generate files that browsers <em>can</em> consume. There are several tools we can choose for this task, but since we&#39;ve otherwise standardized on Webpack, we wanted to use Webpack here as well.</p>
<p>Since our goal is to load the tests in the browser, we use the test file as the &quot;entry&quot; file. Webpack processes the dependencies of an entry file to generate a new file that contains the entry file&#39;s contents as well as the contents of its dependencies. This new file is the one that Karma will load into the browser to run the tests.</p>
<p>Getting this to happen is pretty straightforward with the <code>karma-webpack</code> plugin to Karma. The only catch was the need to tell Webpack how to deal with the <code>fs</code> dependency in tape. Here&#39;s the initial Karma configuration that got the tests running:</p>
<pre><code class="language-js">var webpack = require(&#39;webpack&#39;);

module.exports = function(config) {
  config.set({
    plugins: [
      require(&#39;karma-webpack&#39;),
      require(&#39;karma-tap&#39;),
      require(&#39;karma-chrome-launcher&#39;),
      require(&#39;karma-phantomjs-launcher&#39;)
    ],

    basePath: &#39;&#39;,
    frameworks: [ &#39;tap&#39; ],
    files: [ &#39;test/**/*.js&#39; ],

    preprocessors: {
      &#39;test/**/*.js&#39;: [ &#39;webpack&#39; ]
    },

    webpack: {
      node : {
        fs: &#39;empty&#39;
      }
    },

    webpackMiddleware: {
      noInfo: true
    },

    reporters: [ &#39;dots&#39; ],
    port: 9876,
    colors: true,
    logLevel: config.LOG_INFO,
    autoWatch: true,
    browsers: [&#39;Chrome&#39;],
    singleRun: false
  })
};
</code></pre>
<p>However, as I mentioned above, I wanted to get code coverage information. Karma offers the <a href="https://github.com/karma-runner/karma-coverage">karma-coverage</a> plugin, but that alone was insufficient in Webpack land: it would end up instrumenting the whole Webpack output -- including the test code itself! -- and thus reporting highly inaccurate coverage numbers.</p>
<p>I ended up reading a <a href="https://github.com/webpack/karma-webpack/issues/21">karma-webpack issue</a> that told me someone else had already solved this exact problem by creating a <a href="https://github.com/deepsweet/istanbul-instrumenter-loader">Webpack loader</a> to instrument modules at build time. By adjusting our Webpack configuration to only apply this loader to application modules -- not to test code or vendor code -- the Webpack output ends up properly instrumented for the karma-coverage plugin to work with it. Our final Karma config ends up looking like this:</p>
<pre><code class="language-js">var webpack = require(&#39;webpack&#39;);

module.exports = function(config) {
  config.set({
    plugins: [
      require(&#39;karma-webpack&#39;),
      require(&#39;karma-tap&#39;),
      require(&#39;karma-chrome-launcher&#39;),
      require(&#39;karma-phantomjs-launcher&#39;),
      require(&#39;karma-coverage&#39;)
    ],

    basePath: &#39;&#39;,
    frameworks: [ &#39;tap&#39; ],
    files: [ &#39;test/**/*.js&#39; ],

    preprocessors: {
      &#39;test/**/*.js&#39;: [ &#39;webpack&#39; ]
    },

    webpack: {
      node : {
        fs: &#39;empty&#39;
      },

      // Instrument code that isn&#39;t test or vendor code.
      module: {
        postLoaders: [{
          test: /\.js$/,
          exclude: /(test|node_modules)\//,
          loader: &#39;istanbul-instrumenter&#39;
        }]
      }
    },

    webpackMiddleware: {
      noInfo: true
    },

    reporters: [
      &#39;dots&#39;,
      &#39;coverage&#39;
    ],

    coverageReporter: {
      type: &#39;text&#39;,
      dir: &#39;coverage/&#39;
    },

    port: 9876,
    colors: true,
    logLevel: config.LOG_INFO,
    autoWatch: true,
    browsers: [&#39;Chrome&#39;],
    singleRun: false
  })
};
</code></pre>
<p>Even with the coverage hiccup, the speed with which I was able to get Karma set up the way I wanted -- and working with <a href="http://travis-ci.org/">TravisCI</a> -- was nothing short of breathtaking. I&#39;m late to the Karma party, but I had no idea it could be this easy. If you haven&#39;t checked it out yet, you should.</p>
]]></content:encoded></item><item><title>The TTL Podcast</title><guid isPermaLink="false">ttl-podcast</guid><link>http://rmurphey.com/2015/05/11/ttl-podcast</link><pubDate>Mon, 11 May 2015 20:12:00 +0000</pubDate><description><![CDATA[Over the past several months, I&#39;ve been on a few different podcasts, plus I&#39;ve been having a lot of fun doing office hours, and generally talking a lot with other people who do the kind of work that I do. I&#39;ve particulary enjoyed talking about a subject that Alex Sexton dubbed Front-End Ops.
It has occurred to me that a) I&#39;m really super fortunate to get to have conversations about this stuff with super-smart people; b) there aren&#39;t yet a lot of great sources of information about front-end ops in the real world; and c) I used to be on a podcast and that sure was fun.
To that end, I threw a tweet out into the world to see who might be willing to talk to me and let me record the conversation. I got enough great responses that I decided to don my podcasting hat again for a little bit, and the result is the TTL Podcast.

If you&#39;re a mid-level front-end dev looking to level up, I&#39;d humbly suggest that this is very much a show for you -- you&#39;ll get to listen in on the thought process of some of the best front-end devs I know. That said, it&#39;s not just a show for those aspiring to take the front-end world by storm; it&#39;s also a chance for those who are already in the trenches, doing daily battle with WebDriver and trying to shave 10 more milliseconds off page load, to commiserate asynchronously. I know I personally have learned a ton -- in some cases I&#39;ve seen a new angle on a problem, and in other cases I&#39;ve had some serious Developer Guilt assuaged.
I&#39;ve released three episodes so far -- conversations with Alex, Burak Yiğit Kaya (Disqus), and Daniel Espeset and Seth Walker (Etsy). More episodes are in the pipeline, including developers from Walmart Labs, Yammer, FT Labs, and The Guardian.
While the initial focus has been on front-end ops, I can see the scope widening over time to cover, generally, the tools and challenges of doing front-end dev at significant scale. If you or someone you know would be a good person to talk to about that sort of thing, I hope you&#39;ll let me know.
While I&#39;m here, I want to give huge and sincere thanks to SauceLabs and Travis CI for their support of the show; to Una Kravets for finding time in her busy life to make me a website; to my sister, who&#39;s been kind enough to pitch in with the editing; and to Bazaarvoice for giving me the freedom to take on a project like this.]]></description><content:encoded><![CDATA[<p>Over the past several months, I&#39;ve been on a <a href="https://www.youtube.com/watch?v=1BYeDhvxm4Q">few</a> <a href="https://developertea.com/episodes/9413">different</a> <a href="http://www.motherboardpodcast.com/episode-11-rebecca-murphey/">podcasts</a>, plus I&#39;ve been having a lot of fun doing <a href="http://rmurphey.com/blog/2015/01/11/office-hours/">office hours</a>, and generally talking a lot with other people who do the kind of work that I do. I&#39;ve particulary enjoyed talking about a subject that Alex Sexton dubbed <a href="http://www.smashingmagazine.com/2013/06/11/front-end-ops/">Front-End Ops</a>.</p>
<p>It has occurred to me that a) I&#39;m really super fortunate to get to have conversations about this stuff with super-smart people; b) there aren&#39;t yet a lot of great sources of information about front-end ops in the real world; and c) I used to be on a <a href="http://yayquery.com">podcast</a> and that sure was fun.</p>
<p>To that end, I threw a tweet out into the world to see who might be willing to talk to me and let me record the conversation. I got enough great responses that I decided to don my podcasting hat again for a little bit, and the result is the <a href="http://ttlpodcast.com">TTL Podcast</a>.</p>
<p><img src="/images/ttl-podcast.png" alt="ttlpodcast.com"></p>
<p>If you&#39;re a mid-level front-end dev looking to level up, I&#39;d humbly suggest that this is very much a show for you -- you&#39;ll get to listen in on the thought process of some of the best front-end devs I know. That said, it&#39;s not just a show for those aspiring to take the front-end world by storm; it&#39;s also a chance for those who are already in the trenches, doing daily battle with WebDriver and trying to shave 10 more milliseconds off page load, to commiserate asynchronously. I know I personally have learned a ton -- in some cases I&#39;ve seen a new angle on a problem, and in other cases I&#39;ve had some serious Developer Guilt assuaged.</p>
<p>I&#39;ve released three episodes so far -- conversations with Alex, Burak Yiğit Kaya (Disqus), and Daniel Espeset and Seth Walker (Etsy). More episodes are in the pipeline, including developers from Walmart Labs, Yammer, FT Labs, and The Guardian.</p>
<p>While the initial focus has been on front-end ops, I can see the scope widening over time to cover, generally, the tools and challenges of doing front-end dev at significant scale. If you or someone you know would be a good person to talk to about that sort of thing, I hope you&#39;ll <a href="mailto:rmurphey+ttlpodcast@gmail.com">let me know</a>.</p>
<p>While I&#39;m here, I want to give huge and sincere thanks to <a href="https://saucelabs.com/">SauceLabs</a> and <a href="https://travis-ci.com/">Travis CI</a> for their support of the show; to <a href="http://una.github.io/">Una Kravets</a> for finding time in her busy life to make me a website; to my sister, who&#39;s been kind enough to pitch in with the editing; and to <a href="http://bazaarvoice.com">Bazaarvoice</a> for giving me the freedom to take on a project like this.</p>
]]></content:encoded></item><item><title>Writing Conference Proposals</title><guid isPermaLink="false">writing-conference-proposals</guid><link>http://rmurphey.com/2015/01/26/writing-conference-proposals</link><pubDate>Mon, 26 Jan 2015 21:00:00 +0000</pubDate><description><![CDATA[I&#39;ve had several office hours sessions in the last couple of weeks, and one topic that comes up again and again is how to write a talk description.
If you think about it, conference organizers don&#39;t have a whole lot to go on when they&#39;re choosing talks, unless they already know who you are. Even if your name is well-known, though, organizers may still not know who you are -- lots of conferences are taking a blind approach to selecting speakers. That means that no matter who you are, your talk description might be the only thing organizers have on which to base their decision. When you give your talk, you&#39;ll need to engage your audience; the abstract is your chance to engage the organizer.
After answering the question several times, I&#39;ve realized that I have a pretty explainable -- some might call it formulaic -- approach to writing abstracts for a certain common type of talk. It works well for talks about how you solved a problem, talks about how you came to learn a thing you didn&#39;t know, and even &quot;10 things you didn&#39;t know about X&quot; talks. I thought I&#39;d try to explain it here.
Paragraph 1: The contextThe first paragraph is where you set the scene, and make it clear to your reader that they have been in the situation you&#39;re going to talk about. This is where you establish a connection, baiting a hook that you&#39;ll set later.

You&#39;ve got the hang of this whole JavaScript thing. Your code works on ancient browsers, and positively sings on new ones. AMD, SPA, MVC -- you can do that stuff in your sleep.

Paragraph 2: Well, actually ...The second paragraph is where you break the bad news, which savvy readers may already know: the thing you laid out in the first paragraph is more complicated than it seems, or has downsides that people don&#39;t realize, or generally is a bad approach ... but only with the benefit of hindsight, which you just happen to have.

But now your users are trying to type in your Very Important Form, and nothing is showing up; that widget that&#39;s supposed to end up in a certain div is showing up somewhere completely different; and, rarely but not never, your app just doesn&#39;t load at all. You thought you had the hang of this whole JavaScript thing, but now you&#39;re in the world of third-party JavaScript, where all you control is a single script tag and where it&#39;s all but impossible to dream up every hostile environment in which your code will be expected to work. &quot;It works on my machine&quot; has never rung quite so hollow.

Paragraph 3: The promiseYou&#39;ve successfully induced a bit of anxiety in your reader -- and a strong desire to know what they don&#39;t know. The hook is set, so the last paragraph is the time to promise to relieve that anxiety -- but only if your talk is chosen!

In this talk, we&#39;ll take a look at some of the delightful bugs we&#39;ve had to solve at Bazaarvoice while working on the third-party JavaScript app that collects and displays ratings and reviews for some of the world&#39;s largest retailers. We&#39;ll also look at some strategies for early detection -- and at some scenarios where you are just plain SOL.

NextIt turns out that in the process of writing your abstract, you&#39;ve also written the most basic outline for your talk: on stage, you&#39;ll want to set the context, explain the complexity, then deliver on your promise. Pretty handy, if you ask me.]]></description><content:encoded><![CDATA[<p>I&#39;ve had several <a href="http://rmurphey.com/blog/2015/01/11/office-hours/">office hours</a> sessions in the last couple of weeks, and one topic that comes up again and again is how to write a talk description.</p>
<p>If you think about it, conference organizers don&#39;t have a whole lot to go on when they&#39;re choosing talks, unless they already know who you are. Even if your name is well-known, though, organizers may still not know who you are -- lots of conferences are taking a <a href="http://weareallaweso.me/for_curators/">blind approach</a> to selecting speakers. That means that no matter who you are, your talk description might be the only thing organizers have on which to base their decision. When you give your talk, you&#39;ll need to engage your audience; the abstract is your chance to engage the organizer.</p>
<p>After answering the question several times, I&#39;ve realized that I have a pretty explainable -- some might call it formulaic -- approach to writing abstracts for a certain common type of talk. It works well for talks about how you solved a problem, talks about how you came to learn a thing you didn&#39;t know, and even &quot;10 things you didn&#39;t know about X&quot; talks. I thought I&#39;d try to explain it here.</p>
<h2>Paragraph 1: The context</h2><p>The first paragraph is where you set the scene, and make it clear to your reader that they have been in the situation you&#39;re going to talk about. This is where you establish a connection, baiting a hook that you&#39;ll set later.</p>
<blockquote>
<p>You&#39;ve got the hang of this whole JavaScript thing. Your code works on ancient browsers, and positively sings on new ones. AMD, SPA, MVC -- you can do that stuff in your sleep.</p>
</blockquote>
<h2>Paragraph 2: Well, actually ...</h2><p>The second paragraph is where you break the bad news, which savvy readers may already know: the thing you laid out in the first paragraph is more complicated than it seems, or has downsides that people don&#39;t realize, or generally is a bad approach ... but only with the benefit of hindsight, which you just happen to have.</p>
<blockquote>
<p>But now your users are trying to type in your Very Important Form, and nothing is showing up; that widget that&#39;s supposed to end up in a certain div is showing up somewhere completely different; and, rarely but not never, your app just doesn&#39;t load at all. You <em>thought</em> you had the hang of this whole JavaScript thing, but now you&#39;re in the world of third-party JavaScript, where all you control is a single script tag and where it&#39;s all but impossible to dream up every hostile environment in which your code will be expected to work. &quot;It works on my machine&quot; has never rung quite so hollow.</p>
</blockquote>
<h2>Paragraph 3: The promise</h2><p>You&#39;ve successfully induced a bit of anxiety in your reader -- and a strong desire to know what they don&#39;t know. The hook is set, so the last paragraph is the time to promise to relieve that anxiety -- but only if your talk is chosen!</p>
<blockquote>
<p>In this talk, we&#39;ll take a look at some of the delightful bugs we&#39;ve had to solve at Bazaarvoice while working on the third-party JavaScript app that collects and displays ratings and reviews for some of the world&#39;s largest retailers. We&#39;ll also look at some strategies for early detection -- and at some scenarios where you are just plain SOL.</p>
</blockquote>
<h2>Next</h2><p>It turns out that in the process of writing your abstract, you&#39;ve also written the most basic outline for your talk: on stage, you&#39;ll want to set the context, explain the complexity, then deliver on your promise. Pretty handy, if you ask me.</p>
]]></content:encoded></item><item><title>Office Hours for Aspiring Speakers</title><guid isPermaLink="false">office-hours</guid><link>http://rmurphey.com/2015/01/11/office-hours</link><pubDate>Sun, 11 Jan 2015 21:00:00 +0000</pubDate><description><![CDATA[Update: Office hours are on hold for now while I settle into a new role at Bazaarvoice.
I&#39;m expecting that my 2015 is going to include a bit less speaking than in years past, so I&#39;m hoping I can use some of that newly available time to help new speakers find their way to the stage. To that end, I&#39;m kicking off &quot;office hours&quot; this week: a few slots a week where aspiring and up-and-coming speakers can borrow my ear for a bit to talk about their ideas, their fears, their questions, and their ambitions.
This idea isn&#39;t mine; I was inspired by a similar effort by Jen Myers, who has been offering mentoring sessions to aspiring speakers since 2013. I&#39;m forever indebted to the folks who helped me get through my first talk, and I&#39;ve been honored to give a gentle nudge to several other speakers in the years since.
If you&#39;re interested, you can sign up here. There&#39;s no script or agenda, and -- at least to start with -- I&#39;m not going to try to suggest who should or shouldn&#39;t sign up. If you think it would be useful to you, go for it! My only ask is that you be seriously interested in giving coherent, informative, engaging talks on technical topics.]]></description><content:encoded><![CDATA[<p><em>Update: Office hours are <a href="http://rmurphey.com/blog/2015/08/04/pausing-office-hours/">on hold</a> for now while I settle into a new role at Bazaarvoice.</em></p>
<p>I&#39;m expecting that my 2015 is going to include a bit less speaking than in years past, so I&#39;m hoping I can use some of that newly available time to help new speakers find their way to the stage. To that end, I&#39;m kicking off &quot;office hours&quot; this week: a few slots a week where aspiring and up-and-coming speakers can borrow my ear for a bit to talk about their ideas, their fears, their questions, and their ambitions.</p>
<p>This idea isn&#39;t mine; I was inspired by a similar effort by <a href="http://jenmyers.net/mentoring/">Jen Myers</a>, who has been offering mentoring sessions to aspiring speakers since 2013. I&#39;m forever indebted to the folks who helped me get through my first talk, and I&#39;ve been honored to give a gentle nudge to several other speakers in the years since.</p>
<p>If you&#39;re interested, you can <a href="http://calendly.com/rmurphey/office-hours">sign up here</a>. There&#39;s no script or agenda, and -- at least to start with -- I&#39;m not going to try to suggest who should or shouldn&#39;t sign up. If you think it would be useful to you, go for it! My only ask is that you be seriously interested in giving coherent, informative, engaging talks on technical topics.</p>
]]></content:encoded></item><item><title>Flying Lessons</title><guid isPermaLink="false">flying-lessons</guid><link>http://rmurphey.com/2014/11/01/flying-lessons</link><pubDate>Sat, 01 Nov 2014 0:00:00 +0000</pubDate><description><![CDATA[In October of 2008, I&#39;d been unemployed for about four months. I was doing some freelance work, but still feeling entirely uncertain about my ability to make a living. I decided to do what any marginally employed person might do: spend about $7,000 taking lessons to become a private pilot.
I have had a lifelong fascination with flying, and I&#39;d taken lessons in gliders when I was a kid -- every four hours of helping at the airfield got me one 15-minute lesson. If you don&#39;t know about gliders, they&#39;re just airplanes except without an engine. On the up side, that means your engine can&#39;t fail; on the down side, if you mess up when you&#39;re trying to land, you don&#39;t exactly get a second chance. That whole landing thing always terrified me, and I was off to college before I ever managed to &quot;solo.&quot;
A little more than 13 years later, I found myself in a Cessna 152 rolling down a 3,200-foot grass runway just outside of Durham, N.C., the 100-foot trees at the end of the runway growing ever-closer in the windshield until a dial on the instrument panel said we were going 55 knots -- which is basically like 55 miles per hour, but when you say knots you sound like a pilot (or a sailor, I guess) -- and the instructor said it was time to pull back on the yoke, ever so gently. And the plane lifted off the runway and the windshield was filled with more sky than ground and the trees passed below me and I was flying.
The FAA says you can get your license after just [40 hours of flying][ppl], plus a little bit of ground instruction, and on that October day I was sure I&#39;d knock it out in 45 hours, tops. I&#39;d been flying flight simulators since I was like six years old, when -- no joke -- I loaded the program off a cassette player. When I was a kid I went to the airport in my hometown to score expired navigational charts. Plus I had flown gliders, and plus, I was smart. How hard could it be?
You know how they say flying is safer than driving? You&#39;re pretty safe on that plane that you took to get here -- like, hundreds of times safer than in a car -- but it turns out that little planes flown by private pilots crash all the time. Pilots leave the gas caps unscrewed and all the fuel gets sucked out and they don&#39;t even notice until the engine sputters and dies. They overload their plane on a hot day and don&#39;t quite clear those trees at the end of that runway. They fly into weather for which their skills are no match, and end up running into a mountain -- euphemistically referred to as CFIT, or &quot;controlled flight into terrain.&quot;
Lots of private pilots are shining examples of the Dunning-Kruger effect: unskilled and unaware of it, much like myself in those first few lessons. A typical private pilot has fewer than [100 hours][nyt] of flying time --  airline pilots have thousands or even tens of thousands -- but they have that piece of plastic that says they can fly a plane, and gosh darnit, they are going to fly a plane.
It would eventually take me six months and more than 60 hours to get my license, and by the end I was in no rush. In one of many sleepless nights during my training, I came to realize a thing: learning to fly wasn&#39;t just about learning to take off and land and get from point A to point B. Barring infinite money and infinite time, it was about learning how to be permanently new at a thing that could kill me if I screwed it up.
It&#39;s been six years since I rolled down that runway, and six years later, it occurs to me that there are a whole lot of parallels between that experience and my life as a developer. I remember showing up to the inaugural JSConf in 2009, feeling pretty secure in my standing as a bit of a jQuery badass, and being promptly blown away by just how large the JavaScript world actually was, even in 2009. I felt intimidated and overwhelmed and, I won&#39;t lie, a bit embarrassed at how little I actually knew and understood. Over time, though, I&#39;ve realized: this is just the permanent state of things. I&#39;d better get used to it.
This, then, is a talk about how to be new at a thing.

not about learning new things, about being new at a thing

Aviate, Navigate, Communicate
translation: know your priorities
flying: nowhere to pull over
priorites when flying: 1) do not die, 2) get where you&#39;re going
priorities at a new job: balance learning with project delivery.
study, ask, do
on my team, we try to be explicit about this with new folks.

All Available Information
FAR §91.103
flying: you are responsible for not dying. you&#39;re expected to know about the weather, the airport you&#39;re flying to, the route you&#39;re taking, your aircraft&#39;s limitations, your own limitations, etc. the FAA will occasionally do &quot;ramp checks&quot; to make sure you&#39;ve done your due diligence.
ultimately, this is all about not making assumptions. just because it&#39;s sunny out doesn&#39;t mean it will be in a couple of hours. just because you flew to an airport on a half tank of fuel last time doesn&#39;t mean it will work out the same way today, when there&#39;s a 40-knot headwind.
&quot;all available information&quot; is somewhat preposterous on its face these days; the amount of information available to us is unreal. i think of this more as a challenge: what information could i get that i haven&#39;t gotten? could it possibly be useful?
&quot;all available information&quot; means being diligent and methodical about gathering facts before making a decision. this is a lot slower than making decisions based on assumptions. later, when you&#39;re not new, you can make decisions based on assumptions -- we might call that instinct. but not when you&#39;re new.
when i was hired at bv, they brought me on to improve the organization and maintainability of a project&#39;s codebase. i didn&#39;t just read the code and get to work tearing it apart; i interviewed every developer on the team to find out where their pain points were, and learned that certain parts of the code, while terrible, weren&#39;t worth spending time on.
what information could you get that you haven&#39;t gotten? could it possibly be useful?

Climb, Communicate, Confess, Comply
sometimes we get lost. it&#39;s ok!
step 1 is to realize you&#39;re lost
step 2 is to explain what&#39;s wrong
step 3 is to ask for help
step 4 is to do what they say

i think a lot of people are reluctant to ask for help because they&#39;re afraid of how people will respond when it becomes clear they don&#39;t know everything. of course they don&#39;t know everything, they are new! i think also though that people don&#39;t know how to ask for help. in my experience, people are actually incredibly willing to help -- as long as you&#39;ve done your due diligence. this means you&#39;ve read the docs, done your google due diligence, read the surrounding code, explored the problem with debugging tools, and produced a reduced test case that demonstrates your problem.

developing the skills to make a good request for help is essential to being good at being new at a thing.

The ChecklistThe Go-Around
sometimes, despite our best efforts, we need to start over
this isn&#39;t exceptional -- it&#39;s an entirely normal maneuver

Your code is not a reflection of you. It isn’t a reflection of your beliefs, your upbringing, or your ability to be a good person. Your code is [...] a reflection of your thinking process at the time that you wrote it. - @rockbot


Trust Your Instruments
translation: learn how to tell what&#39;s going on when you don&#39;t know what&#39;s going on]]></description><content:encoded><![CDATA[<p>In October of 2008, I&#39;d been unemployed for about four months. I was doing some freelance work, but still feeling entirely uncertain about my ability to make a living. I decided to do what any marginally employed person might do: spend about $7,000 taking lessons to become a private pilot.</p>
<p>I have had a lifelong fascination with flying, and I&#39;d taken lessons in gliders when I was a kid -- every four hours of helping at the airfield got me one 15-minute lesson. If you don&#39;t know about gliders, they&#39;re just airplanes except without an engine. On the up side, that means your engine can&#39;t fail; on the down side, if you mess up when you&#39;re trying to land, you don&#39;t exactly get a second chance. That whole landing thing always terrified me, and I was off to college before I ever managed to &quot;solo.&quot;</p>
<p>A little more than 13 years later, I found myself in a Cessna 152 rolling down a 3,200-foot grass runway just outside of Durham, N.C., the 100-foot trees at the end of the runway growing ever-closer in the windshield until a dial on the instrument panel said we were going 55 knots -- which is basically like 55 miles per hour, but when you say knots you sound like a pilot (or a sailor, I guess) -- and the instructor said it was time to pull back on the yoke, ever so gently. And the plane lifted off the runway and the windshield was filled with more sky than ground and the trees passed below me and I was flying.</p>
<p>The FAA says you can get your license after just [40 hours of flying][ppl], plus a little bit of ground instruction, and on that October day I was sure I&#39;d knock it out in 45 hours, tops. I&#39;d been flying flight simulators since I was like six years old, when -- no joke -- I loaded the program off a cassette player. When I was a kid I went to the airport in my hometown to score expired navigational charts. Plus I had flown gliders, and plus, I was smart. How hard could it be?</p>
<p>You know how they say flying is safer than driving? You&#39;re pretty safe on that plane that you took to get here -- like, hundreds of times safer than in a car -- but it turns out that little planes flown by private pilots crash all the time. Pilots leave the gas caps unscrewed and all the fuel gets sucked out and they don&#39;t even notice until the engine sputters and dies. They overload their plane on a hot day and don&#39;t quite clear those trees at the end of that runway. They fly into weather for which their skills are no match, and end up running into a mountain -- euphemistically referred to as CFIT, or &quot;controlled flight into terrain.&quot;</p>
<p>Lots of private pilots are shining examples of the Dunning-Kruger effect: unskilled and unaware of it, much like myself in those first few lessons. A typical private pilot has fewer than [100 hours][nyt] of flying time --  airline pilots have thousands or even tens of thousands -- but they have that piece of plastic that says they can fly a plane, and gosh darnit, they are going to fly a plane.</p>
<p>It would eventually take me six months and more than 60 hours to get my license, and by the end I was in no rush. In one of many sleepless nights during my training, I came to realize a thing: learning to fly wasn&#39;t just about learning to take off and land and get from point A to point B. Barring infinite money and infinite time, it was about learning how to be permanently new at a thing that could kill me if I screwed it up.</p>
<p>It&#39;s been six years since I rolled down that runway, and six years later, it occurs to me that there are a whole lot of parallels between that experience and my life as a developer. I remember showing up to the inaugural JSConf in 2009, feeling pretty secure in my standing as a bit of a jQuery badass, and being promptly blown away by just how large the JavaScript world actually was, even in 2009. I felt intimidated and overwhelmed and, I won&#39;t lie, a bit embarrassed at how little I actually knew and understood. Over time, though, I&#39;ve realized: this is just the permanent state of things. I&#39;d better get used to it.</p>
<p>This, then, is a talk about how to be new at a thing.</p>
<ul>
<li>not about learning new things, about <em>being new at a thing</em></li>
</ul>
<h2>Aviate, Navigate, Communicate</h2><ul>
<li>translation: know your priorities</li>
<li>flying: nowhere to pull over</li>
<li>priorites when flying: 1) do not die, 2) get where you&#39;re going</li>
<li>priorities at a new job: balance learning with project delivery.</li>
<li>study, ask, do</li>
<li>on my team, we try to be explicit about this with new folks.</li>
</ul>
<h2>All Available Information</h2><ul>
<li>FAR §91.103</li>
<li>flying: <em>you</em> are responsible for not dying. you&#39;re expected to know about the weather, the airport you&#39;re flying to, the route you&#39;re taking, your aircraft&#39;s limitations, your own limitations, etc. the FAA will occasionally do &quot;ramp checks&quot; to make sure you&#39;ve done your due diligence.</li>
<li>ultimately, this is all about not making assumptions. just because it&#39;s sunny out doesn&#39;t mean it will be in a couple of hours. just because you flew to an airport on a half tank of fuel last time doesn&#39;t mean it will work out the same way today, when there&#39;s a 40-knot headwind.</li>
<li>&quot;all available information&quot; is somewhat preposterous on its face these days; the amount of information available to us is unreal. i think of this more as a challenge: what information could i get that i haven&#39;t gotten? could it possibly be useful?</li>
<li>&quot;all available information&quot; means being diligent and methodical about gathering facts before making a decision. this is a lot slower than making decisions based on assumptions. later, when you&#39;re not new, you can make decisions based on assumptions -- we might call that instinct. but not when you&#39;re new.</li>
<li>when i was hired at bv, they brought me on to improve the organization and maintainability of a project&#39;s codebase. i didn&#39;t just read the code and get to work tearing it apart; i interviewed every developer on the team to find out where their pain points were, and learned that certain parts of the code, while terrible, weren&#39;t worth spending time on.</li>
<li>what information could you get that you haven&#39;t gotten? could it possibly be useful?</li>
</ul>
<h2>Climb, Communicate, Confess, Comply</h2><ul>
<li>sometimes we get lost. it&#39;s ok!</li>
<li>step 1 is to realize you&#39;re lost</li>
<li>step 2 is to explain what&#39;s wrong</li>
<li>step 3 is to ask for help</li>
<li><p>step 4 is to <em>do what they say</em></p>
</li>
<li><p>i think a lot of people are reluctant to ask for help because they&#39;re afraid of how people will respond when it becomes clear they don&#39;t know everything. of course they don&#39;t know everything, they are new! i think also though that people don&#39;t know how to ask for help. in my experience, people are actually incredibly willing to help -- as long as you&#39;ve done your due diligence. this means you&#39;ve read the docs, done your google due diligence, read the surrounding code, explored the problem with debugging tools, and produced a reduced test case that demonstrates your problem.</p>
</li>
<li>developing the skills to make a good request for help is essential to being good at being new at a thing.</li>
</ul>
<h2>The Checklist</h2><h2>The Go-Around</h2><ul>
<li>sometimes, despite our best efforts, we need to start over</li>
<li><p>this isn&#39;t exceptional -- it&#39;s an entirely normal maneuver</p>
</li>
<li><p>Your code is not a reflection of you. It isn’t a reflection of your beliefs, your upbringing, or your ability to be a good person. Your code is [...] a reflection of your thinking process at the time that you wrote it. - @rockbot</p>
</li>
</ul>
<h2>Trust Your Instruments</h2><ul>
<li>translation: learn how to tell what&#39;s going on when you don&#39;t know what&#39;s going on</li>
</ul>
]]></content:encoded></item><item><title>Writing Unit Tests for Existing JavaScript</title><guid isPermaLink="false">unit-tests</guid><link>http://rmurphey.com/2014/07/13/unit-tests</link><pubDate>Sun, 13 Jul 2014 20:21:00 +0000</pubDate><description><![CDATA[My team at Bazaarvoice has been spending a lot of time lately thinking about quality and how we can have greater confidence that our software is working as it should.
We&#39;ve long had functional tests in place that attempt to ask questions like &quot;When a user clicks a button, will The Widget do The Thing?&quot; These tests tell us a fair amount about the state of our product, but we&#39;ve found that they&#39;re brittle -- even after we abstracted away the CSS selectors that they rely on -- and that they take approximately forever to run, especially if we want to run them in all of the browsers we support. The quality of the tests themselves is all over the map, too -- some of them are in fact unit tests, not really testing anything functional at all.
A few months ago we welcomed a new QA lead to our team as part of our renewed focus on quality. Having a team member who is taking a thoughtful, systematic approach to quality is a game-changer -- he&#39;s not just making sure that new features work, but rather has scrutinized our entire approach to delivering quality software, to great effect.
One of the things he has repeatedly emphasized is the need to push our tests down the stack. Our functional tests should be black-box -- writing them shouldn&#39;t require detailed knowledge of how the software works under the hood. Our unit tests, on the other hand, should provide broad and detailed coverage of the actual code base. In an ideal world, functional tests can be few and slow-ish, because they serve as an infrequent smoke test of the application; unit tests should be thorough, but execute quickly enough that we run them all the time.
Until now, our unit tests have been entirely focused on utility and framework code -- do we properly parse a URL, for example? -- not on code that&#39;s up close and personal with getting The Widget to do The Thing. I&#39;d told myself that this was fine and right and good, but in reality I was pretty terrified of trying to bolt unit tests onto feature code of incredibly varying quality, months or even years after it was first written.
A week or so ago, thanks to some coaxing/chiding from fellow team members, I decided to bite the bullet and see just how bad it would be. A week later, I feel like I&#39;ve taken the first ten steps in a marathon. Of course, taking those first steps involves making the decision to run, and doing enough training ahead of time that you don&#39;t die, so in that regard I&#39;ve come a long way already. Here&#39;s what I&#39;ve done and learned so far.
Step 0I was lucky in that I wasn&#39;t starting entirely from scratch, but if you don&#39;t already have a unit testing framework in place, don&#39;t fret -- it&#39;s pretty easy to set up. We use Grunt with Mocha as our test framework and expect.js as our assertion library, but if I were starting over today I&#39;d take a pretty serious look at Intern.
Our unit tests are organized into suites. Each suite consists of a number of files, each of which tests a single AMD module. Most of the modules under test when I started down this path were pretty isolated -- they didn&#39;t have a ton of dependencies generally, and had very few runtime dependencies. They didn&#39;t interact with other modules that much. Almost all of the existing unit test files loaded a module, executed its methods, and inspected the return value. No big deal.
Feature-related code -- especially already-written feature-related code -- is a different story. Views have templates. Models expect data. Models pass information to views, and views pass information to models. Some models need parents; others expect children. And pretty much everything depended on a global-ish message broker to pass information around.
Since the code was originally written without tests, we are guaranteed that it would be in various states of testability, but a broad rewrite for testability is of course off the table. We&#39;ll rewrite targeted pieces, but doing so comes with great risk. For the most part, our goal will be to write tests for what we have, then refactor cautiously once tests are in place.
We decided that the first place to start was with models, so I found the simplest model I could:
define([
  &#39;framework/bmodel&#39;,
  &#39;underscore&#39;
], function (BModel, _) {
  return BModel.extend({
    options : {},
    name : &#39;mediaViewer&#39;,

    init : function (config, options) {
      _.extend(this.options, options);
    }
  });
});

Why do we have a model that does approximately nothing? I&#39;m not going to attempt to answer that, though there are Reasons -- but for the sake of this discussion, it certainly provides an easy place to start.
I created a new suite for model tests, and added a file to the suite to test the model. I could tell you that I naively plowed ahead thinking that I could just load the module and write some assertions, but that would be a lie.
Mocking: Squire.jsI knew from writing other tests, on this project and projects in the past, that I was going to need to &quot;mock&quot; some of my dependencies. For example, we have a module called ENV that is used for ... well, way too much, though it&#39;s better than it used to be. A large portion of ENV isn&#39;t used by any given module, but ENV itself is required by essentially every model and view.
Squire.js is a really fantastic library for doing mocking in RequireJS-land. It lets you override how a certain dependency will be fulfilled; so, when a module under test asks for &#39;ENV&#39;, you can use Squire to say &quot;use this object that I&#39;ve hand-crafted for this specific test instead.&quot;
I created an Injector module that does the work of loading Squire, plus mocking a couple of things that will be missing when the tests are executed in Node-land.
define([
  &#39;squire&#39;,
  &#39;jquery&#39;
], function (Squire, $) {
  return function () {
    var injector;

    if (typeof window === &#39;undefined&#39;) {
      injector = new Squire(&#39;_BV&#39;);

      injector.mock(&#39;jquery&#39;, function () {
        return $;
      });

      injector.mock(&#39;window&#39;, function () {
        return {};
      });
    }
    else {
      injector = new Squire();
    }

    return injector;
  };
});

Next, I wired up the test to see how far I could get without mocking anything. Note that the main module doesn&#39;t actually load the thing we&#39;re going to test -- first, it sets up the mocks by calling the injector function, and then it uses the created injector to require the module we want to test. Just like a normal require, the injector.require is async, so we have to let our test framework know to wait until it&#39;s loaded before proceeding with our assertions.
define([
  &#39;test/unit/injector&#39;
], function (injector) {
  injector = injector();

  var MediaViewer;

  describe(&#39;MediaViewer Model&#39;, function () {
    before(function (done) {
      injector.require([
        &#39;bv/c2013/model/mediaViewer&#39;
      ], function (M) {
        MediaViewer = M;
        done();
      });
    });

    it(&#39;should be named&#39;, function () {
      var m = new MediaViewer({});
      expect(m.name).to.equal(&#39;mediaViewer&#39;);
    });

    it(&#39;should mix in provided options&#39;, function () {
      var m = new MediaViewer({}, { foo : &#39;bar&#39; });
      expect(m.options.foo).to.equal(&#39;bar&#39;);
    });
  });
});

This, of course, still failed pretty spectacularly. In real life, a model gets instantiated with a component, and a model also expects to have access to an ENV that has knowledge of the component. Creating a &quot;real&quot; component and letting the &quot;real&quot; ENV know about it would be an exercise in inventing the universe, and this is exactly what mocks are for.
While the &quot;real&quot; ENV is a Backbone model that is instantiated using customer-specific configuration data, a much simpler ENV suffices for the sake of testing a model&#39;s functionality:
define([
  &#39;backbone&#39;
], function (Backbone) {
  return function (injector, opts) {
    injector.mock(&#39;ENV&#39;, function () {
      var ENV = new Backbone.Model({
        componentManager : {
          find : function () {
            return opts.component;
          }
        }
      });

      return ENV;
    });

    return injector;
  };
});

Likewise, a &quot;real&quot; component is complicated and difficult to create, but the pieces of a component that this model needs to function are limited. Here&#39;s what the component mock ended up looking like:
define([
  &#39;underscore&#39;
], function (_) {
  return function (settings) {
    settings = settings || {};

    settings.features = settings.features || [];

    return {
      trigger : function () {},
      hasFeature : function (refName, featureName) {
        return _.contains(settings.features, featureName);
      },
      getScope : function () {
        return &#39;scope&#39;;
      },
      contentType : settings.contentType,
      componentId : settings.id,
      views : {}
    };
  };
});

In the case of both mocks, we&#39;ve taken some dramatic shortcuts: the real hasFeature method of a component is a lot more complicated, but in the component mock we create a hasFeature method whose return value can be easily known by the test that uses the mock. Likewise, the behavior of the componentManager&#39;s find method is complex in real life, but in our mock, the method just returns the same thing all the time. Our mocks are designed to be configurable by -- and predictable for -- the test that uses it.
Knowing what to mock and when and how is a learned skill. It&#39;s entirely possible to mock something in such a way that a unit test passes but the actual functionality is broken. We actually have pretty decent tests around our real component code, but not so much around our real ENV code. We should probably fix that, and then I can feel better about mocking ENV as needed.
So far, my approach has been: try to make a test pass without mocking anything, and then mock as little as possible after that. I&#39;ve also made a point of trying to centralize our mocks in a single place, so we aren&#39;t reinventing the wheel for every test.
Finally: when I first set up the injector module, I accidentally made it so that the same injector would be shared by any test that included the module. This is bad, because you end up sharing mocks across tests -- violating the &quot;only mock what you must&quot; rule. The injector module shown above is correct in that it returns a function that can be used to create a new injector, rather than the injector itself.
Here&#39;s what the final MediaViewer test ended up looking like:
define([
  // This properly sets up Squire and mocks window and jQuery
  // if necessary (for running tests from the command line).
  &#39;test/unit/injector&#39;,

  // This is a function that mocks the ENV module.
  &#39;test/unit/mocks/ENV&#39;,

  // This is a function that mocks a component.
  &#39;test/unit/mocks/component&#39;
], function (injector, ENVMock, component) {
  injector = injector();

  // This will become the constructor for the model under test.
  var MediaViewer;

  // Create an object that can serve as a model&#39;s component.
  var c = component();

  // We also need to mock the ENV module and make it aware of
  // the fake component we just created.
  ENVMock(injector, { component : c });

  describe(&#39;MediaViewer Model&#39;, function () {
    before(function (done) {
      injector.require([
        &#39;bv/c2013/model/mediaViewer&#39;
      ], function (M) {
        MediaViewer = M;
        done();
      });
    });

    it(&#39;should be named&#39;, function () {
      var m = new MediaViewer({
        component : c
      }, {});
      expect(m.name).to.equal(&#39;mediaViewer&#39;);
    });

    it(&#39;should mix in provided options&#39;, function () {
      var m = new MediaViewer({
        component : c
      }, { foo : &#39;bar&#39; });

      expect(m.options.foo).to.equal(&#39;bar&#39;);
    });
  });
});

Spying: SinonAfter my stunning success with writing 49 lines of test code to test a 13-line model, I was feeling optimistic about testing views, too. I decided to tackle this fairly simple view first:
define([
  &#39;framework/bview&#39;,
  &#39;underscore&#39;,
  &#39;hbs!contentAuthorProfileInline&#39;,
  &#39;mf!bv/c2013/messages/avatar&#39;,
  &#39;bv/util/productInfo&#39;,
  &#39;framework/util/bvtracker&#39;,
  &#39;util/specialKeys&#39;
], function (BView, _, template, msgPack, ProductInfo, BVTracker, specialKeys) {
  return BView.extend({
    name : &#39;inlineProfile&#39;,

    templateName : &#39;contentAuthorProfileInline&#39;,

    events : {
      &#39;click .bv-content-author-name .bv-fullprofile-popup-target&#39; : &#39;launchProfile&#39;
    },

    template : template,

    msgpacks : [msgPack],

    launchProfile : function (e) {
      // use r&amp;r component outlet to trigger full profile popup component event
      this.getTopModel().trigger( &#39;showfullprofile&#39;, this.model.get(&#39;Author&#39;) );

      BVTracker.feature({
        type : &#39;Used&#39;,
        name : &#39;Click&#39;,
        detail1 : &#39;ViewProfileButton&#39;,
        detail2 : &#39;AuthorAvatar&#39;,
        bvProduct : ProductInfo.getType(this),
        productId : ProductInfo.getId(this)
      });
    }
  });
});

It turned out that I needed to do the same basic mocking for this as I did for the model, but this code presented a couple of interesting things to consider.
First, I wanted to test that this.getTopModel().trigger(...) triggered the proper event, but the getTopModel method was implemented in BView, not the code under test, and without a whole lot of gymnastics, it wasn&#39;t going to return an object with a trigger method.
Second, I wanted to know that BVTracker.feature was getting called with the right values, so I needed a way to inspect the object that got passed to it, but without doing something terrible like exposing it globally.
Enter Sinon and its spies. Spies let you observe methods as they are called. You can either let the method still do its thing while watching how it is called, or simply replace the method with a spy.
I solved the first problem by defining my own getTopModel method on the model instance, and having it return an object. I gave that object a trigger method that was actually just a spy -- for the sake of my test, I didn&#39;t care what trigger did, only how it was called. Other tests [will eventually] ensure that triggering this event has the desired effect on the targeted model, but for the sake of this test, we don&#39;t care.
Here&#39;s what the test looks like:
describe(&#39;#launchProfile&#39;, function () {
  var spy;
  var v;

  before(function () {
    spy = sinon.spy();

    v = new InlineProfile({
      // model and component are defined elsewhere
      component : component,
      model : model
    });

    model.set(&#39;Author&#39;, &#39;author&#39;);

    v.getTopModel = function () {
      return {
        trigger : spy
      };
    };
  });

  it(&#39;should trigger showfullprofile event on top model&#39;, function () {
    v.launchProfile();

    expect(spy.lastCall.args[0]).to.equal(&#39;showfullprofile&#39;);
    expect(spy.lastCall.args[1]).to.equal(&#39;author&#39;);
  });
});

I solved the second problem -- the need to see what&#39;s getting passed to BVTracker.feature -- by creating a BVTracker mock where every method is just a spy:
// This is a mock for BVTracker that can be used by unit tests.
define([
  &#39;underscore&#39;
], function (_) {
  return function (injector, opts) {
    var BVTracker = {};

    injector.mock(&#39;framework/util/bvtracker&#39;, function () {
      _([
        &#39;error&#39;,
        &#39;pageview&#39;,
        &#39;feature&#39;
      ]).each(function (event) {
        BVTracker[event] = sinon.spy();
      });
    });

    return BVTracker;
  };
});

My test looked at the BVTracker.feature spy to see what it got when the view&#39;s launchProfile method was called:
it(&#39;should send a feature analytics event&#39;, function () {
  v.launchProfile();

  var evt = BVTracker.feature.lastCall.args[0];

  expect(evt.type).to.equal(&#39;Used&#39;);
  expect(evt.name).to.equal(&#39;Click&#39;);
  expect(evt.detail1).to.equal(&#39;ViewProfileButton&#39;);
  expect(evt.detail2).to.equal(&#39;AuthorAvatar&#39;);
  expect(evt.bvProduct).to.equal(&#39;RatingsAndReviews&#39;);
  expect(evt.productId).to.equal(&#39;product1&#39;);
});

I&#39;ve barely touched on what you can do with spies, or with Sinon in general. Besides providing simple spy functionality, Sinon delivers a host of functionality that makes tests easier to write -- swaths of which I haven&#39;t even begun to explore. One part I have explored is its ability to create fake XHRs and to fake whole servers, allowing you to test how your code behaves when things go wrong on the server. Do yourself a favor and spend some time reading through the excellent docs.
What to test ... and notI&#39;ve written tests now for a tiny handful of models and views. Setting up the mocks was a bit of a hurdle -- and there were plenty of other hurdles that are too specific to our project for me to talk about them in detail -- but overall, the hardest part has been figuring out what, exactly, to test. I crafted the examples above to be pretty straightforward, but reality is a lot more complicated.
Writing tests for existing code requires first understanding the code that&#39;s being tested and identifying interesting moments in that code. If there&#39;s an operation that affects the &quot;public&quot; experience of the module -- for example, if the value of a model attribute changes -- then we need to write a test that covers that operation&#39;s side effect(s). If there&#39;s code that runs conditionally, we need to test the behavior of that code when that condition is true -- and when it&#39;s not. If there are six possible conditions, we need to test them all. If a model behaves completely differently when it has a parent -- and this happens far too often in our code -- then we need to simulate the parent case, and simulate the standalone case.
It can be tempting to try to test the implementation details of existing code -- and difficult to realize that you&#39;re doing it even when you don&#39;t mean to. I try to stay focused on testing how other code might consume and interact with the module I&#39;m testing. For example, if the module I&#39;m testing triggers an event in a certain situation, I&#39;m going to write a test that proves it, because some other code is probably expecting that event to get triggered. However, I&#39;m not going to test that a method of a certain name gets called in a certain case -- that&#39;s an implementation detail that might change.
The exercise of writing unit tests against existing code proves to be a phenomenal incentive to write better code in the future. One comes to develop a great appreciation of methods that have return values, not side effects. One comes to loathe the person -- often one&#39;s past self -- who authored complex, nested conditional logic. One comes to worship small methods that do exactly one thing.
So far, I haven&#39;t rewritten any of the code I&#39;ve been testing, even when I&#39;ve spotted obvious flaws, and even when rewriting would make the tests themselves easier to write. I don&#39;t know how long I&#39;ll be able to stick to this; there are some specific views and models that I know will be nearly impossible to test without revisiting their innards. When that becomes necessary, I&#39;m hoping I can do it incrementally, testing as I go -- and that our functional tests will give me the cover I need to know I haven&#39;t gone horribly wrong.
Spreading the loveOur team&#39;s next step is to widen the effort to get better unit test coverage of our code. We have something like 100 modules that need testing, and their size and complexity are all over the map. Over the coming weeks, we&#39;ll start to divide and conquer.
One thing I&#39;ve done to try to make the effort easier is to create a scaffolding task using Grunt. Running grunt scaffold-test:model:modelName will generate a basic file that includes mocking that&#39;s guaranteed to be needed, as well as the basic instantiation that will be required and a couple of simple tests.
There&#39;s another senior team member who has led an effort in the past to apply unit tests to an existing code base, and he&#39;s already warned me to expect a bit of a bumpy road as the team struggles through the inevitable early challenges of trying to write unit tests for existing feature code. I expect there to be a pretty steep hill to climb at first, but at the very least, the work I&#39;ve done so far has -- hopefully -- gotten us to the top of the vertical wall that had been standing in our way.
Further ReadingI&#39;m not exactly the first person to write about this. You may find these items interesting:

On adding unit tests to existing code
On whether it&#39;s worth the effort
Working Effectively with Legacy Code]]></description><content:encoded><![CDATA[<p>My team at <a href="http://www.bazaarvoice.com/careers/">Bazaarvoice</a> has been spending a lot of time lately thinking about quality and how we can have greater confidence that our software is working as it should.</p>
<p>We&#39;ve long had functional tests in place that attempt to ask questions like &quot;When a user clicks a button, will The Widget do The Thing?&quot; These tests tell us a fair amount about the state of our product, but we&#39;ve found that they&#39;re brittle -- even after we abstracted away the CSS selectors that they rely on -- and that they take approximately forever to run, especially if we want to run them in all of the browsers we support. The quality of the tests themselves is all over the map, too -- some of them are in fact unit tests, not really testing anything <em>functional</em> at all.</p>
<p>A few months ago we welcomed a new QA lead to our team as part of our renewed focus on quality. Having a team member who is taking a thoughtful, systematic approach to quality is a game-changer -- he&#39;s not just making sure that new features work, but rather has scrutinized our entire approach to delivering quality software, to great effect.</p>
<p>One of the things he has repeatedly emphasized is the need to push our tests down the stack. Our functional tests should be black-box -- writing them shouldn&#39;t require detailed knowledge of how the software works under the hood. Our unit tests, on the other hand, should provide broad and detailed coverage of the actual code base. In an ideal world, functional tests can be few and slow-ish, because they serve as an infrequent smoke test of the application; unit tests should be thorough, but execute quickly enough that we run them all the time.</p>
<p>Until now, our unit tests have been entirely focused on utility and framework code -- do we properly parse a URL, for example? -- not on code that&#39;s up close and personal with getting The Widget to do The Thing. I&#39;d told myself that this was fine and right and good, but in reality I was pretty terrified of trying to bolt unit tests onto feature code of incredibly varying quality, months or even years after it was first written.</p>
<p>A week or so ago, thanks to some coaxing/chiding from fellow team members, I decided to bite the bullet and see just how bad it would be. A week later, I feel like I&#39;ve taken the first ten steps in a marathon. Of course, taking those first steps involves making the decision to run, and doing enough training ahead of time that you don&#39;t die, so in that regard I&#39;ve come a long way already. Here&#39;s what I&#39;ve done and learned so far.</p>
<h3>Step 0</h3><p>I was lucky in that I wasn&#39;t starting entirely from scratch, but if you don&#39;t already have a unit testing framework in place, don&#39;t fret -- it&#39;s pretty easy to set up. We use <a href="http://gruntjs.com/">Grunt</a> with <a href="http://visionmedia.github.io/mocha/">Mocha</a> as our test framework and <a href="https://github.com/LearnBoost/expect.js/">expect.js</a> as our assertion library, but if I were starting over today I&#39;d take a pretty serious look at <a href="http://theintern.io/">Intern</a>.</p>
<p>Our unit tests are organized into suites. Each suite consists of a number of files, each of which tests a single AMD module. Most of the modules under test when I started down this path were pretty isolated -- they didn&#39;t have a ton of dependencies generally, and had very few runtime dependencies. They didn&#39;t interact with other modules that much. Almost all of the existing unit test files loaded a module, executed its methods, and inspected the return value. No big deal.</p>
<p>Feature-related code -- especially already-written feature-related code -- is a different story. Views have templates. Models expect data. Models pass information to views, and views pass information to models. Some models need parents; others expect children. And pretty much everything depended on a global-ish message broker to pass information around.</p>
<p>Since the code was originally written without tests, we are guaranteed that it would be in various states of testability, but a broad rewrite for testability is of course off the table. We&#39;ll rewrite targeted pieces, but doing so comes with great risk. For the most part, our goal will be to write tests for what we have, then refactor cautiously once tests are in place.</p>
<p>We decided that the first place to start was with models, so I found the simplest model I could:</p>
<pre><code class="language-javascript">define([
  &#39;framework/bmodel&#39;,
  &#39;underscore&#39;
], function (BModel, _) {
  return BModel.extend({
    options : {},
    name : &#39;mediaViewer&#39;,

    init : function (config, options) {
      _.extend(this.options, options);
    }
  });
});
</code></pre>
<p>Why do we have a model that does approximately nothing? I&#39;m not going to attempt to answer that, though there are Reasons -- but for the sake of this discussion, it certainly provides an easy place to start.</p>
<p>I created a new suite for model tests, and added a file to the suite to test the model. I could tell you that I naively plowed ahead thinking that I could just load the module and write some assertions, but that would be a lie.</p>
<h3>Mocking: Squire.js</h3><p>I knew from writing other tests, on this project and projects in the past, that I was going to need to &quot;mock&quot; some of my dependencies. For example, we have a module called <code>ENV</code> that is used for ... well, way too much, though it&#39;s better than it used to be. A large portion of <code>ENV</code> isn&#39;t used by any given module, but <code>ENV</code> itself is required by essentially every model and view.</p>
<p><a href="https://github.com/iammerrick/Squire.js/">Squire.js</a> is a really fantastic library for doing mocking in RequireJS-land. It lets you override how a certain dependency will be fulfilled; so, when a module under test asks for <code>&#39;ENV&#39;</code>, you can use Squire to say &quot;use this object that I&#39;ve hand-crafted for this specific test instead.&quot;</p>
<p>I created an Injector module that does the work of loading Squire, plus mocking a couple of things that will be missing when the tests are executed in Node-land.</p>
<pre><code class="language-javascript">define([
  &#39;squire&#39;,
  &#39;jquery&#39;
], function (Squire, $) {
  return function () {
    var injector;

    if (typeof window === &#39;undefined&#39;) {
      injector = new Squire(&#39;_BV&#39;);

      injector.mock(&#39;jquery&#39;, function () {
        return $;
      });

      injector.mock(&#39;window&#39;, function () {
        return {};
      });
    }
    else {
      injector = new Squire();
    }

    return injector;
  };
});
</code></pre>
<p>Next, I wired up the test to see how far I could get without mocking anything. Note that the main module doesn&#39;t actually load the thing we&#39;re going to test -- first, it sets up the mocks by calling the <code>injector</code> function, and then it uses the created injector to require the module we want to test. Just like a normal <code>require</code>, the <code>injector.require</code> is async, so we have to let our test framework know to wait until it&#39;s loaded before proceeding with our assertions.</p>
<pre><code class="language-javascript">define([
  &#39;test/unit/injector&#39;
], function (injector) {
  injector = injector();

  var MediaViewer;

  describe(&#39;MediaViewer Model&#39;, function () {
    before(function (done) {
      injector.require([
        &#39;bv/c2013/model/mediaViewer&#39;
      ], function (M) {
        MediaViewer = M;
        done();
      });
    });

    it(&#39;should be named&#39;, function () {
      var m = new MediaViewer({});
      expect(m.name).to.equal(&#39;mediaViewer&#39;);
    });

    it(&#39;should mix in provided options&#39;, function () {
      var m = new MediaViewer({}, { foo : &#39;bar&#39; });
      expect(m.options.foo).to.equal(&#39;bar&#39;);
    });
  });
});
</code></pre>
<p>This, of course, still failed pretty spectacularly. In real life, a model gets instantiated with a component, and a model also expects to have access to an <code>ENV</code> that has knowledge of the component. Creating a &quot;real&quot; component and letting the &quot;real&quot; <code>ENV</code> know about it would be an exercise in <a href="https://www.youtube.com/watch?v=7s664NsLeFM">inventing the universe</a>, and this is exactly what mocks are for.</p>
<p>While the &quot;real&quot; <code>ENV</code> is a Backbone model that is instantiated using customer-specific configuration data, a much simpler <code>ENV</code> suffices for the sake of testing a model&#39;s functionality:</p>
<pre><code class="language-javascript">define([
  &#39;backbone&#39;
], function (Backbone) {
  return function (injector, opts) {
    injector.mock(&#39;ENV&#39;, function () {
      var ENV = new Backbone.Model({
        componentManager : {
          find : function () {
            return opts.component;
          }
        }
      });

      return ENV;
    });

    return injector;
  };
});
</code></pre>
<p>Likewise, a &quot;real&quot; component is complicated and difficult to create, but the pieces of a component that this model needs to function are limited. Here&#39;s what the component mock ended up looking like:</p>
<pre><code class="language-javascript">define([
  &#39;underscore&#39;
], function (_) {
  return function (settings) {
    settings = settings || {};

    settings.features = settings.features || [];

    return {
      trigger : function () {},
      hasFeature : function (refName, featureName) {
        return _.contains(settings.features, featureName);
      },
      getScope : function () {
        return &#39;scope&#39;;
      },
      contentType : settings.contentType,
      componentId : settings.id,
      views : {}
    };
  };
});
</code></pre>
<p>In the case of both mocks, we&#39;ve taken some dramatic shortcuts: the real <code>hasFeature</code> method of a component is a lot more complicated, but in the component mock we create a <code>hasFeature</code> method whose return value can be easily known by the test that uses the mock. Likewise, the behavior of the <code>componentManager</code>&#39;s <code>find</code> method is complex in real life, but in our mock, the method just returns the same thing all the time. Our mocks are designed to be configurable by -- and predictable for -- the test that uses it.</p>
<p>Knowing what to mock and when and how is a learned skill. It&#39;s entirely possible to mock something in such a way that a unit test passes but the actual functionality is broken. We actually have pretty decent tests around our real component code, but not so much around our real <code>ENV</code> code. We should probably fix that, and then I can feel better about mocking <code>ENV</code> as needed.</p>
<p>So far, my approach has been: try to make a test pass without mocking anything, and then mock as little as possible after that. I&#39;ve also made a point of trying to centralize our mocks in a single place, so we aren&#39;t reinventing the wheel for every test.</p>
<p>Finally: when I first set up the injector module, I accidentally made it so that the same injector would be shared by any test that included the module. This is bad, because you end up sharing mocks across tests -- violating the &quot;only mock what you must&quot; rule. The injector module shown above is correct in that it returns a function that can be used to create a new injector, rather than the injector itself.</p>
<p>Here&#39;s what the final MediaViewer test ended up looking like:</p>
<pre><code class="language-javascript">define([
  // This properly sets up Squire and mocks window and jQuery
  // if necessary (for running tests from the command line).
  &#39;test/unit/injector&#39;,

  // This is a function that mocks the ENV module.
  &#39;test/unit/mocks/ENV&#39;,

  // This is a function that mocks a component.
  &#39;test/unit/mocks/component&#39;
], function (injector, ENVMock, component) {
  injector = injector();

  // This will become the constructor for the model under test.
  var MediaViewer;

  // Create an object that can serve as a model&#39;s component.
  var c = component();

  // We also need to mock the ENV module and make it aware of
  // the fake component we just created.
  ENVMock(injector, { component : c });

  describe(&#39;MediaViewer Model&#39;, function () {
    before(function (done) {
      injector.require([
        &#39;bv/c2013/model/mediaViewer&#39;
      ], function (M) {
        MediaViewer = M;
        done();
      });
    });

    it(&#39;should be named&#39;, function () {
      var m = new MediaViewer({
        component : c
      }, {});
      expect(m.name).to.equal(&#39;mediaViewer&#39;);
    });

    it(&#39;should mix in provided options&#39;, function () {
      var m = new MediaViewer({
        component : c
      }, { foo : &#39;bar&#39; });

      expect(m.options.foo).to.equal(&#39;bar&#39;);
    });
  });
});
</code></pre>
<h3>Spying: Sinon</h3><p>After my stunning success with writing 49 lines of test code to test a 13-line model, I was feeling optimistic about testing views, too. I decided to tackle this fairly simple view first:</p>
<pre><code class="language-javascript">define([
  &#39;framework/bview&#39;,
  &#39;underscore&#39;,
  &#39;hbs!contentAuthorProfileInline&#39;,
  &#39;mf!bv/c2013/messages/avatar&#39;,
  &#39;bv/util/productInfo&#39;,
  &#39;framework/util/bvtracker&#39;,
  &#39;util/specialKeys&#39;
], function (BView, _, template, msgPack, ProductInfo, BVTracker, specialKeys) {
  return BView.extend({
    name : &#39;inlineProfile&#39;,

    templateName : &#39;contentAuthorProfileInline&#39;,

    events : {
      &#39;click .bv-content-author-name .bv-fullprofile-popup-target&#39; : &#39;launchProfile&#39;
    },

    template : template,

    msgpacks : [msgPack],

    launchProfile : function (e) {
      // use r&amp;r component outlet to trigger full profile popup component event
      this.getTopModel().trigger( &#39;showfullprofile&#39;, this.model.get(&#39;Author&#39;) );

      BVTracker.feature({
        type : &#39;Used&#39;,
        name : &#39;Click&#39;,
        detail1 : &#39;ViewProfileButton&#39;,
        detail2 : &#39;AuthorAvatar&#39;,
        bvProduct : ProductInfo.getType(this),
        productId : ProductInfo.getId(this)
      });
    }
  });
});
</code></pre>
<p>It turned out that I needed to do the same basic mocking for this as I did for the model, but this code presented a couple of interesting things to consider.</p>
<p>First, I wanted to test that <code>this.getTopModel().trigger(...)</code> triggered the proper event, but the <code>getTopModel</code> method was implemented in <code>BView</code>, not the code under test, and without a whole lot of gymnastics, it wasn&#39;t going to return an object with a <code>trigger</code> method.</p>
<p>Second, I wanted to know that <code>BVTracker.feature</code> was getting called with the right values, so I needed a way to inspect the object that got passed to it, but without doing something terrible like exposing it globally.</p>
<p>Enter <a href="http://sinonjs.org">Sinon</a> and its <a href="http://sinonjs.org/docs/#spies">spies</a>. Spies let you observe methods as they are called. You can either let the method still do its thing while watching how it is called, or simply replace the method with a spy.</p>
<p>I solved the first problem by defining my own <code>getTopModel</code> method on the model instance, and having it return an object. I gave that object a <code>trigger</code> method that was actually just a spy -- for the sake of my test, I didn&#39;t care what trigger <em>did</em>, only how it was called. Other tests [will eventually] ensure that triggering this event has the desired effect on the targeted model, but for the sake of this test, we don&#39;t care.</p>
<p>Here&#39;s what the test looks like:</p>
<pre><code class="language-javascript">describe(&#39;#launchProfile&#39;, function () {
  var spy;
  var v;

  before(function () {
    spy = sinon.spy();

    v = new InlineProfile({
      // model and component are defined elsewhere
      component : component,
      model : model
    });

    model.set(&#39;Author&#39;, &#39;author&#39;);

    v.getTopModel = function () {
      return {
        trigger : spy
      };
    };
  });

  it(&#39;should trigger showfullprofile event on top model&#39;, function () {
    v.launchProfile();

    expect(spy.lastCall.args[0]).to.equal(&#39;showfullprofile&#39;);
    expect(spy.lastCall.args[1]).to.equal(&#39;author&#39;);
  });
});
</code></pre>
<p>I solved the second problem -- the need to see what&#39;s getting passed to <code>BVTracker.feature</code> -- by creating a <code>BVTracker</code> mock where every method is just a spy:</p>
<pre><code class="language-javascript">// This is a mock for BVTracker that can be used by unit tests.
define([
  &#39;underscore&#39;
], function (_) {
  return function (injector, opts) {
    var BVTracker = {};

    injector.mock(&#39;framework/util/bvtracker&#39;, function () {
      _([
        &#39;error&#39;,
        &#39;pageview&#39;,
        &#39;feature&#39;
      ]).each(function (event) {
        BVTracker[event] = sinon.spy();
      });
    });

    return BVTracker;
  };
});
</code></pre>
<p>My test looked at the <code>BVTracker.feature</code> spy to see what it got when the view&#39;s <code>launchProfile</code> method was called:</p>
<pre><code class="language-javascript">it(&#39;should send a feature analytics event&#39;, function () {
  v.launchProfile();

  var evt = BVTracker.feature.lastCall.args[0];

  expect(evt.type).to.equal(&#39;Used&#39;);
  expect(evt.name).to.equal(&#39;Click&#39;);
  expect(evt.detail1).to.equal(&#39;ViewProfileButton&#39;);
  expect(evt.detail2).to.equal(&#39;AuthorAvatar&#39;);
  expect(evt.bvProduct).to.equal(&#39;RatingsAndReviews&#39;);
  expect(evt.productId).to.equal(&#39;product1&#39;);
});
</code></pre>
<p>I&#39;ve barely touched on what you can do with spies, or with Sinon in general. Besides providing simple spy functionality, Sinon delivers a host of functionality that makes tests easier to write -- swaths of which I haven&#39;t even begun to explore. One part I have explored is its ability to create fake XHRs and to fake whole servers, allowing you to test how your code behaves when things go wrong on the server. Do yourself a favor and spend some time reading through the excellent <a href="http://sinonjs.org/docs/">docs</a>.</p>
<h3>What to test ... and not</h3><p>I&#39;ve written tests now for a tiny handful of models and views. Setting up the mocks was a bit of a hurdle -- and there were plenty of other hurdles that are too specific to our project for me to talk about them in detail -- but overall, the hardest part has been figuring out what, exactly, to test. I crafted the examples above to be pretty straightforward, but reality is a lot more complicated.</p>
<p>Writing tests for existing code requires first understanding the code that&#39;s being tested and identifying interesting moments in that code. If there&#39;s an operation that affects the &quot;public&quot; experience of the module -- for example, if the value of a model attribute changes -- then we need to write a test that covers that operation&#39;s side effect(s). If there&#39;s code that runs conditionally, we need to test the behavior of that code when that condition is true -- and when it&#39;s not. If there are six possible conditions, we need to test them all. If a model behaves completely differently when it has a parent -- and this happens far too often in our code -- then we need to simulate the parent case, and simulate the standalone case.</p>
<p>It can be tempting to try to test the implementation details of existing code -- and difficult to realize that you&#39;re doing it even when you don&#39;t mean to. I try to stay focused on testing how other code might consume and interact with the module I&#39;m testing. For example, if the module I&#39;m testing triggers an event in a certain situation, I&#39;m going to write a test that proves it, because some other code is probably expecting that event to get triggered. However, I&#39;m not going to test that a method of a certain name gets called in a certain case -- that&#39;s an implementation detail that might change.</p>
<p>The exercise of writing unit tests against existing code proves to be a phenomenal incentive to write better code in the future. One comes to develop a great appreciation of methods that have return values, not side effects. One comes to loathe the person -- often one&#39;s past self -- who authored complex, nested conditional logic. One comes to worship small methods that do exactly one thing.</p>
<p>So far, I haven&#39;t rewritten any of the code I&#39;ve been testing, even when I&#39;ve spotted obvious flaws, and even when rewriting would make the tests themselves easier to write. I don&#39;t know how long I&#39;ll be able to stick to this; there are some specific views and models that I know will be nearly impossible to test without revisiting their innards. When that becomes necessary, I&#39;m hoping I can do it incrementally, testing as I go -- and that our functional tests will give me the cover I need to know I haven&#39;t gone horribly wrong.</p>
<h3>Spreading the love</h3><p>Our team&#39;s next step is to widen the effort to get better unit test coverage of our code. We have something like 100 modules that need testing, and their size and complexity are all over the map. Over the coming weeks, we&#39;ll start to divide and conquer.</p>
<p>One thing I&#39;ve done to try to make the effort easier is to create a scaffolding task using Grunt. Running <code>grunt scaffold-test:model:modelName</code> will generate a basic file that includes mocking that&#39;s guaranteed to be needed, as well as the basic instantiation that will be required and a couple of simple tests.</p>
<p>There&#39;s another senior team member who has led an effort in the past to apply unit tests to an existing code base, and he&#39;s already warned me to expect a bit of a bumpy road as the team struggles through the inevitable early challenges of trying to write unit tests for existing feature code. I expect there to be a pretty steep hill to climb at first, but at the very least, the work I&#39;ve done so far has -- hopefully -- gotten us to the top of the vertical wall that had been standing in our way.</p>
<h3>Further Reading</h3><p>I&#39;m not exactly the first person to write about this. You may find these items interesting:</p>
<ul>
<li><a href="http://stackoverflow.com/questions/3476054/can-unit-testing-be-successfully-added-into-an-existing-production-project-if-s">On adding unit tests to existing code</a></li>
<li><a href="http://programmers.stackexchange.com/questions/207401/writing-tests-for-existing-code">On whether it&#39;s worth the effort</a></li>
<li><a href="http://www.amazon.com/gp/product/0131177052">Working Effectively with Legacy Code</a></li>
</ul>
]]></content:encoded></item><item><title>Two Things about Conditionals in JavaScript</title><guid isPermaLink="false">js-conditionals</guid><link>http://rmurphey.com/2012/12/10/js-conditionals</link><pubDate>Mon, 10 Dec 2012 21:40:00 +0000</pubDate><description><![CDATA[Just a quick post, inspired by Laura Kalbag&#39;s post, which included this gem:

We shouldn’t be fearful of writing about what we know. Even if you write from the most basic point of view, about something which has been ‘around for ages’, you’ll likely be saying something new to someone.

One: There is no else ifWhen you write something like this ...
function saySomething( msg ) {
  if ( msg === &#39;Hello&#39; ) {
    console.log(&#39;Hello there&#39;);
  } else if ( msg === &#39;Yo&#39; ) {
    console.log(&#39;Yo dawg&#39;);
  }
}

... then what you&#39;re actually writing is this ...
function saySomething( msg ) {
  if ( msg === &#39;Hello&#39; ) {
    console.log(&#39;Hello there&#39;);
  } else {
    if ( msg === &#39;Yo&#39; ) {
      console.log(&#39;Yo dawg&#39;);
    }
  }
}

That&#39;s because there is no else if in JavaScript. You know how you can write an if statement without any curly braces?
if ( foo ) bar() // please don&#39;t do this if you want your code to be legible

You&#39;re doing the same thing with the else part of the initial if statement when you write else if: you&#39;re skipping the curly braces for the second if block, the one you&#39;re providing to else. There&#39;s nothing wrong with else if per se, but it&#39;s worth knowing about what&#39;s actually happening.
Two: return Means Never Having to Say elseConsider some code like this:
function howBig( num ) {
  if ( num &lt; 10 ) {
    return &#39;small&#39;;
  } else if ( num &gt;= 10 &amp;&amp; num &lt; 100 ) {
    return &#39;medium&#39;;
  } else if ( num &gt;= 100 ) {
    return &#39;big&#39;;
  }
}

If the number we pass to howBig is less than 10, then our function will return &#39;small&#39;. As soon as it returns, none of the rest of the function will run -- this means we can skip the else part entirely, which means our code could look like this:
function howBig( num ) {
  if ( num &lt; 10 ) {
    return &#39;small&#39;;
  }

  if ( num &lt; 100 ) {
    return &#39;medium&#39;;
  }

  if ( num &gt;= 100 ) {
    return &#39;big&#39;;
  }
}

But wait -- if the first if statement isn&#39;t true, and the second if statement isn&#39;t true, then we will always return &#39;big&#39;. That means the third if statement isn&#39;t even required:
function howBig( num ) {
  if ( num &lt; 10 ) {
    return &#39;small&#39;;
  }

  if ( num &lt; 100 ) {
    return &#39;medium&#39;;
  }

  return &#39;big&#39;;
}

Note: this post was edited to improve a couple of the examples and to fix some typos.]]></description><content:encoded><![CDATA[<p>Just a quick post, inspired by <a href="http://laurakalbag.com/display-none/">Laura Kalbag&#39;s post</a>, which included this gem:</p>
<blockquote>
<p>We shouldn’t be fearful of writing about what we know. Even if you write from the most basic point of view, about something which has been ‘around for ages’, you’ll likely be saying something new to someone.</p>
</blockquote>
<h2>One: There is no <code>else if</code></h2><p>When you write something like this ...</p>
<pre><code class="language-javascript">function saySomething( msg ) {
  if ( msg === &#39;Hello&#39; ) {
    console.log(&#39;Hello there&#39;);
  } else if ( msg === &#39;Yo&#39; ) {
    console.log(&#39;Yo dawg&#39;);
  }
}
</code></pre>
<p>... then what you&#39;re actually writing is this ...</p>
<pre><code class="language-javascript">function saySomething( msg ) {
  if ( msg === &#39;Hello&#39; ) {
    console.log(&#39;Hello there&#39;);
  } else {
    if ( msg === &#39;Yo&#39; ) {
      console.log(&#39;Yo dawg&#39;);
    }
  }
}
</code></pre>
<p>That&#39;s because there is no <code>else if</code> in JavaScript. You know how you can write an <code>if</code> statement without any curly braces?</p>
<pre><code class="language-javascript">if ( foo ) bar() // please don&#39;t do this if you want your code to be legible
</code></pre>
<p>You&#39;re doing the same thing with the <code>else</code> part of the initial <code>if</code> statement when you write <code>else if</code>: you&#39;re skipping the curly braces for the second <code>if</code> block, the one you&#39;re providing to <code>else</code>. There&#39;s nothing <em>wrong</em> with <code>else if</code> per se, but it&#39;s worth knowing about what&#39;s actually happening.</p>
<h2>Two: <code>return</code> Means Never Having to Say <code>else</code></h2><p>Consider some code like this:</p>
<pre><code class="language-javascript">function howBig( num ) {
  if ( num &lt; 10 ) {
    return &#39;small&#39;;
  } else if ( num &gt;= 10 &amp;&amp; num &lt; 100 ) {
    return &#39;medium&#39;;
  } else if ( num &gt;= 100 ) {
    return &#39;big&#39;;
  }
}
</code></pre>
<p>If the number we pass to <code>howBig</code> is less than 10, then our function will return <code>&#39;small&#39;</code>. As soon as it returns, none of the rest of the function will run -- this means we can skip the <code>else</code> part entirely, which means our code could look like this:</p>
<pre><code class="language-javascript">function howBig( num ) {
  if ( num &lt; 10 ) {
    return &#39;small&#39;;
  }

  if ( num &lt; 100 ) {
    return &#39;medium&#39;;
  }

  if ( num &gt;= 100 ) {
    return &#39;big&#39;;
  }
}
</code></pre>
<p>But wait -- if the first <code>if</code> statement isn&#39;t true, and the second <code>if</code> statement isn&#39;t true, then we will <em>always</em> return <code>&#39;big&#39;</code>. That means the third <code>if</code> statement isn&#39;t even required:</p>
<pre><code class="language-javascript">function howBig( num ) {
  if ( num &lt; 10 ) {
    return &#39;small&#39;;
  }

  if ( num &lt; 100 ) {
    return &#39;medium&#39;;
  }

  return &#39;big&#39;;
}
</code></pre>
<p><small><em>Note: this post was edited to improve a couple of the examples and to fix some typos.</em></small></p>
]]></content:encoded></item><item><title>This is the Cigarette</title><guid isPermaLink="false">this-is-the-cigarette</guid><link>http://rmurphey.com/2012/12/09/this-is-the-cigarette</link><pubDate>Sun, 09 Dec 2012 19:40:00 +0000</pubDate><description><![CDATA[This is the cigarette I smoked* on Wednesday after I got out of a meeting in Boston and went to my desk and read my messages and learned that our birthmother &quot;match&quot; had fallen through.
The last three weeks have been among the happiest, most exciting, most terrifying times I can remember. Saying that we are sad and disappointed and et cetera doesn&#39;t really cover it, but, well, there it is. Our search will continue.
* Don&#39;t worry, Mom, I don&#39;t usually smoke. Desperate times, desperate measures.]]></description><content:encoded><![CDATA[<p><a href="http://www.flickr.com/photos/rdmey/8259827572/" title="Untitled by rdmey, on Flickr"><img src="http://farm9.staticflickr.com/8212/8259827572_73b5a4e269.jpg" width="200"></a></p>
<p>This is the cigarette I smoked* on Wednesday after I got out of a meeting in Boston and went to my desk and read my messages and learned that our birthmother &quot;match&quot; had fallen through.</p>
<p>The last three weeks have been among the happiest, most exciting, most terrifying times I can remember. Saying that we are sad and disappointed and et cetera doesn&#39;t really cover it, but, well, there it is. Our search will continue.</p>
<p><small>* Don&#39;t worry, Mom, I don&#39;t usually smoke. Desperate times, desperate measures.</small></p>
]]></content:encoded></item><item><title>On Choosing a Syntax Highlighting Scheme for Your Next Presentation</title><guid isPermaLink="false">choosing-presentation-color-scheme</guid><link>http://rmurphey.com/2012/11/29/choosing-presentation-color-scheme</link><pubDate>Thu, 29 Nov 2012 20:20:00 +0000</pubDate><description><![CDATA[This is a projector screen:

You will notice that it is white, or some reasonable approximation thereof. It is probably made of a reflective material that sparkles a bit when light shines on it. Still: white.
Do you know what color this screen is when you use a projector to display this image onto it?

It is still white. Crazy, I know! The thing is, projectors cannot project black; they can only not project any light on a region that you intend to be black.
Chances are you are reading this on an LCD screen of some sort, where the rules are completely different: they usually start out essentially black, not white, and pixels are brightened as required. The pixels that start out dark can generally stay pretty dark.
On a projection screen, on the other hand, the appearance of black is nothing more than an optical illusion, made possible by the projector projecting brightness everywhere else.
What does this mean? Lots of things, but in particular, it means that you should never, ever, ever use a color scheme with a dark background -- no matter how high-contrast and good it looks on your monitor -- if you will be presenting using a projector that is projecting onto a white screen. At least, assuming that you intend for your audience to be able to actually read the code.
Presentation Color Schemes That I Have Loved
Ben Alman&#39;s TextMate Theme: Ben has tailored this to be incredible for presenting about JS code.
Tomorrow Theme: The light-background flavor is decent, but could probably stand to be higher-contrast, at least for some languages.]]></description><content:encoded><![CDATA[<p>This is a projector screen:</p>
<p><img src="https://dl.dropboxusercontent.com/u/2916642/projection-screen.jpg" width="300px"></p>
<p>You will notice that it is white, or some reasonable approximation thereof. It is probably made of a reflective material that sparkles a bit when light shines on it. Still: white.</p>
<p>Do you know what color this screen is when you use a projector to display this image onto it?</p>
<p><img src="https://dl.dropboxusercontent.com/u/2916642/dark-code.png" width="300px"></p>
<p>It is still white. Crazy, I know! The thing is, projectors cannot project black; they can only <em>not</em> project any light on a region that you intend to be black.</p>
<p>Chances are you are reading this on an LCD screen of some sort, where the rules are completely different: they usually start out essentially black, not white, and pixels are brightened as required. The pixels that start out dark can generally stay pretty dark.</p>
<p>On a projection screen, on the other hand, the appearance of black is nothing more than an optical illusion, made possible by the projector projecting brightness everywhere else.</p>
<p>What does this mean? Lots of things, but in particular, it means that you should never, ever, ever use a color scheme with a dark background -- no matter how high-contrast and good it looks on your monitor -- if you will be presenting using a projector that is projecting onto a white screen. At least, assuming that you intend for your audience to be able to actually read the code.</p>
<h3>Presentation Color Schemes That I Have Loved</h3><ul>
<li><a href="https://gist.github.com/4171437">Ben Alman&#39;s TextMate Theme</a>: Ben has tailored this to be incredible for presenting about JS code.</li>
<li><a href="https://github.com/chriskempson/tomorrow-theme">Tomorrow Theme</a>: The light-background flavor is decent, but could probably stand to be higher-contrast, at least for some languages.</li>
</ul>
]]></content:encoded></item><item><title>Show &amp; Tell</title><guid isPermaLink="false">times-open-science-fair</guid><link>http://rmurphey.com/2012/11/25/times-open-science-fair</link><pubDate>Sun, 25 Nov 2012 20:20:00 +0000</pubDate><description><![CDATA[I spoke at the Times Open Source Science Fair a couple of weeks ago. I&#39;ll admit that I was pretty skeptical of the concept when I was first asked, but as someone who used to work as an editor at a tiny newspaper in upstate New York, I wasn&#39;t about to say no when the Times asked me to come say hi.
A few days before the event, I got an email asking me for information about what I&#39;d be showing off at my booth. Booth? Wat? They weren&#39;t kidding about the science fair thing, but what the heck was I going to show at a booth?
It turns out this is basically the best idea ever. I recruited my Bocoup colleague Rick Waldron to join me, and together we spent a whirlwind hour showing off robots powered by JavaScript to an endless stream of people walking up to our booth. Rick did a great job of setting up a demo that people could play with, and they took turns moving sliding potentiometers that controlled servos that moved an arm with a gripper at the end, trying to pick up Bocoup stickers. Ours was one of about a dozen booths showing off open-source projects, and the room was a wonderful madhouse.
After a break for dinner, I, Jeremy Ashkenas, and Zach Holman each gave 20-minute talks, but the talks were really just icing on the evening. The &quot;science fair&quot; format promoted such intentional interaction, in a way that traditional conferences just can&#39;t, no matter how great the hall track or the parties may be. The format invited and encouraged attendees to talk to the presenters -- indeed, if they didn&#39;t talk to the presenters, there wasn&#39;t much else for them to do. By the time the official talks came around, a super-casual, super-conversational atmosphere had already been established, and the energy that created was tangibly different from any event I&#39;ve been to before.
I love conferences, and the sharing of knowledge that happens there, and there&#39;s a whole lot to be said for their speaker-audience format -- don&#39;t get me wrong. But I&#39;d also love to see more events figure out how to integrate this show and tell format. &quot;Booths&quot; don&#39;t need to mean &quot;vendors trying to sell things&quot; -- they can actually be a great opportunity to facilitate conversation, and to let open source contributors show off their hard work.]]></description><content:encoded><![CDATA[<p>I spoke at the <a href="http://opensourcesciencefair.com/">Times Open Source Science Fair</a> a couple of weeks ago. I&#39;ll admit that I was pretty skeptical of the concept when I was first asked, but as someone who used to work as an editor at a tiny newspaper in upstate New York, I wasn&#39;t about to say no when the Times asked me to come say hi.</p>
<p>A few days before the event, I got an email asking me for information about what I&#39;d be showing off at my booth. Booth? Wat? They weren&#39;t kidding about the science fair thing, but what the heck was I going to show at a booth?</p>
<p>It turns out this is basically the best idea ever. I recruited my Bocoup colleague <a href="http://twitter.com/rwaldron">Rick Waldron</a> to join me, and together we spent a whirlwind hour showing off <a href="https://github.com/rwldrn/johnny-five">robots powered by JavaScript</a> to an endless stream of people walking up to our booth. Rick did a great job of setting up a demo that people could play with, and they took turns moving <a href="https://www.sparkfun.com/products/9119">sliding potentiometers</a> that controlled <a href="https://www.sparkfun.com/products/9064">servos</a> that moved an arm with a gripper at the end, trying to pick up Bocoup stickers. Ours was one of about a <a href="http://open.blogs.nytimes.com/2012/11/21/open-source-science-fair-exhibitor-experiences/">dozen booths</a> showing off open-source projects, and the room was a wonderful madhouse.</p>
<p>After a break for dinner, I, <a href="http://twitter.com/jashkenas">Jeremy Ashkenas</a>, and <a href="http://twitter.com/holman">Zach Holman</a> each gave 20-minute talks, but the talks were really just icing on the evening. The &quot;science fair&quot; format promoted such <em>intentional interaction</em>, in a way that traditional conferences just can&#39;t, no matter how great the hall track or the parties may be. The format invited and encouraged attendees to talk to the presenters -- indeed, if they didn&#39;t talk to the presenters, there wasn&#39;t much else for them to do. By the time the official talks came around, a super-casual, super-conversational atmosphere had already been established, and the energy that created was tangibly different from any event I&#39;ve been to before.</p>
<p>I love conferences, and the sharing of knowledge that happens there, and there&#39;s a whole lot to be said for their speaker-audience format -- don&#39;t get me wrong. But I&#39;d also love to see more events figure out how to integrate this show and tell format. &quot;Booths&quot; don&#39;t need to mean &quot;vendors trying to sell things&quot; -- they can actually be a great opportunity to facilitate conversation, and to let open source contributors show off their hard work.</p>
]]></content:encoded></item><item><title>Recent Talks</title><guid isPermaLink="false">recent-talks</guid><link>http://rmurphey.com/2012/11/21/recent-talks</link><pubDate>Wed, 21 Nov 2012 10:40:00 +0000</pubDate><description><![CDATA[A post from Alex Russell reminded me that I&#39;ve given a number of talks in the last few months, and some of them even have video on the internet.
I&#39;ve been ridiculously spoiled to get to travel all over the place these last few months -- San Francisco, New York, Amsterdam, Berlin, Brighton -- and speak at some truly first-class conferences, sharing the stage, sharing meals, and sharing beers with some seriously amazing folks. My recent news means I&#39;ll be doing a lot less travel for the next little bit, but I&#39;m ever-so-grateful for the opportunities I&#39;ve had and the people I&#39;ve gotten to see and meet these last few months.
Writing Testable JavaScriptThis is the first talk I&#39;ve developed that I&#39;ve managed to give several times in rapid succession: three times in six days, including at Full Frontal, the online JS Summit, and to a group of developers at the New York Times. There&#39;s no video yet, but the slides are here, and there should be video soon, I think.


JS Minty FreshA fun talk at Fronteers about eliminating code smells from your JavaScript. The best feedback I got afterwards was from an attendee who said they felt at the beginning of the talk like the material was going to be too basic for them, and by the end of the talk, the material was nearly over their head. &quot;I guess that makes you a good teacher,&quot; he said. Aw!


Rebecca Murphey | JS Minty Fresh: Identifying and Eliminating Smells in Your Code Base | Fronteers 2012 from Fronteers on Vimeo.

Slides
If you like this, you should also check out the screencasts we released at Bocoup earlier this week.
Beyond the DOM: Sane Structure for JS AppsAn update of my code organization talk, delivered at the jQuery Conference in San Francisco. It&#39;s fun for me to see how my thinking around code organization has evolved and improved since my first, now-almost-embarassing talk at the 2009 jQuery Conference in Boston.


Slides
Johnny Five: Bringing the JavaScript Culture to HardwareThis one was from the New York Times Open Source Science Fair, a fun night of about a dozen folks presenting open-source projects at &quot;booths,&quot; followed by short talks about open source by Jeremy Ashkenas, me, and Zach Holman. The slides don&#39;t necessarily stand on their own very well, but the short version is: use JavaScript to make things in the real world, because it&#39;s ridiculously easy and ridiculously fun.


Getting Better at JavaScriptI put this together as a quickie for the Berlin UpFront user group -- it was the first talk I gave with my broken foot, and the last talk I&#39;d give for weeks because I lost my voice a couple of hours later. There&#39;s not a whole lot here, but it was a fun talk and a fun group, and a topic that I get plenty of questions about. Again, no video, but here are the slides:]]></description><content:encoded><![CDATA[<p><a href="http://infrequently.org/2012/11/bits-and-remainders/">A post from Alex Russell</a> reminded me that I&#39;ve given a number of talks in the last few months, and some of them even have video on the internet.</p>
<p>I&#39;ve been ridiculously spoiled to get to travel all over the place these last few months -- San Francisco, New York, Amsterdam, Berlin, Brighton -- and speak at some truly first-class conferences, sharing the stage, sharing meals, and sharing beers with some seriously amazing folks. My <a href="http://rmurphey.com/blog/2012/11/14/this-is-the-cup-of-coffee/">recent news</a> means I&#39;ll be doing a lot less travel for the next little bit, but I&#39;m ever-so-grateful for the opportunities I&#39;ve had and the people I&#39;ve gotten to see and meet these last few months.</p>
<h3>Writing Testable JavaScript</h3><p>This is the first talk I&#39;ve developed that I&#39;ve managed to give several times in rapid succession: three times in six days, including at <a href="http://2012.full-frontal.org/">Full Frontal</a>, the online <a href="http://environmentsforhumans.com/2012/javascript-summit/">JS Summit</a>, and to a group of developers at the New York Times. There&#39;s no video yet, but the <a href="https://speakerdeck.com/rmurphey/writing-testable-javascript-mocha-version">slides are here</a>, and there should be video soon, I think.</p>
<p><script async class="speakerdeck-embed" data-id="eb8bb4800ff201308f97123138155402" data-ratio="1.33333333333333" src="//speakerdeck.com/assets/embed.js"></script></p>

<h3>JS Minty Fresh</h3><p>A fun talk at <a href="http://fronteers.nl/congres/2012">Fronteers</a> about eliminating code smells from your JavaScript. The best feedback I got afterwards was from an attendee who said they felt at the beginning of the talk like the material was going to be too basic for them, and by the end of the talk, the material was nearly over their head. &quot;I guess that makes you a good teacher,&quot; he said. Aw!</p>
<iframe src="http://player.vimeo.com/video/53416986?badge=0" width="500" height="281" frameborder="0" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>

<p><a href="http://vimeo.com/53416986">Rebecca Murphey | JS Minty Fresh: Identifying and Eliminating Smells in Your Code Base | Fronteers 2012</a> from <a href="http://vimeo.com/fronteers">Fronteers</a> on <a href="http://vimeo.com">Vimeo</a>.</p>

<p><a href="http://rmurphey.com/js-minty-fresh/presentation/">Slides</a></p>
<p>If you like this, you should also check out the <a href="http://training.bocoup.com/screencasts/">screencasts</a> we released at Bocoup earlier this week.</p>
<h3>Beyond the DOM: Sane Structure for JS Apps</h3><p>An update of my code organization talk, delivered at the <a href="http://events.jquery.org/2012/sf/">jQuery Conference in San Francisco</a>. It&#39;s fun for me to see how my thinking around code organization has evolved and improved since my first, now-almost-embarassing talk at the 2009 jQuery Conference in Boston.</p>
<iframe width="500" height="281" src="http://www.youtube.com/embed/cd7HHN6IkrU" frameborder="0" allowfullscreen></iframe>

<p><a href="https://speakerdeck.com/rmurphey/jquery-conference-sf-2012-beyond-the-dom-sane-structure-for-js-apps">Slides</a></p>
<h3>Johnny Five: Bringing the JavaScript Culture to Hardware</h3><p>This one was from the New York Times <a href="http://opensourcesciencefair.com/">Open Source Science Fair</a>, a fun night of about a dozen folks presenting open-source projects at &quot;booths,&quot; followed by short talks about open source by Jeremy Ashkenas, me, and Zach Holman. The slides don&#39;t necessarily stand on their own very well, but the short version is: use JavaScript to make things in the real world, because it&#39;s ridiculously easy and ridiculously fun.</p>
<p><script async class="speakerdeck-embed" data-id="6ab92f30161e0130f5111231381d612b" data-ratio="1.2994923857868" src="//speakerdeck.com/assets/embed.js"></script></p>

<h3>Getting Better at JavaScript</h3><p>I put this together as a quickie for the Berlin <a href="http://up.front.ug/">UpFront</a> user group -- it was the first talk I gave with my broken foot, and the last talk I&#39;d give for weeks because I lost my voice a couple of hours later. There&#39;s not a whole lot here, but it was a fun talk and a fun group, and a topic that I get plenty of questions about. Again, no video, but here are the slides:</p>
<p><script async class="speakerdeck-embed" data-id="50746953453e4d0002081c02" data-ratio="1.2994923857868" src="//speakerdeck.com/assets/embed.js"></script></p>]]></content:encoded></item><item><title>This is the Cup of Coffee</title><guid isPermaLink="false">this-is-the-cup-of-coffee</guid><link>http://rmurphey.com/2012/11/14/this-is-the-cup-of-coffee</link><pubDate>Wed, 14 Nov 2012 10:40:00 +0000</pubDate><description><![CDATA[This is the cup of coffee I was making earlier this week when Melissa gave me a thumbs-up while she talked on the phone to a woman in Pennsylvania who had just finished telling Melissa that yes, indeed, after 10 weeks or three years of waiting depending on how you count, a 29-year-old woman who&#39;s due to give birth in Iowa at the beginning of February has decided that Melissa and I should be so lucky as to get to be her baby girl&#39;s forever family.
Most people get to post ultrasound pictures on Twitter at moments like these, but for now this will suffice to remind me of the moment I found out I would get to be a mom. My head is spinning, and while on the one hand it&#39;s a little difficult to fathom that this is all just 10 weeks away, on the other hand I&#39;m counting down the days.
Our adoption will be an open one; the meaning of &quot;open&quot; varies widely, but in our case it means we talked to the birth mother before she chose us, we&#39;ll be meeting her in a few weeks, we&#39;ll do our very best to be in Iowa for the delivery, and we&#39;ll stay in touch with letters and pictures afterwards. Melissa and I are grateful that we&#39;ll be able to adopt as a couple, though we are saddened that we have to adopt outside of our home state of North Carolina in order to do so. It&#39;s important to us that our child have both of us as her legal parents, and I don&#39;t hesitate to say that it&#39;s downright shitty that we have to jump through significant legal and financial hoops -- and stay in a hotel in Iowa with a newborn for an unknown number of days -- to make it so. It is what it is, and good people are working and voting to make it better, and it can&#39;t happen fast enough.
I&#39;ve learned a lot about adoption these past few months, and I know a lot of people have a lot of questions, some of which they&#39;re reluctant to ask. If you&#39;re interested in learning more, I highly recommend In On It: What Adoptive Parents Would Like You to Know About Adoption. You&#39;re also welcome to ask me questions if you see me in real life or on the internets -- I can&#39;t promise I&#39;ll know the answers, but I promise to do my best.
In the meantime, wish us luck :)]]></description><content:encoded><![CDATA[<p><img src="http://farm9.staticflickr.com/8482/8187360514_db246b4ac9.jpg" width="400"></p>
<p>This is the cup of coffee I was making earlier this week when Melissa gave me a thumbs-up while she talked on the phone to a woman in Pennsylvania who had just finished telling Melissa that yes, indeed, after 10 weeks or three years of waiting depending on how you count, a 29-year-old woman who&#39;s due to give birth in Iowa at the beginning of February has decided that Melissa and I should be so lucky as to get to be her baby girl&#39;s forever family.</p>
<p>Most people get to post ultrasound pictures on Twitter at moments like these, but for now this will suffice to remind me of the moment I found out I would get to be a mom. My head is spinning, and while on the one hand it&#39;s a little difficult to fathom that this is all just 10 weeks away, on the other hand I&#39;m counting down the days.</p>
<p>Our adoption will be an open one; the meaning of &quot;open&quot; varies widely, but in our case it means we talked to the birth mother before she chose us, we&#39;ll be meeting her in a few weeks, we&#39;ll do our very best to be in Iowa for the delivery, and we&#39;ll stay in touch with letters and pictures afterwards. Melissa and I are grateful that we&#39;ll be able to adopt as a couple, though we are saddened that we have to adopt outside of our home state of North Carolina in order to do so. It&#39;s important to us that our child have both of us as her <em>legal</em> parents, and I don&#39;t hesitate to say that it&#39;s downright shitty that we have to jump through significant legal and financial hoops -- and stay in a hotel in Iowa with a newborn for an unknown number of days -- to make it so. It is what it is, and good people are working and voting to make it better, and it can&#39;t happen fast enough.</p>
<p>I&#39;ve learned a lot about adoption these past few months, and I know a lot of people have a lot of questions, some of which they&#39;re reluctant to ask. If you&#39;re interested in learning more, I <em>highly</em> recommend <a href="http://www.amazon.com/In-On-It-Adoption-Relatives/dp/0982876505/ref=sr_1_1?ie=UTF8&amp;qid=1352948795&amp;sr=8-1&amp;keywords=in+on+it">In On It: What Adoptive Parents Would Like You to Know About Adoption</a>. You&#39;re also welcome to ask me questions if you see me in real life or on the internets -- I can&#39;t promise I&#39;ll know the answers, but I promise to do my best.</p>
<p>In the meantime, wish us luck :)</p>
]]></content:encoded></item><item><title>Using object literals for flow control and settings</title><guid isPermaLink="false">object-literals</guid><link>http://rmurphey.com/2011/07/24/object-literals</link><pubDate>Sun, 24 Jul 2011 0:00:00 +0000</pubDate><description><![CDATA[I got an email the other day from someone reading through jQuery Fundamentals -- they&#39;d come across the section
about patterns for performance and compression, which is based on a
presentation by Paul Irish gave back at the 2009 jQuery
Conference in Boston.
In that section, there&#39;s a bit about alternative patterns for flow control --
that is, deciding what a program should do next. We&#39;re all familiar with the
standard if statement:
{% codeblock lang:javascript %}
function isAnimal(thing) {
  if (thing === &#39;dog&#39; || thing === &#39;cat&#39;) {
    console.log(&quot;yes!&quot;);
  } else {
    console.log(&quot;no&quot;);
  }
}
{% endcodeblock %}
What stumped the person who emailed me, though, was when the same logic as we
see above was written like this:
{% codeblock lang:javascript %}
function isAnimal(thing) {
  if (({ cat : 1, dog : 1 })[ thing ]) {
    console.log(&quot;yes!&quot;);
  } else {
    console.log(&quot;no&quot;);
  }
}
{% endcodeblock %}
What&#39;s happening here is that we&#39;re using a throwaway object literal to express
the conditions under which we will say a thing is an animal. We could have
stored the object in a variable first:
{% codeblock lang:javascript %}
function isAnimal(thing) {
  var animals = {
    cat : 1,
    dog : 1
  };
  if (animals[ thing ]) {
    console.log(&quot;yes!&quot;);
  } else {
    console.log(&quot;no&quot;);
  }
}
{% endcodeblock %}
However, that variable&#39;s only purpose would be to provide this one lookup, so
it can be argued that the version that doesn&#39;t bother setting the variable is
more economical. Reasonable people can probably disagree about whether this
economy of bytes is a good tradeoff for readability -- something like this is
perfectly readable to a seasoned developer, but potentially puzzling otherwise
-- but it&#39;s an interesting example of how we can use literals in JavaScript
without bothering to store a value in a variable.
The pattern works with an array, too:
{% codeblock lang:javascript %}
function animalByIndex(index) {
  return [ &#39;cat&#39;, &#39;dog&#39; ][ index ];
}
{% endcodeblock %}
It&#39;s also useful for looking up values generally, which is how I find myself
using it most often these days in my work with Toura, where
we routinely branch our code depending on the form factor of the device we&#39;re
targeting:
{% codeblock lang:javascript %}
function getBlingLevel(device) {
  return ({
    phone : 100,
    tablet : 200
  })[ device.type ];
}
{% endcodeblock %}
As an added benefit, constructs that use this pattern will return the
conveniently falsy undefined if you try to look up a value that doesn&#39;t have
a corresponding property in the object literal.
A great way to come across techniques like this is to read the source code of
your favorite library (and other libraries too). Unfortunately, once
discovered, these patterns can be difficult to decipher, even if you have
pretty good Google fu. Just in case your neighborhood blogger isn&#39;t available,
IRC is alive and well in 2011, and it&#39;s an excellent place to get access to
smart folks eager to take the time to explain.]]></description><content:encoded><![CDATA[<p>I got an email the other day from someone reading through <a href="http://jqfundamentals.com">jQuery Fundamentals</a> -- they&#39;d come across the section
about patterns for performance and compression, which is based on a
presentation by <a href="http://paulirish.com">Paul Irish</a> gave back at the 2009 jQuery
Conference in Boston.</p>
<p>In that section, there&#39;s a bit about alternative patterns for flow control --
that is, deciding what a program should do next. We&#39;re all familiar with the
standard if statement:</p>
<p>{% codeblock lang:javascript %}
function isAnimal(thing) {
  if (thing === &#39;dog&#39; || thing === &#39;cat&#39;) {
    console.log(&quot;yes!&quot;);
  } else {
    console.log(&quot;no&quot;);
  }
}
{% endcodeblock %}</p>
<p>What stumped the person who emailed me, though, was when the same logic as we
see above was written like this:</p>
<p>{% codeblock lang:javascript %}
function isAnimal(thing) {
  if (({ cat : 1, dog : 1 })[ thing ]) {
    console.log(&quot;yes!&quot;);
  } else {
    console.log(&quot;no&quot;);
  }
}
{% endcodeblock %}</p>
<p>What&#39;s happening here is that we&#39;re using a throwaway object literal to express
the conditions under which we will say a <code>thing</code> is an animal. We could have
stored the object in a variable first:</p>
<p>{% codeblock lang:javascript %}
function isAnimal(thing) {
  var animals = {
    cat : 1,
    dog : 1
  };</p>
<p>  if (animals[ thing ]) {
    console.log(&quot;yes!&quot;);
  } else {
    console.log(&quot;no&quot;);
  }
}
{% endcodeblock %}</p>
<p>However, that variable&#39;s only purpose would be to provide this one lookup, so
it can be argued that the version that doesn&#39;t bother setting the variable is
more economical. Reasonable people can probably disagree about whether this
economy of bytes is a good tradeoff for readability -- something like this is
perfectly readable to a seasoned developer, but potentially puzzling otherwise
-- but it&#39;s an interesting example of how we can use literals in JavaScript
without bothering to store a value in a variable.</p>
<p>The pattern works with an array, too:</p>
<p>{% codeblock lang:javascript %}
function animalByIndex(index) {
  return [ &#39;cat&#39;, &#39;dog&#39; ][ index ];
}
{% endcodeblock %}</p>
<p>It&#39;s also useful for looking up values generally, which is how I find myself
using it most often these days in my work with <a href="http://toura.com">Toura</a>, where
we routinely branch our code depending on the form factor of the device we&#39;re
targeting:</p>
<p>{% codeblock lang:javascript %}
function getBlingLevel(device) {
  return ({
    phone : 100,
    tablet : 200
  })[ device.type ];
}
{% endcodeblock %}</p>
<p>As an added benefit, constructs that use this pattern will return the
conveniently falsy <code>undefined</code> if you try to look up a value that doesn&#39;t have
a corresponding property in the object literal.</p>
<p>A great way to come across techniques like this is to read the source code of
your favorite library (and other libraries too). Unfortunately, once
discovered, these patterns can be difficult to decipher, even if you have
pretty good Google fu. Just in case your neighborhood blogger isn&#39;t available,
IRC is alive and well in 2011, and it&#39;s an excellent place to get access to
smart folks eager to take the time to explain.</p>
]]></content:encoded></item><item><title>Lessons From a Rewrite</title><guid isPermaLink="false">lessons-from-a-rewrite</guid><link>http://rmurphey.com/2011/07/06/lessons-from-a-rewrite</link><pubDate>Wed, 06 Jul 2011 9:50:00 +0000</pubDate><description><![CDATA[MVC and friends have been around for decades, but it’s only in the last couple
of years that broad swaths of developers have started applying those patterns
to JavaScript. As that awareness spreads, developers eager to use their
newfound insight are presented with a target-rich environment, and the
temptation to rewrite can be strong.

There’s a subtle reason that programmers always want to throw away the code
and start over. The reason is that they think the old code is a mess. … The reason
that they think the old code is a mess is because of a cardinal, fundamental
law of programming: It’s harder to read code than to write it. -  Joel Spolsky


When I started working with  Toura Mobile  late last year, they already had
a product: a web-based CMS to create the structure of a mobile application and
populate it with content, and a PhoneGap-based application to consume the
output of the CMS inside a native application. Customers were paying, but the
development team was finding that delivering new features was a struggle, and
bug fixes seemed just as likely to break something else as not. They contacted
me to see whether they should consider a rewrite.
With due deference to Spolsky, I don’t think it was a lack of readability
driving their inclination to rewrite. In fact, the code wasn’t all that
difficult to read or follow. The problem was that the PhoneGap side of things
had been written to solve the problems of a single-purpose, one-off
application, and it was becoming clear that it needed to be a flexible,
extensible delivery system for all of the content combinations clients could
dream up. It wasn’t an app — it was an app that made there be an app.

Where a new system concept or new technology is used, one has to build a system
to throw away, for even the best planning is not so omniscient as to get it
right the first time. Hence plan to throw one away; you will, anyhow. - Fred
Brooks,  The Mythical Man Month 

By the time I’d reviewed the code and started writing up my findings, the
decision had already been made: Toura was going to throw one away and start
from scratch. For four grueling and exciting months, I helped them figure out
how to do it better the second time around. In the end, I like to think we’ve
come up with a solid architecture that’s going to adapt well to clients’
ever-changing needs. Here, then, are some of the lessons we learned along the
way.
Understand what you’re rewritingI had spent only a few days with the codebase when we decided that we were
going to rewrite it. In some ways, this was good — I was a fresh set of eyes,
someone who could think about the system in a new way — but in other ways, it
was a major hindrance. We spent a lot of time at the beginning getting me up to
speed on what, exactly, we were making; things that went without saying for
existing team members did not, in fact, go without saying for me.
This constant need for explanation and clarification was frustrating at times,
both for me and for the existing team, but it forced us to state the problem in
plain terms. The value of this was incredible — as a team, we were far less
likely to accept assumptions from the original implementation, even assumptions
that seemed obvious.
One of the key features of Toura applications is the ability to update them
“over the air” — it’s not necessary to put a new version in an app store in
order to update an app’s content or even its structure. In the original app,
this was accomplished via generated SQL diffs of the data. If the app was at
version 3, and the data in the CMS was at version 10, then the app would
request a patch file to upgrade version 3 to version 10. The CMS had to
generate a diff for all possible combinations: version 3 to version 10, version
4 to version 10, etc. The diff consisted of queries to run against an SQLite
database on the device. Opportunities for failures or errors were rampant,
a situation exacerbated by the async nature of the SQLite interface.
In the new app, we replicated the feature with vastly less complexity
— whenever there is an update, we just make the full data available at an
app-specific URL as a JSON file, using the same format that we use to provide
the initial data for the app on the device. The new data is stored on the
device, but it’s also retained in memory while the application is running via
Dojo’s Item File Read Store, which allows us to query it synchronously. The
need for version-by-version diffs has been eliminated.
Restating the problem led to a simpler, more elegant solution that greatly
reduced the opportunities for errors and failure. As an added benefit, using
JSON has allowed us to meet needs that we never anticipated — the flexibility
it provides has become a valuable tool in our toolbox.
Identify pain pointsIf the point of a rewrite is to make development easier, then an important step
is to figure out what, exactly, is making development hard. Again, this was
a time to question assumptions — as it turned out, there were things that had
come to be accepted burdens that were actually relatively easy to address.
One of the biggest examples of this was the time required to develop and test
anything that might behave differently on one operating system versus another.
For example, the Android OS has limited support for the audio and video tags,
so a native workaround is required to play media on Android that is not
required on iOS.
In the original code, this device-specific branching was handled in a way that
undoubtedly made sense at the beginning but grew unwieldy over time. Developers
would create Mustache templates, wrapping the template tags in /* */ so the
templates were actually executable, and then compile those templates into plain
JavaScript files for production. Here are a few lines from one of those
templates:
{% codeblock lang:javascript %}
/ {{^android}} /
var mediaPath = &quot;www/media/&quot; + toura.pages.currentId + &quot;/&quot;;
/ {{/android}} /
/ {{#android}} /
var mediaPath = [Toura.getTouraPath(), toura.pages.currentId].join(&quot;/&quot;);
/ {{/android}} /
var imagesList = [], dimensionsList = [], namesList = [], thumbsList = [];
var pos = -1, count = 0;
/ {{#android}} /
var pos = 0, count = 0;
/ {{/android}} /
{% endcodeblock %}
These templates were impossible to check with a code quality tool like JSHint,
because it was standard to declare the same variable multiple times. Multiple
declarations of the same variable meant that the order of those declarations
was important, which made the templates tremendously fragile. The theoretical
payoff was smaller code in production, but the cost of that byte shaving was
high, and the benefit somewhat questionable — after all, we’d be delivering the
code directly from the device, not over HTTP.
In the rewrite, we used a simple configuration object to specify information
about the environment, and then we look at the values in that configuration
object to determine how the app should behave. The configuration object is
created as part of building a production-ready app, but in development we can
alter configuration settings at will. Simple if statements replaced fragile
template tags.
Since Dojo allows specifying code blocks for exclusion based on the settings
you provide to the build process, we could mark code for exclusion if we really
didn’t want it in production.
By using a configuration object instead of template tags for branching, we
eliminated a major pain point in day-to-day development. While nothing matches
the proving ground of the device itself, it’s now trivial to effectively
simulate different device experiences from the comfort of the browser. We do
the majority of our development there, with a high degree of confidence that
things will work mostly as expected once we reach the device. If you’ve ever
waited for an app to build and install to a device, then you know how much
faster it is to just press Command-R in your browser instead.
Have a communication manifestoDeciding that you’re going to embrace an MVC-ish approach to an application is
a big step, but only a first step — there are a million more decisions you’re
going to need to make, big and small. One of the widest-reaching decisions to
make is how you’ll communicate among the various pieces of the application.
There are all sorts of levels of communication, from application-wide state
management — what page am I on? — to communication between UI components — when
a user enters a search term, how do I get and display the results?
From the outset, I had a fairly clear idea of how this should work based on
past experiences, but at first I took for granted that the other developers
would see things the same way I did, and I wasn’t necessarily consistent
myself. For a while we had several different patterns of communication,
depending on who had written the code and when. Every time you went to use
a component, it was pretty much a surprise which pattern it would use.
After one too many episodes of frustration, I realized that part of my job was
going to be to lay down the law about this — it wasn’t that my way was more
right than others, but rather that we needed to choose a way, or else reuse and
maintenance was going to become a nightmare. Here’s what I came up with:

myComponent.set(key, value) to change state (with the help of setter
methods from Dojo’s dijit._Widget mixin)
myComponent.on&amp;lt;Event&amp;gt;(componentEventData) to announce state changes
and user interaction; Dojo lets us
connect to the
execution of arbitrary methods, so other pieces could listen for these
methods to be executed.
dojo.publish(topic, [ data ]) to announce occurrences of app-wide interest,
such as when the window is resized
myComponent.subscribe(topic) to allow individual components react to
published topics

Once we spelled out the patterns, the immediate benefit
wasn’t maintainability or reuse; rather, we found that we didn’t have to make
these decisions on a component-by-component basis anymore, and we could focus
on the questions that were actually unique to a component. With conventions
we could rely on, we were constantly discovering new ways to abstract and DRY
our code, and the consistency across components meant it was easier to work
with code someone else had written.
Sanify asynchronicityOne of the biggest challenges of JavaScript development — well, besides working
with the DOM — is managing the asynchronicity of it all. In the old system,
this was dealt with in various ways: sometimes a method would take a success
callback and a failure callback; other times a function would return an object
and check one of its properties on an interval.
{% codeblock lang:javascript %}
images = toura.sqlite.getMedias(id, &quot;image&quot;);
var onGetComplete = setInterval(function () {
  if (images.incomplete)
    return;
  clearInterval(onGetComplete);
  showImagesHelper(images.objs, choice)
},10);
{% endcodeblock %}
The problem here, of course, is that if images.incomplete never gets set to
false — that is, if the getMedias method fails — then the interval will never
get cleared. Dojo and now jQuery (since version 1.5) offer a facility for
handling this situation in an elegant and powerful way. In the new version of
the app, the above functionality looks something like this:
{% codeblock lang:javascript %}
toura.app.Data.get(id, ‘image’).then(showImages, showImagesFail);
{% endcodeblock %}
The get method of toura.app.Data returns an immutable promise
— the promise’s then method makes the resulting value of the asynchronous get
method available to showImages, but does not allow showImages to alter the
value. The promise returned by the get method can also be stored in a variable,
so that additional callbacks can be attached to it.
Using promises vastly simplifies asynchronous code, which can be one of the
biggest sources of complexity in a non-trivial application. By using promises,
we got code that was easier to follow, components that were thoroughly
decoupled, and new flexibility in how we responded to the outcome of an
asynchronous operation.
Naming things is hardThroughout the course of the rewrite we were constantly confronted with one of
those pressing questions developers wrestle with: what should I name this
variable/module/method/thing? Sometimes I would find myself feeling slightly
absurd about the amount of time we’d spend naming a thing, but just recently
I was reminded how much power those names have over our thinking.
Every application generated by the Toura CMS consists of a set of “nodes,”
organized into a hierarchy. With the exception of pages that are standard
across all apps, such as the search page, the base content type for a page
inside APP is always a node — or rather, it was, until the other day. I was
working on a new feature and struggling to figure out how I’d display a piece
of content that was unique to the app but wasn’t really associated with a node
at all. I pored over our existing code, seeing the word node on what felt like
every other line. As an experiment, I changed that word node to baseObj in
a few high-level files, and suddenly a whole world of solutions opened up to me
— the name of a thing had limiting my thinking.
The lesson here, for me, is that the time we spent (and spend) figuring out
what to name a thing is not lost time; perhaps even more importantly, the goal
should be to give a thing the most generic name that still conveys what the
thing’s job — in the context in which you’ll use the thing — actually is.
Never write large appsI touched on this earlier, but if there is one lesson I take from every large
app I’ve worked on, it is this:

The secret to building large apps is never build large apps. Break up your
applications into small pieces. Then, assemble those testable, bite-sized
pieces into your big application. - Justin Meyer

The more tied components are to each other, the less reusable they will be, and
the more difficult it becomes to make changes to one without accidentally
affecting another. Much like we had a manifesto of sorts for communication
among components, we strived for a clear delineation of responsibilities among
our components. Each one should do one thing and do it well.
For example, simply rendering a page involves several small, single-purpose
components:
{% codeblock lang:javascript %}
function nodeRoute(route, nodeId, pageState) {
  pageState = pageState || {};
  var nodeModel = toura.app.Data.getModel(nodeId),
      page = toura.app.UI.getCurrentPage();
  if (!nodeModel) {
    toura.app.Router.home();
    return;
  }
  if (!page || !page.node || nodeId !== page.node.id) {
    page = toura.app.PageFactory.createPage(&#39;node&#39;, nodeModel);
if (page.failure) {
  toura.app.Router.back();
  return;
}

toura.app.UI.showPage(pf, nodeModel);
  }
  page.init(pageState);
  // record node pageview if it is node-only
  if (nodeId &amp;&amp; !pageState.assetType) {
    dojo.publish(&#39;/node/view&#39;, [ route.hash ]);
  }
  return true;
}
{% endcodeblock %}
The router observes a URL change, parses the parameters for the route from the
URL, and passes those parameters to a function. The Data component gets the
relevant data, and then hands it to the PageFactory component to generate the
page. As the page is generated, the individual components for the page are also
created and placed in the page. The PageFactory component returns the generated
page, but at this point the page is not in the DOM. The UI component receives
it, places it in the DOM, and handles the animation from the old page to the
new one.
Every step is its own tiny app, making the whole process tremendously testable.
The output of one step may become the input to another step, but when input and
output are predictable, the questions our tests need to answer are trivial:
“When I asked the Data component for the data for node123, did I get the data
for node123?”
Individual UI components are their own tiny apps as well. On a page that
displays a videos node, we have a video player component, a video list
component, and a video caption component. Selecting a video in the list
announces the selection via the list’s onSelect method. Dojo allows us to
connect to the execution of object methods, so in the page controller, we have
this:
{% codeblock lang:javascript %}
this.connect(this.videoList, &#39;onSelect&#39;, function(assetId) {
  var video = this._videoById(assetId);
  this.videoCaption.set(&#39;content&#39;, video.caption || &#39;&#39;);
  this.videoPlayer.play(assetId);
});
{% endcodeblock %}
The page controller receives the message and passes it along to the other
components that need to know about it — components don’t communicate directly
with one another. This means the component that lists the videos can list
anything, not just videos — its only job is to announce a selection, not to do
anything as a result.
Keep rewriting
It takes confidence to throw work away … When people first start drawing,
they’re often reluctant to redo parts that aren’t right … they convince
themselves that the drawing is not that bad, really — in fact, maybe they meant
it to look that way. - Paul Graham, “Taste for Makers”

The blank slate offered by a rewrite allows us to fix old mistakes, but
inevitably we will make new ones in the process. As good stewards of our code,
we must always be open to the possibility of a better way of doing a thing. “It
works” should never be mistaken for “it’s done.”]]></description><content:encoded><![CDATA[<p>MVC and friends have been around for decades, but it’s only in the last couple
of years that broad swaths of developers have started applying those patterns
to JavaScript. As that awareness spreads, developers eager to use their
newfound insight are presented with a target-rich environment, and the
temptation to rewrite can be strong.</p>
<blockquote>
<p>There’s a subtle reason that programmers always want to throw away the code
and start over. The reason is that they think the old code is a mess. … The reason
that they think the old code is a mess is because of a cardinal, fundamental
law of programming: It’s harder to read code than to write it. - <a href="http://www.joelonsoftware.com/articles/fog0000000069.html"> Joel Spolsky
</a></p>
</blockquote>
<p>When I started working with <a href="http://toura.com/"> Toura Mobile </a> late last year, they already had
a product: a web-based CMS to create the structure of a mobile application and
populate it with content, and a PhoneGap-based application to consume the
output of the CMS inside a native application. Customers were paying, but the
development team was finding that delivering new features was a struggle, and
bug fixes seemed just as likely to break something else as not. They contacted
me to see whether they should consider a rewrite.</p>
<p>With due deference to Spolsky, I don’t think it was a lack of readability
driving their inclination to rewrite. In fact, the code wasn’t all that
difficult to read or follow. The problem was that the PhoneGap side of things
had been written to solve the problems of a single-purpose, one-off
application, and it was becoming clear that it needed to be a flexible,
extensible delivery system for all of the content combinations clients could
dream up. It wasn’t an app — it was an app that made there be an app.</p>
<blockquote>
<p>Where a new system concept or new technology is used, one has to build a system
to throw away, for even the best planning is not so omniscient as to get it
right the first time. Hence plan to throw one away; you will, anyhow. - Fred
Brooks, <a href="http://en.wikipedia.org/wiki/The_Mythical_Man-Month"> The Mythical Man Month </a></p>
</blockquote>
<p>By the time I’d reviewed the code and started writing up my findings, the
decision had already been made: Toura was going to throw one away and start
from scratch. For four grueling and exciting months, I helped them figure out
how to do it better the second time around. In the end, I like to think we’ve
come up with a solid architecture that’s going to adapt well to clients’
ever-changing needs. Here, then, are some of the lessons we learned along the
way.</p>
<h2>Understand what you’re rewriting</h2><p>I had spent only a few days with the codebase when we decided that we were
going to rewrite it. In some ways, this was good — I was a fresh set of eyes,
someone who could think about the system in a new way — but in other ways, it
was a major hindrance. We spent a lot of time at the beginning getting me up to
speed on what, exactly, we were making; things that went without saying for
existing team members did not, in fact, go without saying for me.</p>
<p>This constant need for explanation and clarification was frustrating at times,
both for me and for the existing team, but it forced us to state the problem in
plain terms. The value of this was incredible — as a team, we were far less
likely to accept assumptions from the original implementation, even assumptions
that seemed obvious.</p>
<p>One of the key features of Toura applications is the ability to update them
“over the air” — it’s not necessary to put a new version in an app store in
order to update an app’s content or even its structure. In the original app,
this was accomplished via generated SQL diffs of the data. If the app was at
version 3, and the data in the CMS was at version 10, then the app would
request a patch file to upgrade version 3 to version 10. The CMS had to
generate a diff for all possible combinations: version 3 to version 10, version
4 to version 10, etc. The diff consisted of queries to run against an SQLite
database on the device. Opportunities for failures or errors were rampant,
a situation exacerbated by the async nature of the SQLite interface.</p>
<p>In the new app, we replicated the feature with vastly less complexity
— whenever there is an update, we just make the full data available at an
app-specific URL as a JSON file, using the same format that we use to provide
the initial data for the app on the device. The new data is stored on the
device, but it’s also retained in memory while the application is running via
Dojo’s Item File Read Store, which allows us to query it synchronously. The
need for version-by-version diffs has been eliminated.</p>
<p>Restating the problem led to a simpler, more elegant solution that greatly
reduced the opportunities for errors and failure. As an added benefit, using
JSON has allowed us to meet needs that we never anticipated — the flexibility
it provides has become a valuable tool in our toolbox.</p>
<h2>Identify pain points</h2><p>If the point of a rewrite is to make development easier, then an important step
is to figure out what, exactly, is making development hard. Again, this was
a time to question assumptions — as it turned out, there were things that had
come to be accepted burdens that were actually relatively easy to address.</p>
<p>One of the biggest examples of this was the time required to develop and test
anything that might behave differently on one operating system versus another.
For example, the Android OS has limited support for the audio and video tags,
so a native workaround is required to play media on Android that is not
required on iOS.</p>
<p>In the original code, this device-specific branching was handled in a way that
undoubtedly made sense at the beginning but grew unwieldy over time. Developers
would create Mustache templates, wrapping the template tags in <code>/* */</code> so the
templates were actually executable, and then compile those templates into plain
JavaScript files for production. Here are a few lines from one of those
templates:</p>
<p>{% codeblock lang:javascript %}
/<em> {{^android}} </em>/
var mediaPath = &quot;www/media/&quot; + toura.pages.currentId + &quot;/&quot;;
/<em> {{/android}} </em>/
/<em> {{#android}} </em>/
var mediaPath = [Toura.getTouraPath(), toura.pages.currentId].join(&quot;/&quot;);
/<em> {{/android}} </em>/
var imagesList = [], dimensionsList = [], namesList = [], thumbsList = [];
var pos = -1, count = 0;
/<em> {{#android}} </em>/
var pos = 0, count = 0;
/<em> {{/android}} </em>/
{% endcodeblock %}</p>
<p>These templates were impossible to check with a code quality tool like JSHint,
because it was standard to declare the same variable multiple times. Multiple
declarations of the same variable meant that the order of those declarations
was important, which made the templates tremendously fragile. The theoretical
payoff was smaller code in production, but the cost of that byte shaving was
high, and the benefit somewhat questionable — after all, we’d be delivering the
code directly from the device, not over HTTP.</p>
<p>In the rewrite, we used a simple configuration object to specify information
about the environment, and then we look at the values in that configuration
object to determine how the app should behave. The configuration object is
created as part of building a production-ready app, but in development we can
alter configuration settings at will. Simple <code>if</code> statements replaced fragile
template tags.</p>
<p>Since Dojo allows specifying code blocks for exclusion based on the settings
you provide to the build process, we could mark code for exclusion if we really
didn’t want it in production.</p>
<p>By using a configuration object instead of template tags for branching, we
eliminated a major pain point in day-to-day development. While nothing matches
the proving ground of the device itself, it’s now trivial to effectively
simulate different device experiences from the comfort of the browser. We do
the majority of our development there, with a high degree of confidence that
things will work mostly as expected once we reach the device. If you’ve ever
waited for an app to build and install to a device, then you know how much
faster it is to just press Command-R in your browser instead.</p>
<h2>Have a communication manifesto</h2><p>Deciding that you’re going to embrace an MVC-ish approach to an application is
a big step, but only a first step — there are a million more decisions you’re
going to need to make, big and small. One of the widest-reaching decisions to
make is how you’ll communicate among the various pieces of the application.
There are all sorts of levels of communication, from application-wide state
management — what page am I on? — to communication between UI components — when
a user enters a search term, how do I get and display the results?</p>
<p>From the outset, I had a fairly clear idea of how this should work based on
past experiences, but at first I took for granted that the other developers
would see things the same way I did, and I wasn’t necessarily consistent
myself. For a while we had several different patterns of communication,
depending on who had written the code and when. Every time you went to use
a component, it was pretty much a surprise which pattern it would use.</p>
<p>After one too many episodes of frustration, I realized that part of my job was
going to be to lay down the law about this — it wasn’t that my way was more
right than others, but rather that we needed to choose a way, or else reuse and
maintenance was going to become a nightmare. Here’s what I came up with:</p>
<ul>
<li><code>myComponent.set(key, value)</code> to change state (with the help of setter
methods from Dojo’s <a href="http://dojotoolkit.org/reference-guide/dijit/_Widget.html">dijit._Widget mixin</a>)</li>
<li><code>myComponent.on&amp;lt;Event&amp;gt;(componentEventData)</code> to announce state changes
and user interaction; Dojo lets us
<a href="http://dojotoolkit.org/reference-guide/dojo/connect.html">connect</a> to the
execution of arbitrary methods, so other pieces could listen for these
methods to be executed.</li>
<li><code>dojo.publish(topic, [ data ])</code> to announce occurrences of app-wide interest,
such as when the window is resized</li>
<li><code>myComponent.subscribe(topic)</code> to allow individual components react to
published topics</li>
</ul>
<p>Once we spelled out the patterns, the immediate benefit
wasn’t maintainability or reuse; rather, we found that we didn’t have to make
these decisions on a component-by-component basis anymore, and we could focus
on the questions that were actually unique to a component. With conventions
we could rely on, we were constantly discovering new ways to abstract and DRY
our code, and the consistency across components meant it was easier to work
with code someone else had written.</p>
<h2>Sanify asynchronicity</h2><p>One of the biggest challenges of JavaScript development — well, besides working
with the DOM — is managing the asynchronicity of it all. In the old system,
this was dealt with in various ways: sometimes a method would take a success
callback and a failure callback; other times a function would return an object
and check one of its properties on an interval.</p>
<p>{% codeblock lang:javascript %}
images = toura.sqlite.getMedias(id, &quot;image&quot;);</p>
<p>var onGetComplete = setInterval(function () {
  if (images.incomplete)
    return;</p>
<p>  clearInterval(onGetComplete);
  showImagesHelper(images.objs, choice)
},10);
{% endcodeblock %}</p>
<p>The problem here, of course, is that if <code>images.incomplete</code> never gets set to
false — that is, if the <code>getMedias</code> method fails — then the interval will never
get cleared. Dojo and now jQuery (since version 1.5) offer a facility for
handling this situation in an elegant and powerful way. In the new version of
the app, the above functionality looks something like this:</p>
<p>{% codeblock lang:javascript %}
toura.app.Data.get(id, ‘image’).then(showImages, showImagesFail);
{% endcodeblock %}</p>
<p>The <code>get</code> method of <code>toura.app.Data</code> returns an <a href="http://www.sitepen.com/blog/2010/05/03/robust-promises-with-dojo-deferred-1-5/">immutable promise</a>
— the promise’s then method makes the resulting value of the asynchronous get
method available to <code>showImages</code>, but does not allow <code>showImages</code> to alter the
value. The promise returned by the get method can also be stored in a variable,
so that additional callbacks can be attached to it.</p>
<p>Using promises vastly simplifies asynchronous code, which can be one of the
biggest sources of complexity in a non-trivial application. By using promises,
we got code that was easier to follow, components that were thoroughly
decoupled, and new flexibility in how we responded to the outcome of an
asynchronous operation.</p>
<h2>Naming things is hard</h2><p>Throughout the course of the rewrite we were constantly confronted with one of
those pressing questions developers wrestle with: what should I name this
variable/module/method/thing? Sometimes I would find myself feeling slightly
absurd about the amount of time we’d spend naming a thing, but just recently
I was reminded how much power those names have over our thinking.</p>
<p>Every application generated by the Toura CMS consists of a set of “nodes,”
organized into a hierarchy. With the exception of pages that are standard
across all apps, such as the search page, the base content type for a page
inside APP is always a node — or rather, it was, until the other day. I was
working on a new feature and struggling to figure out how I’d display a piece
of content that was unique to the app but wasn’t really associated with a node
at all. I pored over our existing code, seeing the word node on what felt like
every other line. As an experiment, I changed that word node to baseObj in
a few high-level files, and suddenly a whole world of solutions opened up to me
— the name of a thing had limiting my thinking.</p>
<p>The lesson here, for me, is that the time we spent (and spend) figuring out
what to name a thing is not lost time; perhaps even more importantly, the goal
should be to give a thing the most generic name that still conveys what the
thing’s job — in the context in which you’ll use the thing — actually is.</p>
<h2>Never write large apps</h2><p>I touched on this earlier, but if there is one lesson I take from every large
app I’ve worked on, it is this:</p>
<blockquote>
<p>The secret to building large apps is never build large apps. Break up your
applications into small pieces. Then, assemble those testable, bite-sized
pieces into your big application. - Justin Meyer</p>
</blockquote>
<p>The more tied components are to each other, the less reusable they will be, and
the more difficult it becomes to make changes to one without accidentally
affecting another. Much like we had a manifesto of sorts for communication
among components, we strived for a clear delineation of responsibilities among
our components. Each one should do one thing and do it well.</p>
<p>For example, simply rendering a page involves several small, single-purpose
components:</p>
<p>{% codeblock lang:javascript %}
function nodeRoute(route, nodeId, pageState) {
  pageState = pageState || {};</p>
<p>  var nodeModel = toura.app.Data.getModel(nodeId),
      page = toura.app.UI.getCurrentPage();</p>
<p>  if (!nodeModel) {
    toura.app.Router.home();
    return;
  }</p>
<p>  if (!page || !page.node || nodeId !== page.node.id) {
    page = toura.app.PageFactory.createPage(&#39;node&#39;, nodeModel);</p>
<pre><code>if (page.failure) {
  toura.app.Router.back();
  return;
}

toura.app.UI.showPage(pf, nodeModel);
</code></pre><p>  }</p>
<p>  page.init(pageState);</p>
<p>  // record node pageview if it is node-only
  if (nodeId &amp;&amp; !pageState.assetType) {
    dojo.publish(&#39;/node/view&#39;, [ route.hash ]);
  }</p>
<p>  return true;
}
{% endcodeblock %}</p>
<p>The router observes a URL change, parses the parameters for the route from the
URL, and passes those parameters to a function. The Data component gets the
relevant data, and then hands it to the PageFactory component to generate the
page. As the page is generated, the individual components for the page are also
created and placed in the page. The PageFactory component returns the generated
page, but at this point the page is not in the DOM. The UI component receives
it, places it in the DOM, and handles the animation from the old page to the
new one.</p>
<p>Every step is its own tiny app, making the whole process tremendously testable.
The output of one step may become the input to another step, but when input and
output are predictable, the questions our tests need to answer are trivial:
“When I asked the Data component for the data for node123, did I get the data
for node123?”</p>
<p>Individual UI components are their own tiny apps as well. On a page that
displays a videos node, we have a video player component, a video list
component, and a video caption component. Selecting a video in the list
announces the selection via the list’s onSelect method. Dojo allows us to
connect to the execution of object methods, so in the page controller, we have
this:</p>
<p>{% codeblock lang:javascript %}
this.connect(this.videoList, &#39;onSelect&#39;, function(assetId) {
  var video = this._videoById(assetId);
  this.videoCaption.set(&#39;content&#39;, video.caption || &#39;&#39;);
  this.videoPlayer.play(assetId);
});
{% endcodeblock %}</p>
<p>The page controller receives the message and passes it along to the other
components that need to know about it — components don’t communicate directly
with one another. This means the component that lists the videos can list
anything, not just videos — its only job is to announce a selection, not to do
anything as a result.</p>
<h2>Keep rewriting</h2><blockquote>
<p>It takes confidence to throw work away … When people first start drawing,
they’re often reluctant to redo parts that aren’t right … they convince
themselves that the drawing is not that bad, really — in fact, maybe they meant
it to look that way. - <a href="http://www.paulgraham.com/taste.html">Paul Graham, “Taste for Makers”</a></p>
</blockquote>
<p>The blank slate offered by a rewrite allows us to fix old mistakes, but
inevitably we will make new ones in the process. As good stewards of our code,
we must always be open to the possibility of a better way of doing a thing. “It
works” should never be mistaken for “it’s done.”</p>
]]></content:encoded></item><item><title>A new chapter</title><guid isPermaLink="false">a-new-chapter</guid><link>http://rmurphey.com/2011/05/31/a-new-chapter</link><pubDate>Tue, 31 May 2011 0:00:00 +0000</pubDate><description><![CDATA[It was three years ago this summer that I got the call, bought the Yuengling, smoked the cigarettes, and began life as an independent consultant. It&rsquo;s been (almost) three years of ups and downs, and, eventually, among the most rewarding experiences of my life. Day by day, I wrote my own job description, found my own clients, set my own schedule, and set my own agenda.

Starting tomorrow, it&rsquo;s time for a new chapter in my working life: I&rsquo;ll be joining Toura Mobile full-time as their lead JavaScript developer, continuing my work with them on creating a PhoneGap- and Dojo-based platform for the rapid creation of content-rich mobile applications.

I&rsquo;ve been working with Toura for about six months now, starting shortly after I met Matt Rogish, their director of development, at a JavaScript event in New York. They brought me on as a consultant to review their existing application, and the eventual decision was to rewrite it from the ground up, using the lessons learned and knowledge gained from the first version to inform the second. It was a risky decision, but it&rsquo;s paid off: earlier this year, Toura started shipping apps built with the rewritten system, and the care we took to create modular, loosely coupled components from the get-go has paid off immensely, meeting current needs while making it easier to develop new features. With the rewrite behind us, these days we&rsquo;re using the solid foundation we built to allow users of the platform to create ever more customized experiences in their applications.

If you know me at all, you know that I&rsquo;ve been pretty die-hard about being an independent consultant, so you might think this was a difficult decision. Oddly, it wasn&rsquo;t &mdash; I&rsquo;ve enjoyed these last several months immensely, the team I work with is fantastic, and I&rsquo;ve never felt more proud of work I&rsquo;ve done. Whenever I found myself wondering whether Toura might eventually tire of paying my consulting rates, I&rsquo;d get downright mopey. Over the course of three years, I&rsquo;ve worked hard for all of my clients, but this is the first time I&rsquo;ve felt so invested in a project&rsquo;s success or failure, like there was a real and direct correlation between my efforts and the outcome. It&rsquo;s a heady feeling, and I hope and expect it to continue for a while.

By the way, I&rsquo;ll be talking about the rewrite at both TXJS and GothamJS in the next few weeks.

Also: we&rsquo;re hiring :)]]></description><content:encoded><![CDATA[<p>It was three years ago this summer that I <a href="http://blog.rebeccamurphey.com/2-years-in-some-thoughts-on-working-for-mysel">got the call, bought the Yuengling, smoked the cigarettes</a>, and began life as an independent consultant. It&rsquo;s been (almost) three years of ups and downs, and, eventually, among the most rewarding experiences of my life. Day by day, I wrote my own job description, found my own clients, set my own schedule, and set my own agenda.</p>

<p>Starting tomorrow, it&rsquo;s time for a new chapter in my working life: I&rsquo;ll be joining <a href="http://toura.com">Toura Mobile</a> full-time as their lead JavaScript developer, continuing my work with them on creating a PhoneGap- and Dojo-based platform for the rapid creation of content-rich mobile applications.</p>

<p>I&rsquo;ve been working with Toura for about six months now, starting shortly after I met <a href="http://twitter.com/MattRogish">Matt Rogish</a>, their director of development, at a JavaScript event in New York. They brought me on as a consultant to review their existing application, and the eventual decision was to rewrite it from the ground up, using the lessons learned and knowledge gained from the first version to inform the second. It was a risky decision, but it&rsquo;s paid off: earlier this year, Toura started shipping apps built with the rewritten system, and the care we took to create modular, loosely coupled components from the get-go has paid off immensely, meeting current needs while making it easier to develop new features. With the rewrite behind us, these days we&rsquo;re using the solid foundation we built to allow users of the platform to create ever more customized experiences in their applications.</p>

<p>If you know me at all, you know that I&rsquo;ve been pretty die-hard about being an independent consultant, so you might think this was a difficult decision. Oddly, it wasn&rsquo;t &mdash; I&rsquo;ve enjoyed these last several months immensely, the team I work with is fantastic, and I&rsquo;ve never felt more proud of work I&rsquo;ve done. Whenever I found myself wondering whether Toura might eventually tire of paying my consulting rates, I&rsquo;d get downright mopey. Over the course of three years, I&rsquo;ve worked hard for all of my clients, but this is the first time I&rsquo;ve felt so invested in a project&rsquo;s success or failure, like there was a real and direct correlation between my efforts and the outcome. It&rsquo;s a heady feeling, and I hope and expect it to continue for a while.</p>

<p>By the way, I&rsquo;ll be talking about the rewrite at both <a href="http://2011.texasjavascript.com">TXJS</a> and <a href="http://gothamjs.com">GothamJS</a> in the next few weeks.</p>

<p>Also: <a href="http://toura.com/about/jobs/">we&rsquo;re hiring</a> :)</p>]]></content:encoded></item><item><title>Getting Better at JavaScript</title><guid isPermaLink="false">getting-better-at-javascript</guid><link>http://rmurphey.com/2011/05/20/getting-better-at-javascript</link><pubDate>Fri, 20 May 2011 0:00:00 +0000</pubDate><description><![CDATA[I seem to be getting a lot of emails these days asking a deceptively simple
question: “How do I get better at JavaScript?” What follows are some
semi-random thoughts on the subject:
The thing that I’ve come to realize about these questions is that some things
just take time. I wish I could write down “Ten Things You Need to Know to Make
You Amazing at the JavaScript,” but it doesn’t work that way. Books are
fantastic at exposing you to guiding principles and patterns, but if your brain
isn’t ready to connect them with real-world problems, it won’t.
The number one thing that will make you better at writing JavaScript is writing
JavaScript. It’s OK if you cringe at it six months from now. It’s OK if you
know it could be better if you only understood X, Y, or Z a little bit better.
 Cultivate dissatisfaction , and fear the day when you aren’t disappointed with
the code you wrote last month.
Encounters with new concepts are almost always eventually rewarding, but in the
short term I’ve found they can be downright demoralizing if you’re not aware of
the bigger picture. The first step to being better at a thing is realizing you
could be better at that thing, and initially that realization tends to involve
being overwhelmed with all you don’t know. The first  JSConf , in 2009, was
exactly this for me. I showed up eager to learn but feeling pretty cocky about
my skills. I left brutally aware of the smallness of my knowledge, and it was a
transformational experience: getting good at a thing involves seeking out
opportunities to feel small.
One of the most helpful things in my learning has been having access to smart
people who are willing to answer my questions and help me when I get stuck.
Meeting these people and maintaining relationships with them is hard work, and
it generally involves interacting with them in real life, not just on the
internet, but the dividends of this investment are unfathomable.
To that end, attend conferences. Talk to the speakers and ask them questions.
Write them emails afterwards saying that it was nice to meet them. Subscribe to
their blogs. Pay attention to what they’re doing and evangelize their good
work.
Remember, too, that local meetups can be good exposure to new ideas too, even
if on a smaller scale. The added bonus of local meetups is that the people
you’ll meet there are … local! It’s easy to maintain relationships with them
and share in learning with them in real life.
(An aside: If your company won’t pay for you to attend any conferences, make
clear how short-sighted your company’s decision is and start looking for a new
job, because your company does not deserve you. Then, if you can, cough up the
money and go anyway. As a self-employed consultant, I still managed to find
something like $10,000 to spend on travel- and conference-related expenses last
year, and I consider every penny of it to be money spent on being better at
what I do. When I hear about big companies that won’t fork over even a fraction
of that for an employee who is raising their hand and saying “help me be better
at what I do!”, I rage.)
Make a point of following the bug tracker and repository for an active
open-source project. Read the bug reports. Try the test cases. Understand the
commits. I admit that I have never been able to make myself do this for
extended periods of time, but I try to drop in on certain projects now and then
because it exposes me to arbitrary code and concepts that I might not otherwise
run into.
Read the source for your favorite library, and refer to it when you need to
know how a method works. Consult the documentation when there’s some part of
the source you don’t understand. When choosing tools and plugins, read the
source, and see whether there are things you’d do differently.
Eavesdrop on communities, and participate when you have something helpful to
add. Lurk on a mailing list or a forum or in an IRC channel, help other people
solve problems. If you’re not a  help vampire  — if you give more than you take —
the “elders” of a community will notice, and you will be rewarded with their
willingness to help you when it matters.
Finally, books:

JavaScript: The Good Parts, by Douglas Crockford. It took me more than one
try to get through this not-very-thick book, and it is not gospel. However,
it is mandatory reading for any serious JavaScript developer.
 Eloquent JavaScript , Marijn Haverbeke (also in print). This is another book
that I consider mandatory; you may not read straight through it, but you
should have it close at hand. I like it so much that I actually bought the
print version, and then was lucky enough to get a signed copy from Marijn at
JSConf 2011.
JavaScript Patterns, by Stoyan Stefanov. This was the book that showed me
there were names for so many patterns that I’d discovered purely through
fumbling around with my own code. I read it on the flight to the 2010 Boston
jQuery Conference, and it’s definitely the kind of book that I wouldn’t have
gotten as much out of a year earlier, when I had a lot less experience with
the kinds of problems it addresses.
Object-Oriented JavaScript, by Stoyan Stefanov. It’s been ages since I read
this book, and so I confess that I don’t have a strong recollection of it,
but it was probably the first book I read that got me thinking about
structuring JavaScript code beyond the “get some elements, do something with
them” paradigm of jQuery.

Good luck.]]></description><content:encoded><![CDATA[<p>I seem to be getting a lot of emails these days asking a deceptively simple
question: “How do I get better at JavaScript?” What follows are some
semi-random thoughts on the subject:</p>
<p>The thing that I’ve come to realize about these questions is that some things
just take time. I wish I could write down “Ten Things You Need to Know to Make
You Amazing at the JavaScript,” but it doesn’t work that way. Books are
fantastic at exposing you to guiding principles and patterns, but if your brain
isn’t ready to connect them with real-world problems, it won’t.</p>
<p><strong>The number one thing that will make you better at writing JavaScript is writing
JavaScript.</strong> It’s OK if you cringe at it six months from now. It’s OK if you
know it could be better if you only understood X, Y, or Z a little bit better.
<a href="http://www.paulgraham.com/taste.html"> Cultivate dissatisfaction </a>, and fear the day when you aren’t disappointed with
the code you wrote last month.</p>
<p>Encounters with new concepts are almost always eventually rewarding, but in the
short term I’ve found they can be downright demoralizing if you’re not aware of
the bigger picture. The first step to being better at a thing is realizing you
could be better at that thing, and initially that realization tends to involve
being overwhelmed with all you don’t know. The first <a href="http://jsconf.us/2009/"> JSConf </a>, in 2009, was
exactly this for me. I showed up eager to learn but feeling pretty cocky about
my skills. I left brutally aware of the smallness of my knowledge, and it was a
transformational experience: getting good at a thing involves seeking out
opportunities to feel small.</p>
<p>One of the most helpful things in my learning has been having access to smart
people who are willing to answer my questions and help me when I get stuck.
Meeting these people and maintaining relationships with them is hard work, and
it generally involves interacting with them in real life, not just on the
internet, but the dividends of this investment are unfathomable.</p>
<p>To that end, attend conferences. Talk to the speakers and ask them questions.
Write them emails afterwards saying that it was nice to meet them. Subscribe to
their blogs. Pay attention to what they’re doing and evangelize their good
work.</p>
<p>Remember, too, that local meetups can be good exposure to new ideas too, even
if on a smaller scale. The added bonus of local meetups is that the people
you’ll meet there are … local! It’s easy to maintain relationships with them
and share in learning with them in real life.</p>
<p>(An aside: If your company won’t pay for you to attend any conferences, make
clear how short-sighted your company’s decision is and start looking for a new
job, because your company does not deserve you. Then, if you can, cough up the
money and go anyway. As a self-employed consultant, I still managed to find
something like $10,000 to spend on travel- and conference-related expenses last
year, and I consider every penny of it to be money spent on being better at
what I do. When I hear about big companies that won’t fork over even a fraction
of that for an employee who is raising their hand and saying “help me be better
at what I do!”, I rage.)</p>
<p>Make a point of following the bug tracker and repository for an active
open-source project. Read the bug reports. Try the test cases. Understand the
commits. I admit that I have never been able to make myself do this for
extended periods of time, but I try to drop in on certain projects now and then
because it exposes me to arbitrary code and concepts that I might not otherwise
run into.</p>
<p>Read the source for your favorite library, and refer to it when you need to
know how a method works. Consult the documentation when there’s some part of
the source you don’t understand. When choosing tools and plugins, read the
source, and see whether there are things you’d do differently.</p>
<p>Eavesdrop on communities, and participate when you have something helpful to
add. Lurk on a mailing list or a forum or in an IRC channel, help other people
solve problems. If you’re not a <a href="http://slash7.com/2006/12/22/vampires/"> help vampire </a> — if you give more than you take —
the “elders” of a community will notice, and you will be rewarded with their
willingness to help you when it matters.</p>
<p>Finally, books:</p>
<ul>
<li>JavaScript: The Good Parts, by Douglas Crockford. It took me more than one
try to get through this not-very-thick book, and it is not gospel. However,
it is mandatory reading for any serious JavaScript developer.</li>
<li><a href="http://eloquentjavascript.net/"> Eloquent JavaScript </a>, Marijn Haverbeke (also in print). This is another book
that I consider mandatory; you may not read straight through it, but you
should have it close at hand. I like it so much that I actually bought the
print version, and then was lucky enough to get a signed copy from Marijn at
JSConf 2011.</li>
<li>JavaScript Patterns, by Stoyan Stefanov. This was the book that showed me
there were names for so many patterns that I’d discovered purely through
fumbling around with my own code. I read it on the flight to the 2010 Boston
jQuery Conference, and it’s definitely the kind of book that I wouldn’t have
gotten as much out of a year earlier, when I had a lot less experience with
the kinds of problems it addresses.</li>
<li>Object-Oriented JavaScript, by Stoyan Stefanov. It’s been ages since I read
this book, and so I confess that I don’t have a strong recollection of it,
but it was probably the first book I read that got me thinking about
structuring JavaScript code beyond the “get some elements, do something with
them” paradigm of jQuery.</li>
</ul>
<p>Good luck.</p>
]]></content:encoded></item></channel></rss>